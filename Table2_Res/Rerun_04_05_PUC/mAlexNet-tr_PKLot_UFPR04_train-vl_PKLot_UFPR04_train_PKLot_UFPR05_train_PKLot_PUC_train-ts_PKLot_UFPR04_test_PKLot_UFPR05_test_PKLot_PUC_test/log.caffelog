I0526 01:22:58.635601  5200 upgrade_proto.cpp:1084] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0526 01:22:58.635814  5200 upgrade_proto.cpp:1091] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0526 01:22:58.635824  5200 upgrade_proto.cpp:1093] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0526 01:22:58.635913  5200 caffe.cpp:197] Use CPU.
I0526 01:22:58.636200  5200 solver.cpp:45] Initializing solver from parameters: 
train_net: "train.prototxt"
test_net: "val-PKLot_UFPR04_train.prototxt"
test_net: "val-PKLot_UFPR05_train.prototxt"
test_net: "val-PKLot_PUC_train.prototxt"
test_iter: 25
test_iter: 47
test_iter: 111
test_interval: 385
base_lr: 0.01
display: 26
max_iter: 13827
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 4609
snapshot: 385
snapshot_prefix: "snapshots/snapshot"
solver_mode: CPU
random_seed: 23
train_state {
  level: 0
  stage: ""
}
test_initialization: true
average_loss: 26
type: "SGD"
I0526 01:22:58.636327  5200 solver.cpp:92] Creating training net from train_net file: train.prototxt
I0526 01:22:58.637317  5200 net.cpp:53] Initializing net from parameters: 
name: "mAlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 224
  }
  image_data_param {
    source: "/home/hao/deep-parking/splits/PKLot/UFPR04_train.txt"
    batch_size: 64
    rand_skip: 64
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "/home/hao/Documents/CV/PKLot/PKLotSegmented/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
I0526 01:22:58.637424  5200 layer_factory.hpp:77] Creating layer data
I0526 01:22:58.637457  5200 net.cpp:86] Creating Layer data
I0526 01:22:58.637468  5200 net.cpp:382] data -> data
I0526 01:22:58.637506  5200 net.cpp:382] data -> label
I0526 01:22:58.637815  5200 image_data_layer.cpp:38] Opening file /home/hao/deep-parking/splits/PKLot/UFPR04_train.txt
I0526 01:22:58.656168  5200 image_data_layer.cpp:53] Shuffling data
I0526 01:22:58.671087  5200 image_data_layer.cpp:63] A total of 49160 images.
I0526 01:22:58.671118  5200 image_data_layer.cpp:70] Skipping first 40 data points.
I0526 01:22:58.677678  5200 image_data_layer.cpp:90] output data size: 64,3,224,224
I0526 01:22:58.677790  5200 net.cpp:124] Setting up data
I0526 01:22:58.677806  5200 net.cpp:131] Top shape: 64 3 224 224 (9633792)
I0526 01:22:58.677811  5200 net.cpp:131] Top shape: 64 (64)
I0526 01:22:58.677815  5200 net.cpp:139] Memory required for data: 38535424
I0526 01:22:58.677821  5200 layer_factory.hpp:77] Creating layer conv1
I0526 01:22:58.677855  5200 net.cpp:86] Creating Layer conv1
I0526 01:22:58.677870  5200 net.cpp:408] conv1 <- data
I0526 01:22:58.677892  5200 net.cpp:382] conv1 -> conv1
I0526 01:22:58.678004  5200 net.cpp:124] Setting up conv1
I0526 01:22:58.678020  5200 net.cpp:131] Top shape: 64 16 54 54 (2985984)
I0526 01:22:58.678025  5200 net.cpp:139] Memory required for data: 50479360
I0526 01:22:58.678043  5200 layer_factory.hpp:77] Creating layer relu1
I0526 01:22:58.678053  5200 net.cpp:86] Creating Layer relu1
I0526 01:22:58.678057  5200 net.cpp:408] relu1 <- conv1
I0526 01:22:58.678061  5200 net.cpp:369] relu1 -> conv1 (in-place)
I0526 01:22:58.678071  5200 net.cpp:124] Setting up relu1
I0526 01:22:58.678077  5200 net.cpp:131] Top shape: 64 16 54 54 (2985984)
I0526 01:22:58.678081  5200 net.cpp:139] Memory required for data: 62423296
I0526 01:22:58.678083  5200 layer_factory.hpp:77] Creating layer pool1
I0526 01:22:58.678095  5200 net.cpp:86] Creating Layer pool1
I0526 01:22:58.678099  5200 net.cpp:408] pool1 <- conv1
I0526 01:22:58.678108  5200 net.cpp:382] pool1 -> pool1
I0526 01:22:58.678143  5200 net.cpp:124] Setting up pool1
I0526 01:22:58.678156  5200 net.cpp:131] Top shape: 64 16 27 27 (746496)
I0526 01:22:58.678164  5200 net.cpp:139] Memory required for data: 65409280
I0526 01:22:58.678169  5200 layer_factory.hpp:77] Creating layer conv2
I0526 01:22:58.678189  5200 net.cpp:86] Creating Layer conv2
I0526 01:22:58.678201  5200 net.cpp:408] conv2 <- pool1
I0526 01:22:58.678216  5200 net.cpp:382] conv2 -> conv2
I0526 01:22:58.678306  5200 net.cpp:124] Setting up conv2
I0526 01:22:58.678318  5200 net.cpp:131] Top shape: 64 20 23 23 (677120)
I0526 01:22:58.678320  5200 net.cpp:139] Memory required for data: 68117760
I0526 01:22:58.678328  5200 layer_factory.hpp:77] Creating layer relu2
I0526 01:22:58.678340  5200 net.cpp:86] Creating Layer relu2
I0526 01:22:58.678349  5200 net.cpp:408] relu2 <- conv2
I0526 01:22:58.678362  5200 net.cpp:369] relu2 -> conv2 (in-place)
I0526 01:22:58.678372  5200 net.cpp:124] Setting up relu2
I0526 01:22:58.678381  5200 net.cpp:131] Top shape: 64 20 23 23 (677120)
I0526 01:22:58.678388  5200 net.cpp:139] Memory required for data: 70826240
I0526 01:22:58.678396  5200 layer_factory.hpp:77] Creating layer pool2
I0526 01:22:58.678406  5200 net.cpp:86] Creating Layer pool2
I0526 01:22:58.678412  5200 net.cpp:408] pool2 <- conv2
I0526 01:22:58.678423  5200 net.cpp:382] pool2 -> pool2
I0526 01:22:58.678436  5200 net.cpp:124] Setting up pool2
I0526 01:22:58.678444  5200 net.cpp:131] Top shape: 64 20 11 11 (154880)
I0526 01:22:58.678450  5200 net.cpp:139] Memory required for data: 71445760
I0526 01:22:58.678458  5200 layer_factory.hpp:77] Creating layer conv3
I0526 01:22:58.678472  5200 net.cpp:86] Creating Layer conv3
I0526 01:22:58.678486  5200 net.cpp:408] conv3 <- pool2
I0526 01:22:58.678498  5200 net.cpp:382] conv3 -> conv3
I0526 01:22:58.678578  5200 net.cpp:124] Setting up conv3
I0526 01:22:58.678592  5200 net.cpp:131] Top shape: 64 30 9 9 (155520)
I0526 01:22:58.678622  5200 net.cpp:139] Memory required for data: 72067840
I0526 01:22:58.678635  5200 layer_factory.hpp:77] Creating layer relu3
I0526 01:22:58.678645  5200 net.cpp:86] Creating Layer relu3
I0526 01:22:58.678651  5200 net.cpp:408] relu3 <- conv3
I0526 01:22:58.678656  5200 net.cpp:369] relu3 -> conv3 (in-place)
I0526 01:22:58.678661  5200 net.cpp:124] Setting up relu3
I0526 01:22:58.678673  5200 net.cpp:131] Top shape: 64 30 9 9 (155520)
I0526 01:22:58.678683  5200 net.cpp:139] Memory required for data: 72689920
I0526 01:22:58.678691  5200 layer_factory.hpp:77] Creating layer pool3
I0526 01:22:58.678702  5200 net.cpp:86] Creating Layer pool3
I0526 01:22:58.678714  5200 net.cpp:408] pool3 <- conv3
I0526 01:22:58.678730  5200 net.cpp:382] pool3 -> pool3
I0526 01:22:58.678747  5200 net.cpp:124] Setting up pool3
I0526 01:22:58.678756  5200 net.cpp:131] Top shape: 64 30 4 4 (30720)
I0526 01:22:58.678761  5200 net.cpp:139] Memory required for data: 72812800
I0526 01:22:58.678768  5200 layer_factory.hpp:77] Creating layer fc4
I0526 01:22:58.678786  5200 net.cpp:86] Creating Layer fc4
I0526 01:22:58.678794  5200 net.cpp:408] fc4 <- pool3
I0526 01:22:58.678807  5200 net.cpp:382] fc4 -> fc4
I0526 01:22:58.679008  5200 net.cpp:124] Setting up fc4
I0526 01:22:58.679023  5200 net.cpp:131] Top shape: 64 48 (3072)
I0526 01:22:58.679028  5200 net.cpp:139] Memory required for data: 72825088
I0526 01:22:58.679037  5200 layer_factory.hpp:77] Creating layer relu4
I0526 01:22:58.679049  5200 net.cpp:86] Creating Layer relu4
I0526 01:22:58.679054  5200 net.cpp:408] relu4 <- fc4
I0526 01:22:58.679062  5200 net.cpp:369] relu4 -> fc4 (in-place)
I0526 01:22:58.679078  5200 net.cpp:124] Setting up relu4
I0526 01:22:58.679088  5200 net.cpp:131] Top shape: 64 48 (3072)
I0526 01:22:58.679095  5200 net.cpp:139] Memory required for data: 72837376
I0526 01:22:58.679101  5200 layer_factory.hpp:77] Creating layer fc5
I0526 01:22:58.679111  5200 net.cpp:86] Creating Layer fc5
I0526 01:22:58.679116  5200 net.cpp:408] fc5 <- fc4
I0526 01:22:58.679122  5200 net.cpp:382] fc5 -> fc5
I0526 01:22:58.679139  5200 net.cpp:124] Setting up fc5
I0526 01:22:58.679145  5200 net.cpp:131] Top shape: 64 2 (128)
I0526 01:22:58.679148  5200 net.cpp:139] Memory required for data: 72837888
I0526 01:22:58.679154  5200 layer_factory.hpp:77] Creating layer loss
I0526 01:22:58.679162  5200 net.cpp:86] Creating Layer loss
I0526 01:22:58.679169  5200 net.cpp:408] loss <- fc5
I0526 01:22:58.679178  5200 net.cpp:408] loss <- label
I0526 01:22:58.679189  5200 net.cpp:382] loss -> loss
I0526 01:22:58.679204  5200 layer_factory.hpp:77] Creating layer loss
I0526 01:22:58.679227  5200 net.cpp:124] Setting up loss
I0526 01:22:58.679234  5200 net.cpp:131] Top shape: (1)
I0526 01:22:58.679236  5200 net.cpp:134]     with loss weight 1
I0526 01:22:58.679250  5200 net.cpp:139] Memory required for data: 72837892
I0526 01:22:58.679255  5200 net.cpp:200] loss needs backward computation.
I0526 01:22:58.679266  5200 net.cpp:200] fc5 needs backward computation.
I0526 01:22:58.679275  5200 net.cpp:200] relu4 needs backward computation.
I0526 01:22:58.679281  5200 net.cpp:200] fc4 needs backward computation.
I0526 01:22:58.679291  5200 net.cpp:200] pool3 needs backward computation.
I0526 01:22:58.679297  5200 net.cpp:200] relu3 needs backward computation.
I0526 01:22:58.679304  5200 net.cpp:200] conv3 needs backward computation.
I0526 01:22:58.679312  5200 net.cpp:200] pool2 needs backward computation.
I0526 01:22:58.679319  5200 net.cpp:200] relu2 needs backward computation.
I0526 01:22:58.679327  5200 net.cpp:200] conv2 needs backward computation.
I0526 01:22:58.679329  5200 net.cpp:200] pool1 needs backward computation.
I0526 01:22:58.679335  5200 net.cpp:200] relu1 needs backward computation.
I0526 01:22:58.679340  5200 net.cpp:200] conv1 needs backward computation.
I0526 01:22:58.679343  5200 net.cpp:202] data does not need backward computation.
I0526 01:22:58.679348  5200 net.cpp:244] This network produces output loss
I0526 01:22:58.679358  5200 net.cpp:257] Network initialization done.
I0526 01:22:58.679877  5200 solver.cpp:190] Creating test net (#0) specified by test_net file: val-PKLot_UFPR04_train.prototxt
I0526 01:22:58.680007  5200 net.cpp:53] Initializing net from parameters: 
name: "mAlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 224
  }
  image_data_param {
    source: "/home/hao/deep-parking/splits/PKLot/UFPR04_train.txt"
    batch_size: 100
    rand_skip: 100
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "/home/hao/Documents/CV/PKLot/PKLotSegmented/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0526 01:22:58.680119  5200 layer_factory.hpp:77] Creating layer data
I0526 01:22:58.680135  5200 net.cpp:86] Creating Layer data
I0526 01:22:58.680143  5200 net.cpp:382] data -> data
I0526 01:22:58.680152  5200 net.cpp:382] data -> label
I0526 01:22:58.680166  5200 image_data_layer.cpp:38] Opening file /home/hao/deep-parking/splits/PKLot/UFPR04_train.txt
I0526 01:22:58.707335  5200 image_data_layer.cpp:53] Shuffling data
I0526 01:22:58.724686  5200 image_data_layer.cpp:63] A total of 49160 images.
I0526 01:22:58.724715  5200 image_data_layer.cpp:70] Skipping first 21 data points.
I0526 01:22:58.725442  5200 image_data_layer.cpp:90] output data size: 100,3,224,224
I0526 01:22:58.725548  5200 net.cpp:124] Setting up data
I0526 01:22:58.725569  5200 net.cpp:131] Top shape: 100 3 224 224 (15052800)
I0526 01:22:58.725575  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:58.725582  5200 net.cpp:139] Memory required for data: 60211600
I0526 01:22:58.725587  5200 layer_factory.hpp:77] Creating layer label_data_1_split
I0526 01:22:58.725602  5200 net.cpp:86] Creating Layer label_data_1_split
I0526 01:22:58.725611  5200 net.cpp:408] label_data_1_split <- label
I0526 01:22:58.725626  5200 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0526 01:22:58.725641  5200 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0526 01:22:58.725654  5200 net.cpp:124] Setting up label_data_1_split
I0526 01:22:58.725664  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:58.725672  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:58.725677  5200 net.cpp:139] Memory required for data: 60212400
I0526 01:22:58.725680  5200 layer_factory.hpp:77] Creating layer conv1
I0526 01:22:58.725703  5200 net.cpp:86] Creating Layer conv1
I0526 01:22:58.725713  5200 net.cpp:408] conv1 <- data
I0526 01:22:58.725726  5200 net.cpp:382] conv1 -> conv1
I0526 01:22:58.725793  5200 net.cpp:124] Setting up conv1
I0526 01:22:58.725802  5200 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 01:22:58.725805  5200 net.cpp:139] Memory required for data: 78874800
I0526 01:22:58.725814  5200 layer_factory.hpp:77] Creating layer relu1
I0526 01:22:58.725821  5200 net.cpp:86] Creating Layer relu1
I0526 01:22:58.725826  5200 net.cpp:408] relu1 <- conv1
I0526 01:22:58.725831  5200 net.cpp:369] relu1 -> conv1 (in-place)
I0526 01:22:58.725836  5200 net.cpp:124] Setting up relu1
I0526 01:22:58.725841  5200 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 01:22:58.725847  5200 net.cpp:139] Memory required for data: 97537200
I0526 01:22:58.725849  5200 layer_factory.hpp:77] Creating layer pool1
I0526 01:22:58.725857  5200 net.cpp:86] Creating Layer pool1
I0526 01:22:58.725862  5200 net.cpp:408] pool1 <- conv1
I0526 01:22:58.725867  5200 net.cpp:382] pool1 -> pool1
I0526 01:22:58.725877  5200 net.cpp:124] Setting up pool1
I0526 01:22:58.725883  5200 net.cpp:131] Top shape: 100 16 27 27 (1166400)
I0526 01:22:58.725888  5200 net.cpp:139] Memory required for data: 102202800
I0526 01:22:58.725890  5200 layer_factory.hpp:77] Creating layer conv2
I0526 01:22:58.725899  5200 net.cpp:86] Creating Layer conv2
I0526 01:22:58.725904  5200 net.cpp:408] conv2 <- pool1
I0526 01:22:58.725910  5200 net.cpp:382] conv2 -> conv2
I0526 01:22:58.725970  5200 net.cpp:124] Setting up conv2
I0526 01:22:58.725976  5200 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 01:22:58.725980  5200 net.cpp:139] Memory required for data: 106434800
I0526 01:22:58.725986  5200 layer_factory.hpp:77] Creating layer relu2
I0526 01:22:58.725992  5200 net.cpp:86] Creating Layer relu2
I0526 01:22:58.725996  5200 net.cpp:408] relu2 <- conv2
I0526 01:22:58.726001  5200 net.cpp:369] relu2 -> conv2 (in-place)
I0526 01:22:58.726007  5200 net.cpp:124] Setting up relu2
I0526 01:22:58.726011  5200 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 01:22:58.726016  5200 net.cpp:139] Memory required for data: 110666800
I0526 01:22:58.726018  5200 layer_factory.hpp:77] Creating layer pool2
I0526 01:22:58.726023  5200 net.cpp:86] Creating Layer pool2
I0526 01:22:58.726027  5200 net.cpp:408] pool2 <- conv2
I0526 01:22:58.726032  5200 net.cpp:382] pool2 -> pool2
I0526 01:22:58.726039  5200 net.cpp:124] Setting up pool2
I0526 01:22:58.726044  5200 net.cpp:131] Top shape: 100 20 11 11 (242000)
I0526 01:22:58.726049  5200 net.cpp:139] Memory required for data: 111634800
I0526 01:22:58.726052  5200 layer_factory.hpp:77] Creating layer conv3
I0526 01:22:58.726060  5200 net.cpp:86] Creating Layer conv3
I0526 01:22:58.726064  5200 net.cpp:408] conv3 <- pool2
I0526 01:22:58.726070  5200 net.cpp:382] conv3 -> conv3
I0526 01:22:58.726119  5200 net.cpp:124] Setting up conv3
I0526 01:22:58.726125  5200 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 01:22:58.726130  5200 net.cpp:139] Memory required for data: 112606800
I0526 01:22:58.726150  5200 layer_factory.hpp:77] Creating layer relu3
I0526 01:22:58.726156  5200 net.cpp:86] Creating Layer relu3
I0526 01:22:58.726161  5200 net.cpp:408] relu3 <- conv3
I0526 01:22:58.726166  5200 net.cpp:369] relu3 -> conv3 (in-place)
I0526 01:22:58.726171  5200 net.cpp:124] Setting up relu3
I0526 01:22:58.726176  5200 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 01:22:58.726181  5200 net.cpp:139] Memory required for data: 113578800
I0526 01:22:58.726184  5200 layer_factory.hpp:77] Creating layer pool3
I0526 01:22:58.726188  5200 net.cpp:86] Creating Layer pool3
I0526 01:22:58.726192  5200 net.cpp:408] pool3 <- conv3
I0526 01:22:58.726197  5200 net.cpp:382] pool3 -> pool3
I0526 01:22:58.726207  5200 net.cpp:124] Setting up pool3
I0526 01:22:58.726212  5200 net.cpp:131] Top shape: 100 30 4 4 (48000)
I0526 01:22:58.726215  5200 net.cpp:139] Memory required for data: 113770800
I0526 01:22:58.726219  5200 layer_factory.hpp:77] Creating layer fc4
I0526 01:22:58.726227  5200 net.cpp:86] Creating Layer fc4
I0526 01:22:58.726230  5200 net.cpp:408] fc4 <- pool3
I0526 01:22:58.726236  5200 net.cpp:382] fc4 -> fc4
I0526 01:22:58.726366  5200 net.cpp:124] Setting up fc4
I0526 01:22:58.726372  5200 net.cpp:131] Top shape: 100 48 (4800)
I0526 01:22:58.726374  5200 net.cpp:139] Memory required for data: 113790000
I0526 01:22:58.726379  5200 layer_factory.hpp:77] Creating layer relu4
I0526 01:22:58.726387  5200 net.cpp:86] Creating Layer relu4
I0526 01:22:58.726392  5200 net.cpp:408] relu4 <- fc4
I0526 01:22:58.726395  5200 net.cpp:369] relu4 -> fc4 (in-place)
I0526 01:22:58.726402  5200 net.cpp:124] Setting up relu4
I0526 01:22:58.726404  5200 net.cpp:131] Top shape: 100 48 (4800)
I0526 01:22:58.726409  5200 net.cpp:139] Memory required for data: 113809200
I0526 01:22:58.726413  5200 layer_factory.hpp:77] Creating layer fc5
I0526 01:22:58.726418  5200 net.cpp:86] Creating Layer fc5
I0526 01:22:58.726423  5200 net.cpp:408] fc5 <- fc4
I0526 01:22:58.726429  5200 net.cpp:382] fc5 -> fc5
I0526 01:22:58.726441  5200 net.cpp:124] Setting up fc5
I0526 01:22:58.726446  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:58.726449  5200 net.cpp:139] Memory required for data: 113810000
I0526 01:22:58.726454  5200 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0526 01:22:58.726461  5200 net.cpp:86] Creating Layer fc5_fc5_0_split
I0526 01:22:58.726465  5200 net.cpp:408] fc5_fc5_0_split <- fc5
I0526 01:22:58.726470  5200 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0526 01:22:58.726478  5200 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0526 01:22:58.726486  5200 net.cpp:124] Setting up fc5_fc5_0_split
I0526 01:22:58.726491  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:58.726495  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:58.726500  5200 net.cpp:139] Memory required for data: 113811600
I0526 01:22:58.726502  5200 layer_factory.hpp:77] Creating layer loss
I0526 01:22:58.726508  5200 net.cpp:86] Creating Layer loss
I0526 01:22:58.726512  5200 net.cpp:408] loss <- fc5_fc5_0_split_0
I0526 01:22:58.726516  5200 net.cpp:408] loss <- label_data_1_split_0
I0526 01:22:58.726523  5200 net.cpp:382] loss -> loss
I0526 01:22:58.726531  5200 layer_factory.hpp:77] Creating layer loss
I0526 01:22:58.726545  5200 net.cpp:124] Setting up loss
I0526 01:22:58.726550  5200 net.cpp:131] Top shape: (1)
I0526 01:22:58.726553  5200 net.cpp:134]     with loss weight 1
I0526 01:22:58.726563  5200 net.cpp:139] Memory required for data: 113811604
I0526 01:22:58.726567  5200 layer_factory.hpp:77] Creating layer accuracy
I0526 01:22:58.726575  5200 net.cpp:86] Creating Layer accuracy
I0526 01:22:58.726580  5200 net.cpp:408] accuracy <- fc5_fc5_0_split_1
I0526 01:22:58.726584  5200 net.cpp:408] accuracy <- label_data_1_split_1
I0526 01:22:58.726590  5200 net.cpp:382] accuracy -> accuracy
I0526 01:22:58.726598  5200 net.cpp:124] Setting up accuracy
I0526 01:22:58.726603  5200 net.cpp:131] Top shape: (1)
I0526 01:22:58.726606  5200 net.cpp:139] Memory required for data: 113811608
I0526 01:22:58.726620  5200 net.cpp:202] accuracy does not need backward computation.
I0526 01:22:58.726625  5200 net.cpp:200] loss needs backward computation.
I0526 01:22:58.726631  5200 net.cpp:200] fc5_fc5_0_split needs backward computation.
I0526 01:22:58.726636  5200 net.cpp:200] fc5 needs backward computation.
I0526 01:22:58.726639  5200 net.cpp:200] relu4 needs backward computation.
I0526 01:22:58.726644  5200 net.cpp:200] fc4 needs backward computation.
I0526 01:22:58.726649  5200 net.cpp:200] pool3 needs backward computation.
I0526 01:22:58.726653  5200 net.cpp:200] relu3 needs backward computation.
I0526 01:22:58.726658  5200 net.cpp:200] conv3 needs backward computation.
I0526 01:22:58.726662  5200 net.cpp:200] pool2 needs backward computation.
I0526 01:22:58.726667  5200 net.cpp:200] relu2 needs backward computation.
I0526 01:22:58.726670  5200 net.cpp:200] conv2 needs backward computation.
I0526 01:22:58.726675  5200 net.cpp:200] pool1 needs backward computation.
I0526 01:22:58.726678  5200 net.cpp:200] relu1 needs backward computation.
I0526 01:22:58.726683  5200 net.cpp:200] conv1 needs backward computation.
I0526 01:22:58.726687  5200 net.cpp:202] label_data_1_split does not need backward computation.
I0526 01:22:58.726693  5200 net.cpp:202] data does not need backward computation.
I0526 01:22:58.726697  5200 net.cpp:244] This network produces output accuracy
I0526 01:22:58.726702  5200 net.cpp:244] This network produces output loss
I0526 01:22:58.726714  5200 net.cpp:257] Network initialization done.
I0526 01:22:58.726781  5200 solver.cpp:190] Creating test net (#1) specified by test_net file: val-PKLot_UFPR05_train.prototxt
I0526 01:22:58.726923  5200 net.cpp:53] Initializing net from parameters: 
name: "mAlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 224
  }
  image_data_param {
    source: "/home/hao/deep-parking/splits/PKLot/UFPR05_train.txt"
    batch_size: 100
    rand_skip: 100
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "/home/hao/Documents/CV/PKLot/PKLotSegmented/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0526 01:22:58.727028  5200 layer_factory.hpp:77] Creating layer data
I0526 01:22:58.727044  5200 net.cpp:86] Creating Layer data
I0526 01:22:58.727049  5200 net.cpp:382] data -> data
I0526 01:22:58.727061  5200 net.cpp:382] data -> label
I0526 01:22:58.727068  5200 image_data_layer.cpp:38] Opening file /home/hao/deep-parking/splits/PKLot/UFPR05_train.txt
I0526 01:22:58.786286  5200 image_data_layer.cpp:53] Shuffling data
I0526 01:22:58.825881  5200 image_data_layer.cpp:63] A total of 93955 images.
I0526 01:22:58.825909  5200 image_data_layer.cpp:70] Skipping first 38 data points.
I0526 01:22:58.828213  5200 image_data_layer.cpp:90] output data size: 100,3,224,224
I0526 01:22:58.828315  5200 net.cpp:124] Setting up data
I0526 01:22:58.828357  5200 net.cpp:131] Top shape: 100 3 224 224 (15052800)
I0526 01:22:58.828383  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:58.828393  5200 net.cpp:139] Memory required for data: 60211600
I0526 01:22:58.828405  5200 layer_factory.hpp:77] Creating layer label_data_1_split
I0526 01:22:58.828425  5200 net.cpp:86] Creating Layer label_data_1_split
I0526 01:22:58.828433  5200 net.cpp:408] label_data_1_split <- label
I0526 01:22:58.828467  5200 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0526 01:22:58.828485  5200 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0526 01:22:58.828495  5200 net.cpp:124] Setting up label_data_1_split
I0526 01:22:58.828502  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:58.828505  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:58.828510  5200 net.cpp:139] Memory required for data: 60212400
I0526 01:22:58.828512  5200 layer_factory.hpp:77] Creating layer conv1
I0526 01:22:58.828527  5200 net.cpp:86] Creating Layer conv1
I0526 01:22:58.828531  5200 net.cpp:408] conv1 <- data
I0526 01:22:58.828538  5200 net.cpp:382] conv1 -> conv1
I0526 01:22:58.828599  5200 net.cpp:124] Setting up conv1
I0526 01:22:58.828606  5200 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 01:22:58.828613  5200 net.cpp:139] Memory required for data: 78874800
I0526 01:22:58.828620  5200 layer_factory.hpp:77] Creating layer relu1
I0526 01:22:58.828627  5200 net.cpp:86] Creating Layer relu1
I0526 01:22:58.828632  5200 net.cpp:408] relu1 <- conv1
I0526 01:22:58.828637  5200 net.cpp:369] relu1 -> conv1 (in-place)
I0526 01:22:58.828642  5200 net.cpp:124] Setting up relu1
I0526 01:22:58.828649  5200 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 01:22:58.828651  5200 net.cpp:139] Memory required for data: 97537200
I0526 01:22:58.828655  5200 layer_factory.hpp:77] Creating layer pool1
I0526 01:22:58.828662  5200 net.cpp:86] Creating Layer pool1
I0526 01:22:58.828666  5200 net.cpp:408] pool1 <- conv1
I0526 01:22:58.828671  5200 net.cpp:382] pool1 -> pool1
I0526 01:22:58.828681  5200 net.cpp:124] Setting up pool1
I0526 01:22:58.828686  5200 net.cpp:131] Top shape: 100 16 27 27 (1166400)
I0526 01:22:58.828689  5200 net.cpp:139] Memory required for data: 102202800
I0526 01:22:58.828692  5200 layer_factory.hpp:77] Creating layer conv2
I0526 01:22:58.828702  5200 net.cpp:86] Creating Layer conv2
I0526 01:22:58.828706  5200 net.cpp:408] conv2 <- pool1
I0526 01:22:58.828712  5200 net.cpp:382] conv2 -> conv2
I0526 01:22:58.828773  5200 net.cpp:124] Setting up conv2
I0526 01:22:58.828800  5200 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 01:22:58.828806  5200 net.cpp:139] Memory required for data: 106434800
I0526 01:22:58.828814  5200 layer_factory.hpp:77] Creating layer relu2
I0526 01:22:58.828820  5200 net.cpp:86] Creating Layer relu2
I0526 01:22:58.828825  5200 net.cpp:408] relu2 <- conv2
I0526 01:22:58.828830  5200 net.cpp:369] relu2 -> conv2 (in-place)
I0526 01:22:58.828835  5200 net.cpp:124] Setting up relu2
I0526 01:22:58.828841  5200 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 01:22:58.828845  5200 net.cpp:139] Memory required for data: 110666800
I0526 01:22:58.828847  5200 layer_factory.hpp:77] Creating layer pool2
I0526 01:22:58.828852  5200 net.cpp:86] Creating Layer pool2
I0526 01:22:58.828855  5200 net.cpp:408] pool2 <- conv2
I0526 01:22:58.828860  5200 net.cpp:382] pool2 -> pool2
I0526 01:22:58.828867  5200 net.cpp:124] Setting up pool2
I0526 01:22:58.828872  5200 net.cpp:131] Top shape: 100 20 11 11 (242000)
I0526 01:22:58.828876  5200 net.cpp:139] Memory required for data: 111634800
I0526 01:22:58.828878  5200 layer_factory.hpp:77] Creating layer conv3
I0526 01:22:58.828891  5200 net.cpp:86] Creating Layer conv3
I0526 01:22:58.828896  5200 net.cpp:408] conv3 <- pool2
I0526 01:22:58.828902  5200 net.cpp:382] conv3 -> conv3
I0526 01:22:58.828953  5200 net.cpp:124] Setting up conv3
I0526 01:22:58.828959  5200 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 01:22:58.828963  5200 net.cpp:139] Memory required for data: 112606800
I0526 01:22:58.828969  5200 layer_factory.hpp:77] Creating layer relu3
I0526 01:22:58.828974  5200 net.cpp:86] Creating Layer relu3
I0526 01:22:58.828976  5200 net.cpp:408] relu3 <- conv3
I0526 01:22:58.828981  5200 net.cpp:369] relu3 -> conv3 (in-place)
I0526 01:22:58.828985  5200 net.cpp:124] Setting up relu3
I0526 01:22:58.828989  5200 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 01:22:58.828996  5200 net.cpp:139] Memory required for data: 113578800
I0526 01:22:58.828999  5200 layer_factory.hpp:77] Creating layer pool3
I0526 01:22:58.829005  5200 net.cpp:86] Creating Layer pool3
I0526 01:22:58.829007  5200 net.cpp:408] pool3 <- conv3
I0526 01:22:58.829012  5200 net.cpp:382] pool3 -> pool3
I0526 01:22:58.829020  5200 net.cpp:124] Setting up pool3
I0526 01:22:58.829025  5200 net.cpp:131] Top shape: 100 30 4 4 (48000)
I0526 01:22:58.829028  5200 net.cpp:139] Memory required for data: 113770800
I0526 01:22:58.829031  5200 layer_factory.hpp:77] Creating layer fc4
I0526 01:22:58.829038  5200 net.cpp:86] Creating Layer fc4
I0526 01:22:58.829042  5200 net.cpp:408] fc4 <- pool3
I0526 01:22:58.829048  5200 net.cpp:382] fc4 -> fc4
I0526 01:22:58.829180  5200 net.cpp:124] Setting up fc4
I0526 01:22:58.829185  5200 net.cpp:131] Top shape: 100 48 (4800)
I0526 01:22:58.829188  5200 net.cpp:139] Memory required for data: 113790000
I0526 01:22:58.829193  5200 layer_factory.hpp:77] Creating layer relu4
I0526 01:22:58.829201  5200 net.cpp:86] Creating Layer relu4
I0526 01:22:58.829205  5200 net.cpp:408] relu4 <- fc4
I0526 01:22:58.829210  5200 net.cpp:369] relu4 -> fc4 (in-place)
I0526 01:22:58.829213  5200 net.cpp:124] Setting up relu4
I0526 01:22:58.829221  5200 net.cpp:131] Top shape: 100 48 (4800)
I0526 01:22:58.829222  5200 net.cpp:139] Memory required for data: 113809200
I0526 01:22:58.829226  5200 layer_factory.hpp:77] Creating layer fc5
I0526 01:22:58.829232  5200 net.cpp:86] Creating Layer fc5
I0526 01:22:58.829236  5200 net.cpp:408] fc5 <- fc4
I0526 01:22:58.829241  5200 net.cpp:382] fc5 -> fc5
I0526 01:22:58.829255  5200 net.cpp:124] Setting up fc5
I0526 01:22:58.829260  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:58.829263  5200 net.cpp:139] Memory required for data: 113810000
I0526 01:22:58.829268  5200 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0526 01:22:58.829277  5200 net.cpp:86] Creating Layer fc5_fc5_0_split
I0526 01:22:58.829282  5200 net.cpp:408] fc5_fc5_0_split <- fc5
I0526 01:22:58.829288  5200 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0526 01:22:58.829293  5200 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0526 01:22:58.829315  5200 net.cpp:124] Setting up fc5_fc5_0_split
I0526 01:22:58.829321  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:58.829324  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:58.829327  5200 net.cpp:139] Memory required for data: 113811600
I0526 01:22:58.829330  5200 layer_factory.hpp:77] Creating layer loss
I0526 01:22:58.829336  5200 net.cpp:86] Creating Layer loss
I0526 01:22:58.829339  5200 net.cpp:408] loss <- fc5_fc5_0_split_0
I0526 01:22:58.829344  5200 net.cpp:408] loss <- label_data_1_split_0
I0526 01:22:58.829349  5200 net.cpp:382] loss -> loss
I0526 01:22:58.829357  5200 layer_factory.hpp:77] Creating layer loss
I0526 01:22:58.829375  5200 net.cpp:124] Setting up loss
I0526 01:22:58.829383  5200 net.cpp:131] Top shape: (1)
I0526 01:22:58.829386  5200 net.cpp:134]     with loss weight 1
I0526 01:22:58.829396  5200 net.cpp:139] Memory required for data: 113811604
I0526 01:22:58.829399  5200 layer_factory.hpp:77] Creating layer accuracy
I0526 01:22:58.829407  5200 net.cpp:86] Creating Layer accuracy
I0526 01:22:58.829412  5200 net.cpp:408] accuracy <- fc5_fc5_0_split_1
I0526 01:22:58.829416  5200 net.cpp:408] accuracy <- label_data_1_split_1
I0526 01:22:58.829421  5200 net.cpp:382] accuracy -> accuracy
I0526 01:22:58.829427  5200 net.cpp:124] Setting up accuracy
I0526 01:22:58.829432  5200 net.cpp:131] Top shape: (1)
I0526 01:22:58.829434  5200 net.cpp:139] Memory required for data: 113811608
I0526 01:22:58.829438  5200 net.cpp:202] accuracy does not need backward computation.
I0526 01:22:58.829442  5200 net.cpp:200] loss needs backward computation.
I0526 01:22:58.829445  5200 net.cpp:200] fc5_fc5_0_split needs backward computation.
I0526 01:22:58.829450  5200 net.cpp:200] fc5 needs backward computation.
I0526 01:22:58.829453  5200 net.cpp:200] relu4 needs backward computation.
I0526 01:22:58.829457  5200 net.cpp:200] fc4 needs backward computation.
I0526 01:22:58.829460  5200 net.cpp:200] pool3 needs backward computation.
I0526 01:22:58.829463  5200 net.cpp:200] relu3 needs backward computation.
I0526 01:22:58.829468  5200 net.cpp:200] conv3 needs backward computation.
I0526 01:22:58.829470  5200 net.cpp:200] pool2 needs backward computation.
I0526 01:22:58.829473  5200 net.cpp:200] relu2 needs backward computation.
I0526 01:22:58.829476  5200 net.cpp:200] conv2 needs backward computation.
I0526 01:22:58.829480  5200 net.cpp:200] pool1 needs backward computation.
I0526 01:22:58.829488  5200 net.cpp:200] relu1 needs backward computation.
I0526 01:22:58.829495  5200 net.cpp:200] conv1 needs backward computation.
I0526 01:22:58.829500  5200 net.cpp:202] label_data_1_split does not need backward computation.
I0526 01:22:58.829504  5200 net.cpp:202] data does not need backward computation.
I0526 01:22:58.829507  5200 net.cpp:244] This network produces output accuracy
I0526 01:22:58.829511  5200 net.cpp:244] This network produces output loss
I0526 01:22:58.829524  5200 net.cpp:257] Network initialization done.
I0526 01:22:58.829607  5200 solver.cpp:190] Creating test net (#2) specified by test_net file: val-PKLot_PUC_train.prototxt
I0526 01:22:58.829761  5200 net.cpp:53] Initializing net from parameters: 
name: "mAlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 224
  }
  image_data_param {
    source: "/home/hao/deep-parking/splits/PKLot/PUC_train.txt"
    batch_size: 100
    rand_skip: 100
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "/home/hao/Documents/CV/PKLot/PKLotSegmented/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0526 01:22:58.829915  5200 layer_factory.hpp:77] Creating layer data
I0526 01:22:58.829957  5200 net.cpp:86] Creating Layer data
I0526 01:22:58.829972  5200 net.cpp:382] data -> data
I0526 01:22:58.829988  5200 net.cpp:382] data -> label
I0526 01:22:58.829999  5200 image_data_layer.cpp:38] Opening file /home/hao/deep-parking/splits/PKLot/PUC_train.txt
I0526 01:22:58.979212  5200 image_data_layer.cpp:53] Shuffling data
I0526 01:22:59.079377  5200 image_data_layer.cpp:63] A total of 220713 images.
I0526 01:22:59.079406  5200 image_data_layer.cpp:70] Skipping first 90 data points.
I0526 01:22:59.082092  5200 image_data_layer.cpp:90] output data size: 100,3,224,224
I0526 01:22:59.082214  5200 net.cpp:124] Setting up data
I0526 01:22:59.082232  5200 net.cpp:131] Top shape: 100 3 224 224 (15052800)
I0526 01:22:59.082239  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:59.082249  5200 net.cpp:139] Memory required for data: 60211600
I0526 01:22:59.082257  5200 layer_factory.hpp:77] Creating layer label_data_1_split
I0526 01:22:59.082274  5200 net.cpp:86] Creating Layer label_data_1_split
I0526 01:22:59.082283  5200 net.cpp:408] label_data_1_split <- label
I0526 01:22:59.082293  5200 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0526 01:22:59.082307  5200 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0526 01:22:59.082321  5200 net.cpp:124] Setting up label_data_1_split
I0526 01:22:59.082329  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:59.082337  5200 net.cpp:131] Top shape: 100 (100)
I0526 01:22:59.082341  5200 net.cpp:139] Memory required for data: 60212400
I0526 01:22:59.082346  5200 layer_factory.hpp:77] Creating layer conv1
I0526 01:22:59.082367  5200 net.cpp:86] Creating Layer conv1
I0526 01:22:59.082376  5200 net.cpp:408] conv1 <- data
I0526 01:22:59.082432  5200 net.cpp:382] conv1 -> conv1
I0526 01:22:59.082541  5200 net.cpp:124] Setting up conv1
I0526 01:22:59.082553  5200 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 01:22:59.082558  5200 net.cpp:139] Memory required for data: 78874800
I0526 01:22:59.082571  5200 layer_factory.hpp:77] Creating layer relu1
I0526 01:22:59.082582  5200 net.cpp:86] Creating Layer relu1
I0526 01:22:59.082589  5200 net.cpp:408] relu1 <- conv1
I0526 01:22:59.082598  5200 net.cpp:369] relu1 -> conv1 (in-place)
I0526 01:22:59.082605  5200 net.cpp:124] Setting up relu1
I0526 01:22:59.082613  5200 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 01:22:59.082621  5200 net.cpp:139] Memory required for data: 97537200
I0526 01:22:59.082626  5200 layer_factory.hpp:77] Creating layer pool1
I0526 01:22:59.082640  5200 net.cpp:86] Creating Layer pool1
I0526 01:22:59.082661  5200 net.cpp:408] pool1 <- conv1
I0526 01:22:59.082674  5200 net.cpp:382] pool1 -> pool1
I0526 01:22:59.082687  5200 net.cpp:124] Setting up pool1
I0526 01:22:59.082697  5200 net.cpp:131] Top shape: 100 16 27 27 (1166400)
I0526 01:22:59.082702  5200 net.cpp:139] Memory required for data: 102202800
I0526 01:22:59.082707  5200 layer_factory.hpp:77] Creating layer conv2
I0526 01:22:59.082721  5200 net.cpp:86] Creating Layer conv2
I0526 01:22:59.082727  5200 net.cpp:408] conv2 <- pool1
I0526 01:22:59.082737  5200 net.cpp:382] conv2 -> conv2
I0526 01:22:59.082849  5200 net.cpp:124] Setting up conv2
I0526 01:22:59.082860  5200 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 01:22:59.082865  5200 net.cpp:139] Memory required for data: 106434800
I0526 01:22:59.082878  5200 layer_factory.hpp:77] Creating layer relu2
I0526 01:22:59.082890  5200 net.cpp:86] Creating Layer relu2
I0526 01:22:59.082911  5200 net.cpp:408] relu2 <- conv2
I0526 01:22:59.082918  5200 net.cpp:369] relu2 -> conv2 (in-place)
I0526 01:22:59.082928  5200 net.cpp:124] Setting up relu2
I0526 01:22:59.082937  5200 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 01:22:59.082943  5200 net.cpp:139] Memory required for data: 110666800
I0526 01:22:59.082950  5200 layer_factory.hpp:77] Creating layer pool2
I0526 01:22:59.082959  5200 net.cpp:86] Creating Layer pool2
I0526 01:22:59.082967  5200 net.cpp:408] pool2 <- conv2
I0526 01:22:59.082978  5200 net.cpp:382] pool2 -> pool2
I0526 01:22:59.082989  5200 net.cpp:124] Setting up pool2
I0526 01:22:59.082999  5200 net.cpp:131] Top shape: 100 20 11 11 (242000)
I0526 01:22:59.083004  5200 net.cpp:139] Memory required for data: 111634800
I0526 01:22:59.083009  5200 layer_factory.hpp:77] Creating layer conv3
I0526 01:22:59.083024  5200 net.cpp:86] Creating Layer conv3
I0526 01:22:59.083031  5200 net.cpp:408] conv3 <- pool2
I0526 01:22:59.083041  5200 net.cpp:382] conv3 -> conv3
I0526 01:22:59.083132  5200 net.cpp:124] Setting up conv3
I0526 01:22:59.083142  5200 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 01:22:59.083148  5200 net.cpp:139] Memory required for data: 112606800
I0526 01:22:59.083160  5200 layer_factory.hpp:77] Creating layer relu3
I0526 01:22:59.083185  5200 net.cpp:86] Creating Layer relu3
I0526 01:22:59.083194  5200 net.cpp:408] relu3 <- conv3
I0526 01:22:59.083202  5200 net.cpp:369] relu3 -> conv3 (in-place)
I0526 01:22:59.083209  5200 net.cpp:124] Setting up relu3
I0526 01:22:59.083220  5200 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 01:22:59.083236  5200 net.cpp:139] Memory required for data: 113578800
I0526 01:22:59.083251  5200 layer_factory.hpp:77] Creating layer pool3
I0526 01:22:59.083268  5200 net.cpp:86] Creating Layer pool3
I0526 01:22:59.083276  5200 net.cpp:408] pool3 <- conv3
I0526 01:22:59.083286  5200 net.cpp:382] pool3 -> pool3
I0526 01:22:59.083300  5200 net.cpp:124] Setting up pool3
I0526 01:22:59.083309  5200 net.cpp:131] Top shape: 100 30 4 4 (48000)
I0526 01:22:59.083314  5200 net.cpp:139] Memory required for data: 113770800
I0526 01:22:59.083321  5200 layer_factory.hpp:77] Creating layer fc4
I0526 01:22:59.083333  5200 net.cpp:86] Creating Layer fc4
I0526 01:22:59.083341  5200 net.cpp:408] fc4 <- pool3
I0526 01:22:59.083374  5200 net.cpp:382] fc4 -> fc4
I0526 01:22:59.083587  5200 net.cpp:124] Setting up fc4
I0526 01:22:59.083600  5200 net.cpp:131] Top shape: 100 48 (4800)
I0526 01:22:59.083602  5200 net.cpp:139] Memory required for data: 113790000
I0526 01:22:59.083608  5200 layer_factory.hpp:77] Creating layer relu4
I0526 01:22:59.083616  5200 net.cpp:86] Creating Layer relu4
I0526 01:22:59.083622  5200 net.cpp:408] relu4 <- fc4
I0526 01:22:59.083628  5200 net.cpp:369] relu4 -> fc4 (in-place)
I0526 01:22:59.083636  5200 net.cpp:124] Setting up relu4
I0526 01:22:59.083639  5200 net.cpp:131] Top shape: 100 48 (4800)
I0526 01:22:59.083642  5200 net.cpp:139] Memory required for data: 113809200
I0526 01:22:59.083647  5200 layer_factory.hpp:77] Creating layer fc5
I0526 01:22:59.083653  5200 net.cpp:86] Creating Layer fc5
I0526 01:22:59.083678  5200 net.cpp:408] fc5 <- fc4
I0526 01:22:59.083703  5200 net.cpp:382] fc5 -> fc5
I0526 01:22:59.083734  5200 net.cpp:124] Setting up fc5
I0526 01:22:59.083743  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:59.083746  5200 net.cpp:139] Memory required for data: 113810000
I0526 01:22:59.083753  5200 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0526 01:22:59.083762  5200 net.cpp:86] Creating Layer fc5_fc5_0_split
I0526 01:22:59.083765  5200 net.cpp:408] fc5_fc5_0_split <- fc5
I0526 01:22:59.083771  5200 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0526 01:22:59.083777  5200 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0526 01:22:59.083788  5200 net.cpp:124] Setting up fc5_fc5_0_split
I0526 01:22:59.083793  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:59.083799  5200 net.cpp:131] Top shape: 100 2 (200)
I0526 01:22:59.083802  5200 net.cpp:139] Memory required for data: 113811600
I0526 01:22:59.083806  5200 layer_factory.hpp:77] Creating layer loss
I0526 01:22:59.083811  5200 net.cpp:86] Creating Layer loss
I0526 01:22:59.083818  5200 net.cpp:408] loss <- fc5_fc5_0_split_0
I0526 01:22:59.083822  5200 net.cpp:408] loss <- label_data_1_split_0
I0526 01:22:59.083829  5200 net.cpp:382] loss -> loss
I0526 01:22:59.083839  5200 layer_factory.hpp:77] Creating layer loss
I0526 01:22:59.083860  5200 net.cpp:124] Setting up loss
I0526 01:22:59.083870  5200 net.cpp:131] Top shape: (1)
I0526 01:22:59.083875  5200 net.cpp:134]     with loss weight 1
I0526 01:22:59.083886  5200 net.cpp:139] Memory required for data: 113811604
I0526 01:22:59.083889  5200 layer_factory.hpp:77] Creating layer accuracy
I0526 01:22:59.083899  5200 net.cpp:86] Creating Layer accuracy
I0526 01:22:59.083904  5200 net.cpp:408] accuracy <- fc5_fc5_0_split_1
I0526 01:22:59.083909  5200 net.cpp:408] accuracy <- label_data_1_split_1
I0526 01:22:59.083914  5200 net.cpp:382] accuracy -> accuracy
I0526 01:22:59.083925  5200 net.cpp:124] Setting up accuracy
I0526 01:22:59.083930  5200 net.cpp:131] Top shape: (1)
I0526 01:22:59.083933  5200 net.cpp:139] Memory required for data: 113811608
I0526 01:22:59.083936  5200 net.cpp:202] accuracy does not need backward computation.
I0526 01:22:59.083942  5200 net.cpp:200] loss needs backward computation.
I0526 01:22:59.083952  5200 net.cpp:200] fc5_fc5_0_split needs backward computation.
I0526 01:22:59.083958  5200 net.cpp:200] fc5 needs backward computation.
I0526 01:22:59.083966  5200 net.cpp:200] relu4 needs backward computation.
I0526 01:22:59.083973  5200 net.cpp:200] fc4 needs backward computation.
I0526 01:22:59.083979  5200 net.cpp:200] pool3 needs backward computation.
I0526 01:22:59.083986  5200 net.cpp:200] relu3 needs backward computation.
I0526 01:22:59.083995  5200 net.cpp:200] conv3 needs backward computation.
I0526 01:22:59.084003  5200 net.cpp:200] pool2 needs backward computation.
I0526 01:22:59.084010  5200 net.cpp:200] relu2 needs backward computation.
I0526 01:22:59.084014  5200 net.cpp:200] conv2 needs backward computation.
I0526 01:22:59.084018  5200 net.cpp:200] pool1 needs backward computation.
I0526 01:22:59.084022  5200 net.cpp:200] relu1 needs backward computation.
I0526 01:22:59.084024  5200 net.cpp:200] conv1 needs backward computation.
I0526 01:22:59.084043  5200 net.cpp:202] label_data_1_split does not need backward computation.
I0526 01:22:59.084051  5200 net.cpp:202] data does not need backward computation.
I0526 01:22:59.084059  5200 net.cpp:244] This network produces output accuracy
I0526 01:22:59.084065  5200 net.cpp:244] This network produces output loss
I0526 01:22:59.084092  5200 net.cpp:257] Network initialization done.
I0526 01:22:59.084328  5200 solver.cpp:57] Solver scaffolding done.
I0526 01:22:59.084393  5200 caffe.cpp:239] Starting Optimization
I0526 01:22:59.084404  5200 solver.cpp:289] Solving mAlexNet
I0526 01:22:59.084409  5200 solver.cpp:290] Learning Rate Policy: step
I0526 01:22:59.084522  5200 solver.cpp:347] Iteration 0, Testing net (#0)
I0526 01:23:14.128211  5200 solver.cpp:414]     Test net output #0: accuracy = 0.52
I0526 01:23:14.128262  5200 solver.cpp:414]     Test net output #1: loss = 1.46103 (* 1 = 1.46103 loss)
I0526 01:23:14.128268  5200 solver.cpp:347] Iteration 0, Testing net (#1)
I0526 01:23:37.111636  5200 solver.cpp:414]     Test net output #0: accuracy = 0.483404
I0526 01:23:37.111729  5200 solver.cpp:414]     Test net output #1: loss = 1.65894 (* 1 = 1.65894 loss)
I0526 01:23:37.111735  5200 solver.cpp:347] Iteration 0, Testing net (#2)
I0526 01:24:31.657389  5200 solver.cpp:414]     Test net output #0: accuracy = 0.514144
I0526 01:24:31.657603  5200 solver.cpp:414]     Test net output #1: loss = 1.49652 (* 1 = 1.49652 loss)
I0526 01:24:32.291792  5200 solver.cpp:239] Iteration 0 (0 iter/s, 93.207s/26 iters), loss = 1.24912
I0526 01:24:32.291843  5200 solver.cpp:258]     Train net output #0: loss = 1.24912 (* 1 = 1.24912 loss)
I0526 01:24:32.291857  5200 sgd_solver.cpp:112] Iteration 0, lr = 0.01
I0526 01:24:48.744628  5200 solver.cpp:239] Iteration 26 (1.58036 iter/s, 16.452s/26 iters), loss = 0.987469
I0526 01:24:48.744683  5200 solver.cpp:258]     Train net output #0: loss = 0.667617 (* 1 = 0.667617 loss)
I0526 01:24:48.744690  5200 sgd_solver.cpp:112] Iteration 26, lr = 0.01
I0526 01:25:04.978760  5200 solver.cpp:239] Iteration 52 (1.60158 iter/s, 16.234s/26 iters), loss = 0.590161
I0526 01:25:04.978914  5200 solver.cpp:258]     Train net output #0: loss = 0.390871 (* 1 = 0.390871 loss)
I0526 01:25:04.978924  5200 sgd_solver.cpp:112] Iteration 52, lr = 0.01
I0526 01:25:20.878191  5200 solver.cpp:239] Iteration 78 (1.63532 iter/s, 15.899s/26 iters), loss = 0.482048
I0526 01:25:20.878248  5200 solver.cpp:258]     Train net output #0: loss = 0.43734 (* 1 = 0.43734 loss)
I0526 01:25:20.878255  5200 sgd_solver.cpp:112] Iteration 78, lr = 0.01
I0526 01:25:36.785997  5200 solver.cpp:239] Iteration 104 (1.6345 iter/s, 15.907s/26 iters), loss = 0.26149
I0526 01:25:36.786209  5200 solver.cpp:258]     Train net output #0: loss = 0.283836 (* 1 = 0.283836 loss)
I0526 01:25:36.786218  5200 sgd_solver.cpp:112] Iteration 104, lr = 0.01
I0526 01:25:52.695905  5200 solver.cpp:239] Iteration 130 (1.63429 iter/s, 15.909s/26 iters), loss = 0.157008
I0526 01:25:52.695957  5200 solver.cpp:258]     Train net output #0: loss = 0.196677 (* 1 = 0.196677 loss)
I0526 01:25:52.695966  5200 sgd_solver.cpp:112] Iteration 130, lr = 0.01
I0526 01:26:08.598362  5200 solver.cpp:239] Iteration 156 (1.63501 iter/s, 15.902s/26 iters), loss = 0.150483
I0526 01:26:08.598481  5200 solver.cpp:258]     Train net output #0: loss = 0.0744879 (* 1 = 0.0744879 loss)
I0526 01:26:08.598490  5200 sgd_solver.cpp:112] Iteration 156, lr = 0.01
I0526 01:26:24.488809  5200 solver.cpp:239] Iteration 182 (1.63625 iter/s, 15.89s/26 iters), loss = 0.11485
I0526 01:26:24.488865  5200 solver.cpp:258]     Train net output #0: loss = 0.251659 (* 1 = 0.251659 loss)
I0526 01:26:24.488873  5200 sgd_solver.cpp:112] Iteration 182, lr = 0.01
I0526 01:26:40.399910  5200 solver.cpp:239] Iteration 208 (1.63409 iter/s, 15.911s/26 iters), loss = 0.0995209
I0526 01:26:40.400141  5200 solver.cpp:258]     Train net output #0: loss = 0.187981 (* 1 = 0.187981 loss)
I0526 01:26:40.400151  5200 sgd_solver.cpp:112] Iteration 208, lr = 0.01
I0526 01:26:56.295882  5200 solver.cpp:239] Iteration 234 (1.63573 iter/s, 15.895s/26 iters), loss = 0.123737
I0526 01:26:56.295940  5200 solver.cpp:258]     Train net output #0: loss = 0.188553 (* 1 = 0.188553 loss)
I0526 01:26:56.295948  5200 sgd_solver.cpp:112] Iteration 234, lr = 0.01
I0526 01:27:11.952805  5200 solver.cpp:239] Iteration 260 (1.66071 iter/s, 15.656s/26 iters), loss = 0.0793488
I0526 01:27:11.952958  5200 solver.cpp:258]     Train net output #0: loss = 0.0435173 (* 1 = 0.0435173 loss)
I0526 01:27:11.952967  5200 sgd_solver.cpp:112] Iteration 260, lr = 0.01
I0526 01:27:27.620893  5200 solver.cpp:239] Iteration 286 (1.65954 iter/s, 15.667s/26 iters), loss = 0.108587
I0526 01:27:27.620949  5200 solver.cpp:258]     Train net output #0: loss = 0.134812 (* 1 = 0.134812 loss)
I0526 01:27:27.620957  5200 sgd_solver.cpp:112] Iteration 286, lr = 0.01
I0526 01:27:43.285210  5200 solver.cpp:239] Iteration 312 (1.65986 iter/s, 15.664s/26 iters), loss = 0.121486
I0526 01:27:43.285454  5200 solver.cpp:258]     Train net output #0: loss = 0.101047 (* 1 = 0.101047 loss)
I0526 01:27:43.285462  5200 sgd_solver.cpp:112] Iteration 312, lr = 0.01
I0526 01:27:58.943495  5200 solver.cpp:239] Iteration 338 (1.66049 iter/s, 15.658s/26 iters), loss = 0.101121
I0526 01:27:58.943547  5200 solver.cpp:258]     Train net output #0: loss = 0.025312 (* 1 = 0.025312 loss)
I0526 01:27:58.943564  5200 sgd_solver.cpp:112] Iteration 338, lr = 0.01
I0526 01:28:14.633911  5200 solver.cpp:239] Iteration 364 (1.65711 iter/s, 15.69s/26 iters), loss = 0.0895359
I0526 01:28:14.634078  5200 solver.cpp:258]     Train net output #0: loss = 0.0767241 (* 1 = 0.0767241 loss)
I0526 01:28:14.634086  5200 sgd_solver.cpp:112] Iteration 364, lr = 0.01
I0526 01:28:26.875910  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_385.caffemodel
I0526 01:28:26.876643  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_385.solverstate
I0526 01:28:26.876946  5200 solver.cpp:347] Iteration 385, Testing net (#0)
I0526 01:28:38.228107  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9816
I0526 01:28:38.228152  5200 solver.cpp:414]     Test net output #1: loss = 0.0559099 (* 1 = 0.0559099 loss)
I0526 01:28:38.228160  5200 solver.cpp:347] Iteration 385, Testing net (#1)
I0526 01:29:00.636562  5200 solver.cpp:414]     Test net output #0: accuracy = 0.840639
I0526 01:29:00.638370  5200 solver.cpp:414]     Test net output #1: loss = 0.388018 (* 1 = 0.388018 loss)
I0526 01:29:00.638386  5200 solver.cpp:347] Iteration 385, Testing net (#2)
I0526 01:29:51.657213  5200 solver.cpp:414]     Test net output #0: accuracy = 0.96955
I0526 01:29:51.658967  5200 solver.cpp:414]     Test net output #1: loss = 0.0854065 (* 1 = 0.0854065 loss)
I0526 01:29:55.323803  5200 solver.cpp:239] Iteration 390 (0.258221 iter/s, 100.689s/26 iters), loss = 0.0780043
I0526 01:29:55.323851  5200 solver.cpp:258]     Train net output #0: loss = 0.0978247 (* 1 = 0.0978247 loss)
I0526 01:29:55.323863  5200 sgd_solver.cpp:112] Iteration 390, lr = 0.01
I0526 01:30:11.244859  5200 solver.cpp:239] Iteration 416 (1.63306 iter/s, 15.921s/26 iters), loss = 0.0804812
I0526 01:30:11.244910  5200 solver.cpp:258]     Train net output #0: loss = 0.0268397 (* 1 = 0.0268397 loss)
I0526 01:30:11.244920  5200 sgd_solver.cpp:112] Iteration 416, lr = 0.01
I0526 01:30:27.174196  5200 solver.cpp:239] Iteration 442 (1.63224 iter/s, 15.929s/26 iters), loss = 0.0569763
I0526 01:30:27.174412  5200 solver.cpp:258]     Train net output #0: loss = 0.0584781 (* 1 = 0.0584781 loss)
I0526 01:30:27.174427  5200 sgd_solver.cpp:112] Iteration 442, lr = 0.01
I0526 01:30:43.061256  5200 solver.cpp:239] Iteration 468 (1.63666 iter/s, 15.886s/26 iters), loss = 0.0895672
I0526 01:30:43.061305  5200 solver.cpp:258]     Train net output #0: loss = 0.173219 (* 1 = 0.173219 loss)
I0526 01:30:43.061313  5200 sgd_solver.cpp:112] Iteration 468, lr = 0.01
I0526 01:30:58.831704  5200 solver.cpp:239] Iteration 494 (1.6487 iter/s, 15.77s/26 iters), loss = 0.0509623
I0526 01:30:58.832731  5200 solver.cpp:258]     Train net output #0: loss = 0.0149572 (* 1 = 0.0149572 loss)
I0526 01:30:58.832741  5200 sgd_solver.cpp:112] Iteration 494, lr = 0.01
I0526 01:31:14.599490  5200 solver.cpp:239] Iteration 520 (1.64912 iter/s, 15.766s/26 iters), loss = 0.0739189
I0526 01:31:14.599540  5200 solver.cpp:258]     Train net output #0: loss = 0.0552222 (* 1 = 0.0552222 loss)
I0526 01:31:14.599547  5200 sgd_solver.cpp:112] Iteration 520, lr = 0.01
I0526 01:31:30.371517  5200 solver.cpp:239] Iteration 546 (1.6486 iter/s, 15.771s/26 iters), loss = 0.0517507
I0526 01:31:30.371773  5200 solver.cpp:258]     Train net output #0: loss = 0.0111749 (* 1 = 0.0111749 loss)
I0526 01:31:30.371781  5200 sgd_solver.cpp:112] Iteration 546, lr = 0.01
I0526 01:31:46.146688  5200 solver.cpp:239] Iteration 572 (1.64828 iter/s, 15.774s/26 iters), loss = 0.0629299
I0526 01:31:46.146744  5200 solver.cpp:258]     Train net output #0: loss = 0.150235 (* 1 = 0.150235 loss)
I0526 01:31:46.146752  5200 sgd_solver.cpp:112] Iteration 572, lr = 0.01
I0526 01:32:01.751387  5200 solver.cpp:239] Iteration 598 (1.66624 iter/s, 15.604s/26 iters), loss = 0.0589787
I0526 01:32:01.751583  5200 solver.cpp:258]     Train net output #0: loss = 0.0238773 (* 1 = 0.0238773 loss)
I0526 01:32:01.751592  5200 sgd_solver.cpp:112] Iteration 598, lr = 0.01
I0526 01:32:17.399874  5200 solver.cpp:239] Iteration 624 (1.66155 iter/s, 15.648s/26 iters), loss = 0.0639426
I0526 01:32:17.399924  5200 solver.cpp:258]     Train net output #0: loss = 0.0171028 (* 1 = 0.0171028 loss)
I0526 01:32:17.399930  5200 sgd_solver.cpp:112] Iteration 624, lr = 0.01
I0526 01:32:33.129002  5200 solver.cpp:239] Iteration 650 (1.653 iter/s, 15.729s/26 iters), loss = 0.035786
I0526 01:32:33.129227  5200 solver.cpp:258]     Train net output #0: loss = 0.016377 (* 1 = 0.016377 loss)
I0526 01:32:33.129236  5200 sgd_solver.cpp:112] Iteration 650, lr = 0.01
I0526 01:32:48.863660  5200 solver.cpp:239] Iteration 676 (1.65247 iter/s, 15.734s/26 iters), loss = 0.0484845
I0526 01:32:48.863714  5200 solver.cpp:258]     Train net output #0: loss = 0.00959702 (* 1 = 0.00959702 loss)
I0526 01:32:48.863723  5200 sgd_solver.cpp:112] Iteration 676, lr = 0.01
I0526 01:33:04.628901  5200 solver.cpp:239] Iteration 702 (1.64922 iter/s, 15.765s/26 iters), loss = 0.0677955
I0526 01:33:04.629140  5200 solver.cpp:258]     Train net output #0: loss = 0.0346486 (* 1 = 0.0346486 loss)
I0526 01:33:04.629149  5200 sgd_solver.cpp:112] Iteration 702, lr = 0.01
I0526 01:33:20.409947  5200 solver.cpp:239] Iteration 728 (1.64766 iter/s, 15.78s/26 iters), loss = 0.055177
I0526 01:33:20.410002  5200 solver.cpp:258]     Train net output #0: loss = 0.0185585 (* 1 = 0.0185585 loss)
I0526 01:33:20.410010  5200 sgd_solver.cpp:112] Iteration 728, lr = 0.01
I0526 01:33:36.176132  5200 solver.cpp:239] Iteration 754 (1.64912 iter/s, 15.766s/26 iters), loss = 0.0564462
I0526 01:33:36.176352  5200 solver.cpp:258]     Train net output #0: loss = 0.0644455 (* 1 = 0.0644455 loss)
I0526 01:33:36.176362  5200 sgd_solver.cpp:112] Iteration 754, lr = 0.01
I0526 01:33:45.263674  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_770.caffemodel
I0526 01:33:45.264340  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_770.solverstate
I0526 01:33:45.264652  5200 solver.cpp:347] Iteration 770, Testing net (#0)
I0526 01:33:56.390322  5200 solver.cpp:414]     Test net output #0: accuracy = 0.5504
I0526 01:33:56.390369  5200 solver.cpp:414]     Test net output #1: loss = 3.01815 (* 1 = 3.01815 loss)
I0526 01:33:56.390375  5200 solver.cpp:347] Iteration 770, Testing net (#1)
I0526 01:34:18.123029  5200 solver.cpp:414]     Test net output #0: accuracy = 0.481915
I0526 01:34:18.123234  5200 solver.cpp:414]     Test net output #1: loss = 6.89245 (* 1 = 6.89245 loss)
I0526 01:34:18.123245  5200 solver.cpp:347] Iteration 770, Testing net (#2)
I0526 01:35:08.928858  5200 solver.cpp:414]     Test net output #0: accuracy = 0.530811
I0526 01:35:08.929100  5200 solver.cpp:414]     Test net output #1: loss = 2.75238 (* 1 = 2.75238 loss)
I0526 01:35:15.560537  5200 solver.cpp:239] Iteration 780 (0.261612 iter/s, 99.384s/26 iters), loss = 0.84379
I0526 01:35:15.560592  5200 solver.cpp:258]     Train net output #0: loss = 0.817075 (* 1 = 0.817075 loss)
I0526 01:35:15.560600  5200 sgd_solver.cpp:112] Iteration 780, lr = 0.01
I0526 01:35:31.225539  5200 solver.cpp:239] Iteration 806 (1.65986 iter/s, 15.664s/26 iters), loss = 0.38928
I0526 01:35:31.225597  5200 solver.cpp:258]     Train net output #0: loss = 0.460048 (* 1 = 0.460048 loss)
I0526 01:35:31.225605  5200 sgd_solver.cpp:112] Iteration 806, lr = 0.01
I0526 01:35:46.919294  5200 solver.cpp:239] Iteration 832 (1.65679 iter/s, 15.693s/26 iters), loss = 0.314885
I0526 01:35:46.919494  5200 solver.cpp:258]     Train net output #0: loss = 0.220241 (* 1 = 0.220241 loss)
I0526 01:35:46.919502  5200 sgd_solver.cpp:112] Iteration 832, lr = 0.01
I0526 01:36:02.567369  5200 solver.cpp:239] Iteration 858 (1.66166 iter/s, 15.647s/26 iters), loss = 0.225037
I0526 01:36:02.567421  5200 solver.cpp:258]     Train net output #0: loss = 0.239919 (* 1 = 0.239919 loss)
I0526 01:36:02.567428  5200 sgd_solver.cpp:112] Iteration 858, lr = 0.01
I0526 01:36:18.332309  5200 solver.cpp:239] Iteration 884 (1.64933 iter/s, 15.764s/26 iters), loss = 0.197284
I0526 01:36:18.332458  5200 solver.cpp:258]     Train net output #0: loss = 0.369714 (* 1 = 0.369714 loss)
I0526 01:36:18.332466  5200 sgd_solver.cpp:112] Iteration 884, lr = 0.01
I0526 01:36:34.181095  5200 solver.cpp:239] Iteration 910 (1.64059 iter/s, 15.848s/26 iters), loss = 0.223504
I0526 01:36:34.181152  5200 solver.cpp:258]     Train net output #0: loss = 0.235685 (* 1 = 0.235685 loss)
I0526 01:36:34.181161  5200 sgd_solver.cpp:112] Iteration 910, lr = 0.01
I0526 01:36:50.129391  5200 solver.cpp:239] Iteration 936 (1.6303 iter/s, 15.948s/26 iters), loss = 0.231494
I0526 01:36:50.129645  5200 solver.cpp:258]     Train net output #0: loss = 0.0782373 (* 1 = 0.0782373 loss)
I0526 01:36:50.129654  5200 sgd_solver.cpp:112] Iteration 936, lr = 0.01
I0526 01:37:05.883280  5200 solver.cpp:239] Iteration 962 (1.65048 iter/s, 15.753s/26 iters), loss = 0.148069
I0526 01:37:05.883335  5200 solver.cpp:258]     Train net output #0: loss = 0.103759 (* 1 = 0.103759 loss)
I0526 01:37:05.883342  5200 sgd_solver.cpp:112] Iteration 962, lr = 0.01
I0526 01:37:21.455440  5200 solver.cpp:239] Iteration 988 (1.66966 iter/s, 15.572s/26 iters), loss = 0.176893
I0526 01:37:21.455603  5200 solver.cpp:258]     Train net output #0: loss = 0.158154 (* 1 = 0.158154 loss)
I0526 01:37:21.455612  5200 sgd_solver.cpp:112] Iteration 988, lr = 0.01
I0526 01:37:37.029785  5200 solver.cpp:239] Iteration 1014 (1.66945 iter/s, 15.574s/26 iters), loss = 0.14135
I0526 01:37:37.029830  5200 solver.cpp:258]     Train net output #0: loss = 0.140845 (* 1 = 0.140845 loss)
I0526 01:37:37.029839  5200 sgd_solver.cpp:112] Iteration 1014, lr = 0.01
I0526 01:37:52.608381  5200 solver.cpp:239] Iteration 1040 (1.66902 iter/s, 15.578s/26 iters), loss = 0.136054
I0526 01:37:52.608604  5200 solver.cpp:258]     Train net output #0: loss = 0.160241 (* 1 = 0.160241 loss)
I0526 01:37:52.608613  5200 sgd_solver.cpp:112] Iteration 1040, lr = 0.01
I0526 01:38:08.175737  5200 solver.cpp:239] Iteration 1066 (1.6702 iter/s, 15.567s/26 iters), loss = 0.0852341
I0526 01:38:08.175788  5200 solver.cpp:258]     Train net output #0: loss = 0.0283758 (* 1 = 0.0283758 loss)
I0526 01:38:08.175796  5200 sgd_solver.cpp:112] Iteration 1066, lr = 0.01
I0526 01:38:23.752110  5200 solver.cpp:239] Iteration 1092 (1.66923 iter/s, 15.576s/26 iters), loss = 0.103782
I0526 01:38:23.752337  5200 solver.cpp:258]     Train net output #0: loss = 0.0275002 (* 1 = 0.0275002 loss)
I0526 01:38:23.752346  5200 sgd_solver.cpp:112] Iteration 1092, lr = 0.01
I0526 01:38:39.323592  5200 solver.cpp:239] Iteration 1118 (1.66977 iter/s, 15.571s/26 iters), loss = 0.119277
I0526 01:38:39.323645  5200 solver.cpp:258]     Train net output #0: loss = 0.237152 (* 1 = 0.237152 loss)
I0526 01:38:39.323652  5200 sgd_solver.cpp:112] Iteration 1118, lr = 0.01
I0526 01:38:54.896245  5200 solver.cpp:239] Iteration 1144 (1.66966 iter/s, 15.572s/26 iters), loss = 0.0682636
I0526 01:38:54.896437  5200 solver.cpp:258]     Train net output #0: loss = 0.062453 (* 1 = 0.062453 loss)
I0526 01:38:54.896456  5200 sgd_solver.cpp:112] Iteration 1144, lr = 0.01
I0526 01:39:00.893052  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_1155.caffemodel
I0526 01:39:00.893720  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_1155.solverstate
I0526 01:39:00.894037  5200 solver.cpp:347] Iteration 1155, Testing net (#0)
I0526 01:39:12.017073  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9784
I0526 01:39:12.017125  5200 solver.cpp:414]     Test net output #1: loss = 0.0663072 (* 1 = 0.0663072 loss)
I0526 01:39:12.017132  5200 solver.cpp:347] Iteration 1155, Testing net (#1)
I0526 01:39:34.107169  5200 solver.cpp:414]     Test net output #0: accuracy = 0.825532
I0526 01:39:34.107302  5200 solver.cpp:414]     Test net output #1: loss = 0.331798 (* 1 = 0.331798 loss)
I0526 01:39:34.107311  5200 solver.cpp:347] Iteration 1155, Testing net (#2)
I0526 01:40:24.324535  5200 solver.cpp:414]     Test net output #0: accuracy = 0.965946
I0526 01:40:24.324679  5200 solver.cpp:414]     Test net output #1: loss = 0.10922 (* 1 = 0.10922 loss)
I0526 01:40:33.918931  5200 solver.cpp:239] Iteration 1170 (0.262568 iter/s, 99.022s/26 iters), loss = 0.106007
I0526 01:40:33.918987  5200 solver.cpp:258]     Train net output #0: loss = 0.0113554 (* 1 = 0.0113554 loss)
I0526 01:40:33.918995  5200 sgd_solver.cpp:112] Iteration 1170, lr = 0.01
I0526 01:40:49.484026  5200 solver.cpp:239] Iteration 1196 (1.67041 iter/s, 15.565s/26 iters), loss = 0.140993
I0526 01:40:49.484077  5200 solver.cpp:258]     Train net output #0: loss = 0.131629 (* 1 = 0.131629 loss)
I0526 01:40:49.484084  5200 sgd_solver.cpp:112] Iteration 1196, lr = 0.01
I0526 01:41:05.072904  5200 solver.cpp:239] Iteration 1222 (1.66795 iter/s, 15.588s/26 iters), loss = 0.0761633
I0526 01:41:05.073071  5200 solver.cpp:258]     Train net output #0: loss = 0.0407044 (* 1 = 0.0407044 loss)
I0526 01:41:05.073078  5200 sgd_solver.cpp:112] Iteration 1222, lr = 0.01
I0526 01:41:20.653846  5200 solver.cpp:239] Iteration 1248 (1.66881 iter/s, 15.58s/26 iters), loss = 0.065438
I0526 01:41:20.653899  5200 solver.cpp:258]     Train net output #0: loss = 0.00427249 (* 1 = 0.00427249 loss)
I0526 01:41:20.653906  5200 sgd_solver.cpp:112] Iteration 1248, lr = 0.01
I0526 01:41:36.212369  5200 solver.cpp:239] Iteration 1274 (1.67117 iter/s, 15.558s/26 iters), loss = 0.142099
I0526 01:41:36.212529  5200 solver.cpp:258]     Train net output #0: loss = 0.178761 (* 1 = 0.178761 loss)
I0526 01:41:36.212538  5200 sgd_solver.cpp:112] Iteration 1274, lr = 0.01
I0526 01:41:51.783066  5200 solver.cpp:239] Iteration 1300 (1.66988 iter/s, 15.57s/26 iters), loss = 0.128667
I0526 01:41:51.783123  5200 solver.cpp:258]     Train net output #0: loss = 0.180862 (* 1 = 0.180862 loss)
I0526 01:41:51.783130  5200 sgd_solver.cpp:112] Iteration 1300, lr = 0.01
I0526 01:42:07.346714  5200 solver.cpp:239] Iteration 1326 (1.67063 iter/s, 15.563s/26 iters), loss = 0.112387
I0526 01:42:07.346846  5200 solver.cpp:258]     Train net output #0: loss = 0.0424513 (* 1 = 0.0424513 loss)
I0526 01:42:07.346855  5200 sgd_solver.cpp:112] Iteration 1326, lr = 0.01
I0526 01:42:22.916975  5200 solver.cpp:239] Iteration 1352 (1.66988 iter/s, 15.57s/26 iters), loss = 0.0931172
I0526 01:42:22.917032  5200 solver.cpp:258]     Train net output #0: loss = 0.0306607 (* 1 = 0.0306607 loss)
I0526 01:42:22.917039  5200 sgd_solver.cpp:112] Iteration 1352, lr = 0.01
I0526 01:42:38.477921  5200 solver.cpp:239] Iteration 1378 (1.67095 iter/s, 15.56s/26 iters), loss = 0.0743435
I0526 01:42:38.478101  5200 solver.cpp:258]     Train net output #0: loss = 0.0217586 (* 1 = 0.0217586 loss)
I0526 01:42:38.478108  5200 sgd_solver.cpp:112] Iteration 1378, lr = 0.01
I0526 01:42:54.057931  5200 solver.cpp:239] Iteration 1404 (1.66891 iter/s, 15.579s/26 iters), loss = 0.0648419
I0526 01:42:54.057986  5200 solver.cpp:258]     Train net output #0: loss = 0.0224009 (* 1 = 0.0224009 loss)
I0526 01:42:54.057993  5200 sgd_solver.cpp:112] Iteration 1404, lr = 0.01
I0526 01:43:09.639693  5200 solver.cpp:239] Iteration 1430 (1.6687 iter/s, 15.581s/26 iters), loss = 0.0839527
I0526 01:43:09.639840  5200 solver.cpp:258]     Train net output #0: loss = 0.128364 (* 1 = 0.128364 loss)
I0526 01:43:09.639848  5200 sgd_solver.cpp:112] Iteration 1430, lr = 0.01
I0526 01:43:25.227830  5200 solver.cpp:239] Iteration 1456 (1.66806 iter/s, 15.587s/26 iters), loss = 0.08253
I0526 01:43:25.227874  5200 solver.cpp:258]     Train net output #0: loss = 0.207122 (* 1 = 0.207122 loss)
I0526 01:43:25.227881  5200 sgd_solver.cpp:112] Iteration 1456, lr = 0.01
I0526 01:43:40.815912  5200 solver.cpp:239] Iteration 1482 (1.66795 iter/s, 15.588s/26 iters), loss = 0.0750677
I0526 01:43:40.816068  5200 solver.cpp:258]     Train net output #0: loss = 0.05899 (* 1 = 0.05899 loss)
I0526 01:43:40.816077  5200 sgd_solver.cpp:112] Iteration 1482, lr = 0.01
I0526 01:43:56.406364  5200 solver.cpp:239] Iteration 1508 (1.66774 iter/s, 15.59s/26 iters), loss = 0.0608129
I0526 01:43:56.406419  5200 solver.cpp:258]     Train net output #0: loss = 0.02394 (* 1 = 0.02394 loss)
I0526 01:43:56.406426  5200 sgd_solver.cpp:112] Iteration 1508, lr = 0.01
I0526 01:44:11.997611  5200 solver.cpp:239] Iteration 1534 (1.66763 iter/s, 15.591s/26 iters), loss = 0.064692
I0526 01:44:11.997776  5200 solver.cpp:258]     Train net output #0: loss = 0.0808688 (* 1 = 0.0808688 loss)
I0526 01:44:11.997783  5200 sgd_solver.cpp:112] Iteration 1534, lr = 0.01
I0526 01:44:14.995148  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_1540.caffemodel
I0526 01:44:14.995815  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_1540.solverstate
I0526 01:44:14.996126  5200 solver.cpp:347] Iteration 1540, Testing net (#0)
I0526 01:44:26.111378  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9808
I0526 01:44:26.111430  5200 solver.cpp:414]     Test net output #1: loss = 0.0562399 (* 1 = 0.0562399 loss)
I0526 01:44:26.111436  5200 solver.cpp:347] Iteration 1540, Testing net (#1)
I0526 01:44:48.155599  5200 solver.cpp:414]     Test net output #0: accuracy = 0.955957
I0526 01:44:48.155756  5200 solver.cpp:414]     Test net output #1: loss = 0.153032 (* 1 = 0.153032 loss)
I0526 01:44:48.155763  5200 solver.cpp:347] Iteration 1540, Testing net (#2)
I0526 01:45:38.365113  5200 solver.cpp:414]     Test net output #0: accuracy = 0.968198
I0526 01:45:38.365260  5200 solver.cpp:414]     Test net output #1: loss = 0.0997352 (* 1 = 0.0997352 loss)
I0526 01:45:50.948511  5200 solver.cpp:239] Iteration 1560 (0.262759 iter/s, 98.95s/26 iters), loss = 0.0610699
I0526 01:45:50.948565  5200 solver.cpp:258]     Train net output #0: loss = 0.0547971 (* 1 = 0.0547971 loss)
I0526 01:45:50.948572  5200 sgd_solver.cpp:112] Iteration 1560, lr = 0.01
I0526 01:46:06.529989  5200 solver.cpp:239] Iteration 1586 (1.6687 iter/s, 15.581s/26 iters), loss = 0.0506743
I0526 01:46:06.530037  5200 solver.cpp:258]     Train net output #0: loss = 0.232432 (* 1 = 0.232432 loss)
I0526 01:46:06.530046  5200 sgd_solver.cpp:112] Iteration 1586, lr = 0.01
I0526 01:46:22.092850  5200 solver.cpp:239] Iteration 1612 (1.67074 iter/s, 15.562s/26 iters), loss = 0.061266
I0526 01:46:22.093004  5200 solver.cpp:258]     Train net output #0: loss = 0.202386 (* 1 = 0.202386 loss)
I0526 01:46:22.093012  5200 sgd_solver.cpp:112] Iteration 1612, lr = 0.01
I0526 01:46:37.652899  5200 solver.cpp:239] Iteration 1638 (1.67106 iter/s, 15.559s/26 iters), loss = 0.0590507
I0526 01:46:37.652953  5200 solver.cpp:258]     Train net output #0: loss = 0.0315357 (* 1 = 0.0315357 loss)
I0526 01:46:37.652961  5200 sgd_solver.cpp:112] Iteration 1638, lr = 0.01
I0526 01:46:53.276623  5200 solver.cpp:239] Iteration 1664 (1.66421 iter/s, 15.623s/26 iters), loss = 0.0453775
I0526 01:46:53.276789  5200 solver.cpp:258]     Train net output #0: loss = 0.0802676 (* 1 = 0.0802676 loss)
I0526 01:46:53.276798  5200 sgd_solver.cpp:112] Iteration 1664, lr = 0.01
I0526 01:47:08.859045  5200 solver.cpp:239] Iteration 1690 (1.66859 iter/s, 15.582s/26 iters), loss = 0.0473237
I0526 01:47:08.859097  5200 solver.cpp:258]     Train net output #0: loss = 0.0923117 (* 1 = 0.0923117 loss)
I0526 01:47:08.859103  5200 sgd_solver.cpp:112] Iteration 1690, lr = 0.01
I0526 01:47:24.419227  5200 solver.cpp:239] Iteration 1716 (1.67095 iter/s, 15.56s/26 iters), loss = 0.0623028
I0526 01:47:24.419379  5200 solver.cpp:258]     Train net output #0: loss = 0.0129689 (* 1 = 0.0129689 loss)
I0526 01:47:24.419387  5200 sgd_solver.cpp:112] Iteration 1716, lr = 0.01
I0526 01:47:39.986577  5200 solver.cpp:239] Iteration 1742 (1.6702 iter/s, 15.567s/26 iters), loss = 0.0564224
I0526 01:47:39.986635  5200 solver.cpp:258]     Train net output #0: loss = 0.0205178 (* 1 = 0.0205178 loss)
I0526 01:47:39.986644  5200 sgd_solver.cpp:112] Iteration 1742, lr = 0.01
I0526 01:47:55.532243  5200 solver.cpp:239] Iteration 1768 (1.67256 iter/s, 15.545s/26 iters), loss = 0.0592144
I0526 01:47:55.532404  5200 solver.cpp:258]     Train net output #0: loss = 0.08902 (* 1 = 0.08902 loss)
I0526 01:47:55.532413  5200 sgd_solver.cpp:112] Iteration 1768, lr = 0.01
I0526 01:48:11.093614  5200 solver.cpp:239] Iteration 1794 (1.67084 iter/s, 15.561s/26 iters), loss = 0.0568104
I0526 01:48:11.093665  5200 solver.cpp:258]     Train net output #0: loss = 0.0115724 (* 1 = 0.0115724 loss)
I0526 01:48:11.093672  5200 sgd_solver.cpp:112] Iteration 1794, lr = 0.01
I0526 01:48:26.650852  5200 solver.cpp:239] Iteration 1820 (1.67127 iter/s, 15.557s/26 iters), loss = 0.0652953
I0526 01:48:26.651018  5200 solver.cpp:258]     Train net output #0: loss = 0.0346727 (* 1 = 0.0346727 loss)
I0526 01:48:26.651027  5200 sgd_solver.cpp:112] Iteration 1820, lr = 0.01
I0526 01:48:42.204104  5200 solver.cpp:239] Iteration 1846 (1.6717 iter/s, 15.553s/26 iters), loss = 0.0485752
I0526 01:48:42.204159  5200 solver.cpp:258]     Train net output #0: loss = 0.00669491 (* 1 = 0.00669491 loss)
I0526 01:48:42.204167  5200 sgd_solver.cpp:112] Iteration 1846, lr = 0.01
I0526 01:48:57.821573  5200 solver.cpp:239] Iteration 1872 (1.66485 iter/s, 15.617s/26 iters), loss = 0.0753189
I0526 01:48:57.821728  5200 solver.cpp:258]     Train net output #0: loss = 0.0755939 (* 1 = 0.0755939 loss)
I0526 01:48:57.821738  5200 sgd_solver.cpp:112] Iteration 1872, lr = 0.01
I0526 01:49:13.375306  5200 solver.cpp:239] Iteration 1898 (1.6717 iter/s, 15.553s/26 iters), loss = 0.0705298
I0526 01:49:13.375360  5200 solver.cpp:258]     Train net output #0: loss = 0.0734389 (* 1 = 0.0734389 loss)
I0526 01:49:13.375366  5200 sgd_solver.cpp:112] Iteration 1898, lr = 0.01
I0526 01:49:28.886783  5200 solver.cpp:239] Iteration 1924 (1.67623 iter/s, 15.511s/26 iters), loss = 0.0996168
I0526 01:49:28.886960  5200 solver.cpp:258]     Train net output #0: loss = 0.0911416 (* 1 = 0.0911416 loss)
I0526 01:49:28.886968  5200 sgd_solver.cpp:112] Iteration 1924, lr = 0.01
I0526 01:49:28.887095  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_1925.caffemodel
I0526 01:49:28.887724  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_1925.solverstate
I0526 01:49:28.888036  5200 solver.cpp:347] Iteration 1925, Testing net (#0)
I0526 01:49:40.039489  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9696
I0526 01:49:40.039541  5200 solver.cpp:414]     Test net output #1: loss = 0.085653 (* 1 = 0.085653 loss)
I0526 01:49:40.039547  5200 solver.cpp:347] Iteration 1925, Testing net (#1)
I0526 01:50:02.423236  5200 solver.cpp:414]     Test net output #0: accuracy = 0.631277
I0526 01:50:02.424634  5200 solver.cpp:414]     Test net output #1: loss = 0.81468 (* 1 = 0.81468 loss)
I0526 01:50:02.424643  5200 solver.cpp:347] Iteration 1925, Testing net (#2)
I0526 01:50:53.096786  5200 solver.cpp:414]     Test net output #0: accuracy = 0.942703
I0526 01:50:53.096956  5200 solver.cpp:414]     Test net output #1: loss = 0.12241 (* 1 = 0.12241 loss)
I0526 01:51:08.737452  5200 solver.cpp:239] Iteration 1950 (0.260391 iter/s, 99.85s/26 iters), loss = 0.0743167
I0526 01:51:08.737504  5200 solver.cpp:258]     Train net output #0: loss = 0.0397346 (* 1 = 0.0397346 loss)
I0526 01:51:08.737514  5200 sgd_solver.cpp:112] Iteration 1950, lr = 0.01
I0526 01:51:24.334365  5200 solver.cpp:239] Iteration 1976 (1.66709 iter/s, 15.596s/26 iters), loss = 0.0562771
I0526 01:51:24.334594  5200 solver.cpp:258]     Train net output #0: loss = 0.00107487 (* 1 = 0.00107487 loss)
I0526 01:51:24.334602  5200 sgd_solver.cpp:112] Iteration 1976, lr = 0.01
I0526 01:51:39.943733  5200 solver.cpp:239] Iteration 2002 (1.66571 iter/s, 15.609s/26 iters), loss = 0.0704664
I0526 01:51:39.943790  5200 solver.cpp:258]     Train net output #0: loss = 0.0181421 (* 1 = 0.0181421 loss)
I0526 01:51:39.943797  5200 sgd_solver.cpp:112] Iteration 2002, lr = 0.01
I0526 01:51:55.586002  5200 solver.cpp:239] Iteration 2028 (1.66219 iter/s, 15.642s/26 iters), loss = 0.0480698
I0526 01:51:55.586203  5200 solver.cpp:258]     Train net output #0: loss = 0.163596 (* 1 = 0.163596 loss)
I0526 01:51:55.586211  5200 sgd_solver.cpp:112] Iteration 2028, lr = 0.01
I0526 01:52:11.203035  5200 solver.cpp:239] Iteration 2054 (1.66496 iter/s, 15.616s/26 iters), loss = 0.0998366
I0526 01:52:11.203088  5200 solver.cpp:258]     Train net output #0: loss = 0.053416 (* 1 = 0.053416 loss)
I0526 01:52:11.203096  5200 sgd_solver.cpp:112] Iteration 2054, lr = 0.01
I0526 01:52:26.807796  5200 solver.cpp:239] Iteration 2080 (1.66624 iter/s, 15.604s/26 iters), loss = 0.0586639
I0526 01:52:26.807996  5200 solver.cpp:258]     Train net output #0: loss = 0.0242316 (* 1 = 0.0242316 loss)
I0526 01:52:26.808003  5200 sgd_solver.cpp:112] Iteration 2080, lr = 0.01
I0526 01:52:42.432147  5200 solver.cpp:239] Iteration 2106 (1.66411 iter/s, 15.624s/26 iters), loss = 0.046647
I0526 01:52:42.432204  5200 solver.cpp:258]     Train net output #0: loss = 0.214271 (* 1 = 0.214271 loss)
I0526 01:52:42.432211  5200 sgd_solver.cpp:112] Iteration 2106, lr = 0.01
I0526 01:52:58.024327  5200 solver.cpp:239] Iteration 2132 (1.66752 iter/s, 15.592s/26 iters), loss = 0.0600671
I0526 01:52:58.024562  5200 solver.cpp:258]     Train net output #0: loss = 0.0380496 (* 1 = 0.0380496 loss)
I0526 01:52:58.024571  5200 sgd_solver.cpp:112] Iteration 2132, lr = 0.01
I0526 01:53:13.838598  5200 solver.cpp:239] Iteration 2158 (1.64411 iter/s, 15.814s/26 iters), loss = 0.0646036
I0526 01:53:13.838652  5200 solver.cpp:258]     Train net output #0: loss = 0.111827 (* 1 = 0.111827 loss)
I0526 01:53:13.838662  5200 sgd_solver.cpp:112] Iteration 2158, lr = 0.01
I0526 01:53:29.655021  5200 solver.cpp:239] Iteration 2184 (1.6439 iter/s, 15.816s/26 iters), loss = 0.0561618
I0526 01:53:29.655148  5200 solver.cpp:258]     Train net output #0: loss = 0.0175787 (* 1 = 0.0175787 loss)
I0526 01:53:29.655164  5200 sgd_solver.cpp:112] Iteration 2184, lr = 0.01
I0526 01:53:45.485779  5200 solver.cpp:239] Iteration 2210 (1.64245 iter/s, 15.83s/26 iters), loss = 0.0646986
I0526 01:53:45.485826  5200 solver.cpp:258]     Train net output #0: loss = 0.0255406 (* 1 = 0.0255406 loss)
I0526 01:53:45.485836  5200 sgd_solver.cpp:112] Iteration 2210, lr = 0.01
I0526 01:54:01.311944  5200 solver.cpp:239] Iteration 2236 (1.64287 iter/s, 15.826s/26 iters), loss = 0.0469203
I0526 01:54:01.312135  5200 solver.cpp:258]     Train net output #0: loss = 0.0597449 (* 1 = 0.0597449 loss)
I0526 01:54:01.312150  5200 sgd_solver.cpp:112] Iteration 2236, lr = 0.01
I0526 01:54:17.115980  5200 solver.cpp:239] Iteration 2262 (1.64526 iter/s, 15.803s/26 iters), loss = 0.0644244
I0526 01:54:17.116030  5200 solver.cpp:258]     Train net output #0: loss = 0.0745351 (* 1 = 0.0745351 loss)
I0526 01:54:17.116040  5200 sgd_solver.cpp:112] Iteration 2262, lr = 0.01
I0526 01:54:32.885777  5200 solver.cpp:239] Iteration 2288 (1.6488 iter/s, 15.769s/26 iters), loss = 0.0603023
I0526 01:54:32.885982  5200 solver.cpp:258]     Train net output #0: loss = 0.0221267 (* 1 = 0.0221267 loss)
I0526 01:54:32.885994  5200 sgd_solver.cpp:112] Iteration 2288, lr = 0.01
I0526 01:54:45.630666  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_2310.caffemodel
I0526 01:54:45.631376  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_2310.solverstate
I0526 01:54:45.631697  5200 solver.cpp:347] Iteration 2310, Testing net (#0)
I0526 01:54:56.919783  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9844
I0526 01:54:56.919829  5200 solver.cpp:414]     Test net output #1: loss = 0.0446423 (* 1 = 0.0446423 loss)
I0526 01:54:56.919839  5200 solver.cpp:347] Iteration 2310, Testing net (#1)
I0526 01:55:19.227385  5200 solver.cpp:414]     Test net output #0: accuracy = 0.882979
I0526 01:55:19.227563  5200 solver.cpp:414]     Test net output #1: loss = 0.31268 (* 1 = 0.31268 loss)
I0526 01:55:19.227578  5200 solver.cpp:347] Iteration 2310, Testing net (#2)
I0526 01:56:09.919704  5200 solver.cpp:414]     Test net output #0: accuracy = 0.974865
I0526 01:56:09.919860  5200 solver.cpp:414]     Test net output #1: loss = 0.0778923 (* 1 = 0.0778923 loss)
I0526 01:56:12.948360  5200 solver.cpp:239] Iteration 2314 (0.259839 iter/s, 100.062s/26 iters), loss = 0.0550715
I0526 01:56:12.948416  5200 solver.cpp:258]     Train net output #0: loss = 0.109714 (* 1 = 0.109714 loss)
I0526 01:56:12.948423  5200 sgd_solver.cpp:112] Iteration 2314, lr = 0.01
I0526 01:56:28.719871  5200 solver.cpp:239] Iteration 2340 (1.6486 iter/s, 15.771s/26 iters), loss = 0.0360488
I0526 01:56:28.719926  5200 solver.cpp:258]     Train net output #0: loss = 0.106426 (* 1 = 0.106426 loss)
I0526 01:56:28.719934  5200 sgd_solver.cpp:112] Iteration 2340, lr = 0.01
I0526 01:56:44.694061  5200 solver.cpp:239] Iteration 2366 (1.62764 iter/s, 15.974s/26 iters), loss = 0.0909619
I0526 01:56:44.694219  5200 solver.cpp:258]     Train net output #0: loss = 0.0192131 (* 1 = 0.0192131 loss)
I0526 01:56:44.694228  5200 sgd_solver.cpp:112] Iteration 2366, lr = 0.01
I0526 01:57:00.535972  5200 solver.cpp:239] Iteration 2392 (1.64131 iter/s, 15.841s/26 iters), loss = 0.0560913
I0526 01:57:00.536026  5200 solver.cpp:258]     Train net output #0: loss = 0.0960002 (* 1 = 0.0960002 loss)
I0526 01:57:00.536032  5200 sgd_solver.cpp:112] Iteration 2392, lr = 0.01
I0526 01:57:16.378087  5200 solver.cpp:239] Iteration 2418 (1.64121 iter/s, 15.842s/26 iters), loss = 0.0596776
I0526 01:57:16.378334  5200 solver.cpp:258]     Train net output #0: loss = 0.0883291 (* 1 = 0.0883291 loss)
I0526 01:57:16.378341  5200 sgd_solver.cpp:112] Iteration 2418, lr = 0.01
I0526 01:57:32.216446  5200 solver.cpp:239] Iteration 2444 (1.64162 iter/s, 15.838s/26 iters), loss = 0.0432087
I0526 01:57:32.216500  5200 solver.cpp:258]     Train net output #0: loss = 0.0700784 (* 1 = 0.0700784 loss)
I0526 01:57:32.216507  5200 sgd_solver.cpp:112] Iteration 2444, lr = 0.01
I0526 01:57:48.035918  5200 solver.cpp:239] Iteration 2470 (1.64359 iter/s, 15.819s/26 iters), loss = 0.0473886
I0526 01:57:48.036113  5200 solver.cpp:258]     Train net output #0: loss = 0.0544587 (* 1 = 0.0544587 loss)
I0526 01:57:48.036123  5200 sgd_solver.cpp:112] Iteration 2470, lr = 0.01
I0526 01:58:03.877185  5200 solver.cpp:239] Iteration 2496 (1.64131 iter/s, 15.841s/26 iters), loss = 0.0449144
I0526 01:58:03.877243  5200 solver.cpp:258]     Train net output #0: loss = 0.00740548 (* 1 = 0.00740548 loss)
I0526 01:58:03.877249  5200 sgd_solver.cpp:112] Iteration 2496, lr = 0.01
I0526 01:58:19.727689  5200 solver.cpp:239] Iteration 2522 (1.64038 iter/s, 15.85s/26 iters), loss = 0.0692472
I0526 01:58:19.727820  5200 solver.cpp:258]     Train net output #0: loss = 0.0294814 (* 1 = 0.0294814 loss)
I0526 01:58:19.727839  5200 sgd_solver.cpp:112] Iteration 2522, lr = 0.01
I0526 01:58:35.582991  5200 solver.cpp:239] Iteration 2548 (1.63986 iter/s, 15.855s/26 iters), loss = 0.0499647
I0526 01:58:35.583043  5200 solver.cpp:258]     Train net output #0: loss = 0.0631841 (* 1 = 0.0631841 loss)
I0526 01:58:35.583050  5200 sgd_solver.cpp:112] Iteration 2548, lr = 0.01
I0526 01:58:51.417718  5200 solver.cpp:239] Iteration 2574 (1.64204 iter/s, 15.834s/26 iters), loss = 0.0370372
I0526 01:58:51.417912  5200 solver.cpp:258]     Train net output #0: loss = 0.0156665 (* 1 = 0.0156665 loss)
I0526 01:58:51.417920  5200 sgd_solver.cpp:112] Iteration 2574, lr = 0.01
I0526 01:59:07.275840  5200 solver.cpp:239] Iteration 2600 (1.63965 iter/s, 15.857s/26 iters), loss = 0.0236753
I0526 01:59:07.275893  5200 solver.cpp:258]     Train net output #0: loss = 0.0174371 (* 1 = 0.0174371 loss)
I0526 01:59:07.275900  5200 sgd_solver.cpp:112] Iteration 2600, lr = 0.01
I0526 01:59:23.110087  5200 solver.cpp:239] Iteration 2626 (1.64204 iter/s, 15.834s/26 iters), loss = 0.0731126
I0526 01:59:23.110249  5200 solver.cpp:258]     Train net output #0: loss = 0.0602693 (* 1 = 0.0602693 loss)
I0526 01:59:23.110267  5200 sgd_solver.cpp:112] Iteration 2626, lr = 0.01
I0526 01:59:38.932791  5200 solver.cpp:239] Iteration 2652 (1.64328 iter/s, 15.822s/26 iters), loss = 0.0396723
I0526 01:59:38.932845  5200 solver.cpp:258]     Train net output #0: loss = 0.0634458 (* 1 = 0.0634458 loss)
I0526 01:59:38.932853  5200 sgd_solver.cpp:112] Iteration 2652, lr = 0.01
I0526 01:59:54.729650  5200 solver.cpp:239] Iteration 2678 (1.64599 iter/s, 15.796s/26 iters), loss = 0.0333507
I0526 01:59:54.729837  5200 solver.cpp:258]     Train net output #0: loss = 0.0841645 (* 1 = 0.0841645 loss)
I0526 01:59:54.729846  5200 sgd_solver.cpp:112] Iteration 2678, lr = 0.01
I0526 02:00:04.469326  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_2695.caffemodel
I0526 02:00:04.470074  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_2695.solverstate
I0526 02:00:04.470422  5200 solver.cpp:347] Iteration 2695, Testing net (#0)
I0526 02:00:15.672542  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9904
I0526 02:00:15.672578  5200 solver.cpp:414]     Test net output #1: loss = 0.0269785 (* 1 = 0.0269785 loss)
I0526 02:00:15.672585  5200 solver.cpp:347] Iteration 2695, Testing net (#1)
I0526 02:00:37.439230  5200 solver.cpp:414]     Test net output #0: accuracy = 0.784894
I0526 02:00:37.439369  5200 solver.cpp:414]     Test net output #1: loss = 0.71406 (* 1 = 0.71406 loss)
I0526 02:00:37.439391  5200 solver.cpp:347] Iteration 2695, Testing net (#2)
I0526 02:01:28.001364  5200 solver.cpp:414]     Test net output #0: accuracy = 0.972973
I0526 02:01:28.001610  5200 solver.cpp:414]     Test net output #1: loss = 0.0731886 (* 1 = 0.0731886 loss)
I0526 02:01:34.010994  5200 solver.cpp:239] Iteration 2704 (0.261883 iter/s, 99.281s/26 iters), loss = 0.0318218
I0526 02:01:34.011040  5200 solver.cpp:258]     Train net output #0: loss = 0.0114922 (* 1 = 0.0114922 loss)
I0526 02:01:34.011049  5200 sgd_solver.cpp:112] Iteration 2704, lr = 0.01
I0526 02:01:49.669613  5200 solver.cpp:239] Iteration 2730 (1.66049 iter/s, 15.658s/26 iters), loss = 0.0481517
I0526 02:01:49.669661  5200 solver.cpp:258]     Train net output #0: loss = 0.0486412 (* 1 = 0.0486412 loss)
I0526 02:01:49.669668  5200 sgd_solver.cpp:112] Iteration 2730, lr = 0.01
I0526 02:02:05.309911  5200 solver.cpp:239] Iteration 2756 (1.6624 iter/s, 15.64s/26 iters), loss = 0.0371104
I0526 02:02:05.310070  5200 solver.cpp:258]     Train net output #0: loss = 0.112173 (* 1 = 0.112173 loss)
I0526 02:02:05.310083  5200 sgd_solver.cpp:112] Iteration 2756, lr = 0.01
I0526 02:02:20.935359  5200 solver.cpp:239] Iteration 2782 (1.664 iter/s, 15.625s/26 iters), loss = 0.0378794
I0526 02:02:20.935406  5200 solver.cpp:258]     Train net output #0: loss = 0.0166854 (* 1 = 0.0166854 loss)
I0526 02:02:20.935417  5200 sgd_solver.cpp:112] Iteration 2782, lr = 0.01
I0526 02:02:36.551843  5200 solver.cpp:239] Iteration 2808 (1.66496 iter/s, 15.616s/26 iters), loss = 0.0439727
I0526 02:02:36.552031  5200 solver.cpp:258]     Train net output #0: loss = 0.00904527 (* 1 = 0.00904527 loss)
I0526 02:02:36.552039  5200 sgd_solver.cpp:112] Iteration 2808, lr = 0.01
I0526 02:02:52.124395  5200 solver.cpp:239] Iteration 2834 (1.66966 iter/s, 15.572s/26 iters), loss = 0.0366563
I0526 02:02:52.124450  5200 solver.cpp:258]     Train net output #0: loss = 0.00763113 (* 1 = 0.00763113 loss)
I0526 02:02:52.124457  5200 sgd_solver.cpp:112] Iteration 2834, lr = 0.01
I0526 02:03:07.752842  5200 solver.cpp:239] Iteration 2860 (1.66368 iter/s, 15.628s/26 iters), loss = 0.0384268
I0526 02:03:07.753064  5200 solver.cpp:258]     Train net output #0: loss = 0.0471214 (* 1 = 0.0471214 loss)
I0526 02:03:07.753073  5200 sgd_solver.cpp:112] Iteration 2860, lr = 0.01
I0526 02:03:23.382958  5200 solver.cpp:239] Iteration 2886 (1.66357 iter/s, 15.629s/26 iters), loss = 0.0290159
I0526 02:03:23.383013  5200 solver.cpp:258]     Train net output #0: loss = 0.00673461 (* 1 = 0.00673461 loss)
I0526 02:03:23.383020  5200 sgd_solver.cpp:112] Iteration 2886, lr = 0.01
I0526 02:03:39.013617  5200 solver.cpp:239] Iteration 2912 (1.66347 iter/s, 15.63s/26 iters), loss = 0.0293464
I0526 02:03:39.013861  5200 solver.cpp:258]     Train net output #0: loss = 0.134782 (* 1 = 0.134782 loss)
I0526 02:03:39.013870  5200 sgd_solver.cpp:112] Iteration 2912, lr = 0.01
I0526 02:03:54.637867  5200 solver.cpp:239] Iteration 2938 (1.66411 iter/s, 15.624s/26 iters), loss = 0.0325408
I0526 02:03:54.637923  5200 solver.cpp:258]     Train net output #0: loss = 0.080153 (* 1 = 0.080153 loss)
I0526 02:03:54.637929  5200 sgd_solver.cpp:112] Iteration 2938, lr = 0.01
I0526 02:04:10.274703  5200 solver.cpp:239] Iteration 2964 (1.66283 iter/s, 15.636s/26 iters), loss = 0.0208144
I0526 02:04:10.274945  5200 solver.cpp:258]     Train net output #0: loss = 0.00589372 (* 1 = 0.00589372 loss)
I0526 02:04:10.274955  5200 sgd_solver.cpp:112] Iteration 2964, lr = 0.01
I0526 02:04:25.910099  5200 solver.cpp:239] Iteration 2990 (1.66294 iter/s, 15.635s/26 iters), loss = 0.0433457
I0526 02:04:25.910156  5200 solver.cpp:258]     Train net output #0: loss = 0.0114674 (* 1 = 0.0114674 loss)
I0526 02:04:25.910164  5200 sgd_solver.cpp:112] Iteration 2990, lr = 0.01
I0526 02:04:41.524907  5200 solver.cpp:239] Iteration 3016 (1.66517 iter/s, 15.614s/26 iters), loss = 0.0272741
I0526 02:04:41.525094  5200 solver.cpp:258]     Train net output #0: loss = 0.07072 (* 1 = 0.07072 loss)
I0526 02:04:41.525102  5200 sgd_solver.cpp:112] Iteration 3016, lr = 0.01
I0526 02:04:57.133723  5200 solver.cpp:239] Iteration 3042 (1.66581 iter/s, 15.608s/26 iters), loss = 0.04297
I0526 02:04:57.133776  5200 solver.cpp:258]     Train net output #0: loss = 0.213845 (* 1 = 0.213845 loss)
I0526 02:04:57.133783  5200 sgd_solver.cpp:112] Iteration 3042, lr = 0.01
I0526 02:05:12.763105  5200 solver.cpp:239] Iteration 3068 (1.66357 iter/s, 15.629s/26 iters), loss = 0.0336564
I0526 02:05:12.763345  5200 solver.cpp:258]     Train net output #0: loss = 0.0181782 (* 1 = 0.0181782 loss)
I0526 02:05:12.763355  5200 sgd_solver.cpp:112] Iteration 3068, lr = 0.01
I0526 02:05:19.371429  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_3080.caffemodel
I0526 02:05:19.372093  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_3080.solverstate
I0526 02:05:19.372404  5200 solver.cpp:347] Iteration 3080, Testing net (#0)
I0526 02:05:30.411768  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9872
I0526 02:05:30.411820  5200 solver.cpp:414]     Test net output #1: loss = 0.0419118 (* 1 = 0.0419118 loss)
I0526 02:05:30.411825  5200 solver.cpp:347] Iteration 3080, Testing net (#1)
I0526 02:05:51.997774  5200 solver.cpp:414]     Test net output #0: accuracy = 0.879787
I0526 02:05:51.999712  5200 solver.cpp:414]     Test net output #1: loss = 0.353259 (* 1 = 0.353259 loss)
I0526 02:05:51.999720  5200 solver.cpp:347] Iteration 3080, Testing net (#2)
I0526 02:06:42.610683  5200 solver.cpp:414]     Test net output #0: accuracy = 0.972343
I0526 02:06:42.610865  5200 solver.cpp:414]     Test net output #1: loss = 0.0810475 (* 1 = 0.0810475 loss)
I0526 02:06:51.638078  5200 solver.cpp:239] Iteration 3094 (0.262961 iter/s, 98.874s/26 iters), loss = 0.0391689
I0526 02:06:51.638136  5200 solver.cpp:258]     Train net output #0: loss = 0.096123 (* 1 = 0.096123 loss)
I0526 02:06:51.638144  5200 sgd_solver.cpp:112] Iteration 3094, lr = 0.01
I0526 02:07:07.443362  5200 solver.cpp:239] Iteration 3120 (1.64505 iter/s, 15.805s/26 iters), loss = 0.044739
I0526 02:07:07.443414  5200 solver.cpp:258]     Train net output #0: loss = 0.0360756 (* 1 = 0.0360756 loss)
I0526 02:07:07.443421  5200 sgd_solver.cpp:112] Iteration 3120, lr = 0.01
I0526 02:07:23.237030  5200 solver.cpp:239] Iteration 3146 (1.6463 iter/s, 15.793s/26 iters), loss = 0.0352165
I0526 02:07:23.237215  5200 solver.cpp:258]     Train net output #0: loss = 0.0298547 (* 1 = 0.0298547 loss)
I0526 02:07:23.237232  5200 sgd_solver.cpp:112] Iteration 3146, lr = 0.01
I0526 02:07:39.028431  5200 solver.cpp:239] Iteration 3172 (1.64651 iter/s, 15.791s/26 iters), loss = 0.0363287
I0526 02:07:39.028486  5200 solver.cpp:258]     Train net output #0: loss = 0.017277 (* 1 = 0.017277 loss)
I0526 02:07:39.028494  5200 sgd_solver.cpp:112] Iteration 3172, lr = 0.01
I0526 02:07:54.814558  5200 solver.cpp:239] Iteration 3198 (1.64703 iter/s, 15.786s/26 iters), loss = 0.0437172
I0526 02:07:54.814721  5200 solver.cpp:258]     Train net output #0: loss = 0.0266406 (* 1 = 0.0266406 loss)
I0526 02:07:54.814729  5200 sgd_solver.cpp:112] Iteration 3198, lr = 0.01
I0526 02:08:10.641108  5200 solver.cpp:239] Iteration 3224 (1.64287 iter/s, 15.826s/26 iters), loss = 0.0397895
I0526 02:08:10.641165  5200 solver.cpp:258]     Train net output #0: loss = 0.0038674 (* 1 = 0.0038674 loss)
I0526 02:08:10.641172  5200 sgd_solver.cpp:112] Iteration 3224, lr = 0.01
I0526 02:08:26.476261  5200 solver.cpp:239] Iteration 3250 (1.64193 iter/s, 15.835s/26 iters), loss = 0.0316834
I0526 02:08:26.476431  5200 solver.cpp:258]     Train net output #0: loss = 0.00161413 (* 1 = 0.00161413 loss)
I0526 02:08:26.476440  5200 sgd_solver.cpp:112] Iteration 3250, lr = 0.01
I0526 02:08:42.265178  5200 solver.cpp:239] Iteration 3276 (1.64682 iter/s, 15.788s/26 iters), loss = 0.0260326
I0526 02:08:42.265233  5200 solver.cpp:258]     Train net output #0: loss = 0.0309173 (* 1 = 0.0309173 loss)
I0526 02:08:42.265239  5200 sgd_solver.cpp:112] Iteration 3276, lr = 0.01
I0526 02:08:58.067505  5200 solver.cpp:239] Iteration 3302 (1.64536 iter/s, 15.802s/26 iters), loss = 0.0365314
I0526 02:08:58.067644  5200 solver.cpp:258]     Train net output #0: loss = 0.141533 (* 1 = 0.141533 loss)
I0526 02:08:58.067653  5200 sgd_solver.cpp:112] Iteration 3302, lr = 0.01
I0526 02:09:13.888511  5200 solver.cpp:239] Iteration 3328 (1.64349 iter/s, 15.82s/26 iters), loss = 0.0251653
I0526 02:09:13.888562  5200 solver.cpp:258]     Train net output #0: loss = 0.104654 (* 1 = 0.104654 loss)
I0526 02:09:13.888571  5200 sgd_solver.cpp:112] Iteration 3328, lr = 0.01
I0526 02:09:29.680029  5200 solver.cpp:239] Iteration 3354 (1.64651 iter/s, 15.791s/26 iters), loss = 0.0254501
I0526 02:09:29.680191  5200 solver.cpp:258]     Train net output #0: loss = 0.012684 (* 1 = 0.012684 loss)
I0526 02:09:29.680199  5200 sgd_solver.cpp:112] Iteration 3354, lr = 0.01
I0526 02:09:45.489555  5200 solver.cpp:239] Iteration 3380 (1.64463 iter/s, 15.809s/26 iters), loss = 0.0311533
I0526 02:09:45.489612  5200 solver.cpp:258]     Train net output #0: loss = 0.0500354 (* 1 = 0.0500354 loss)
I0526 02:09:45.489620  5200 sgd_solver.cpp:112] Iteration 3380, lr = 0.01
I0526 02:10:01.280089  5200 solver.cpp:239] Iteration 3406 (1.64661 iter/s, 15.79s/26 iters), loss = 0.0382187
I0526 02:10:01.280246  5200 solver.cpp:258]     Train net output #0: loss = 0.00999463 (* 1 = 0.00999463 loss)
I0526 02:10:01.280254  5200 sgd_solver.cpp:112] Iteration 3406, lr = 0.01
I0526 02:10:17.058434  5200 solver.cpp:239] Iteration 3432 (1.64786 iter/s, 15.778s/26 iters), loss = 0.036482
I0526 02:10:17.058491  5200 solver.cpp:258]     Train net output #0: loss = 0.0224941 (* 1 = 0.0224941 loss)
I0526 02:10:17.058499  5200 sgd_solver.cpp:112] Iteration 3432, lr = 0.01
I0526 02:10:32.844040  5200 solver.cpp:239] Iteration 3458 (1.64713 iter/s, 15.785s/26 iters), loss = 0.0306412
I0526 02:10:32.844224  5200 solver.cpp:258]     Train net output #0: loss = 0.0116437 (* 1 = 0.0116437 loss)
I0526 02:10:32.844233  5200 sgd_solver.cpp:112] Iteration 3458, lr = 0.01
I0526 02:10:36.488647  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_3465.caffemodel
I0526 02:10:36.489318  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_3465.solverstate
I0526 02:10:36.489629  5200 solver.cpp:347] Iteration 3465, Testing net (#0)
I0526 02:10:47.731962  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9904
I0526 02:10:47.732017  5200 solver.cpp:414]     Test net output #1: loss = 0.0237997 (* 1 = 0.0237997 loss)
I0526 02:10:47.732023  5200 solver.cpp:347] Iteration 3465, Testing net (#1)
I0526 02:11:10.152832  5200 solver.cpp:414]     Test net output #0: accuracy = 0.761277
I0526 02:11:10.152988  5200 solver.cpp:414]     Test net output #1: loss = 0.85994 (* 1 = 0.85994 loss)
I0526 02:11:10.152997  5200 solver.cpp:347] Iteration 3465, Testing net (#2)
I0526 02:12:00.806180  5200 solver.cpp:414]     Test net output #0: accuracy = 0.976126
I0526 02:12:00.806330  5200 solver.cpp:414]     Test net output #1: loss = 0.0622328 (* 1 = 0.0622328 loss)
I0526 02:12:12.767730  5200 solver.cpp:239] Iteration 3484 (0.2602 iter/s, 99.923s/26 iters), loss = 0.0335565
I0526 02:12:12.767782  5200 solver.cpp:258]     Train net output #0: loss = 0.00331221 (* 1 = 0.00331221 loss)
I0526 02:12:12.767789  5200 sgd_solver.cpp:112] Iteration 3484, lr = 0.01
I0526 02:12:28.310158  5200 solver.cpp:239] Iteration 3510 (1.67289 iter/s, 15.542s/26 iters), loss = 0.0216732
I0526 02:12:28.310218  5200 solver.cpp:258]     Train net output #0: loss = 0.0439611 (* 1 = 0.0439611 loss)
I0526 02:12:28.310225  5200 sgd_solver.cpp:112] Iteration 3510, lr = 0.01
I0526 02:12:43.847095  5200 solver.cpp:239] Iteration 3536 (1.67353 iter/s, 15.536s/26 iters), loss = 0.0253706
I0526 02:12:43.847249  5200 solver.cpp:258]     Train net output #0: loss = 0.0239947 (* 1 = 0.0239947 loss)
I0526 02:12:43.847256  5200 sgd_solver.cpp:112] Iteration 3536, lr = 0.01
I0526 02:12:59.383219  5200 solver.cpp:239] Iteration 3562 (1.67364 iter/s, 15.535s/26 iters), loss = 0.0463389
I0526 02:12:59.383275  5200 solver.cpp:258]     Train net output #0: loss = 0.0335883 (* 1 = 0.0335883 loss)
I0526 02:12:59.383283  5200 sgd_solver.cpp:112] Iteration 3562, lr = 0.01
I0526 02:13:14.945452  5200 solver.cpp:239] Iteration 3588 (1.67074 iter/s, 15.562s/26 iters), loss = 0.0467052
I0526 02:13:14.945621  5200 solver.cpp:258]     Train net output #0: loss = 0.044911 (* 1 = 0.044911 loss)
I0526 02:13:14.945628  5200 sgd_solver.cpp:112] Iteration 3588, lr = 0.01
I0526 02:13:30.501381  5200 solver.cpp:239] Iteration 3614 (1.67149 iter/s, 15.555s/26 iters), loss = 0.0313836
I0526 02:13:30.501437  5200 solver.cpp:258]     Train net output #0: loss = 0.0896825 (* 1 = 0.0896825 loss)
I0526 02:13:30.501444  5200 sgd_solver.cpp:112] Iteration 3614, lr = 0.01
I0526 02:13:46.064791  5200 solver.cpp:239] Iteration 3640 (1.67063 iter/s, 15.563s/26 iters), loss = 0.020298
I0526 02:13:46.064960  5200 solver.cpp:258]     Train net output #0: loss = 0.00763238 (* 1 = 0.00763238 loss)
I0526 02:13:46.064967  5200 sgd_solver.cpp:112] Iteration 3640, lr = 0.01
I0526 02:14:01.622602  5200 solver.cpp:239] Iteration 3666 (1.67127 iter/s, 15.557s/26 iters), loss = 0.0145691
I0526 02:14:01.622660  5200 solver.cpp:258]     Train net output #0: loss = 0.0134476 (* 1 = 0.0134476 loss)
I0526 02:14:01.622668  5200 sgd_solver.cpp:112] Iteration 3666, lr = 0.01
I0526 02:14:17.182590  5200 solver.cpp:239] Iteration 3692 (1.67106 iter/s, 15.559s/26 iters), loss = 0.0407876
I0526 02:14:17.182761  5200 solver.cpp:258]     Train net output #0: loss = 0.0109829 (* 1 = 0.0109829 loss)
I0526 02:14:17.182770  5200 sgd_solver.cpp:112] Iteration 3692, lr = 0.01
I0526 02:14:32.736624  5200 solver.cpp:239] Iteration 3718 (1.6717 iter/s, 15.553s/26 iters), loss = 0.0250957
I0526 02:14:32.736678  5200 solver.cpp:258]     Train net output #0: loss = 0.00229303 (* 1 = 0.00229303 loss)
I0526 02:14:32.736686  5200 sgd_solver.cpp:112] Iteration 3718, lr = 0.01
I0526 02:14:48.317773  5200 solver.cpp:239] Iteration 3744 (1.6687 iter/s, 15.581s/26 iters), loss = 0.0355162
I0526 02:14:48.317955  5200 solver.cpp:258]     Train net output #0: loss = 0.0948758 (* 1 = 0.0948758 loss)
I0526 02:14:48.317963  5200 sgd_solver.cpp:112] Iteration 3744, lr = 0.01
I0526 02:15:03.899785  5200 solver.cpp:239] Iteration 3770 (1.6687 iter/s, 15.581s/26 iters), loss = 0.0245079
I0526 02:15:03.899837  5200 solver.cpp:258]     Train net output #0: loss = 0.00690145 (* 1 = 0.00690145 loss)
I0526 02:15:03.899845  5200 sgd_solver.cpp:112] Iteration 3770, lr = 0.01
I0526 02:15:19.461514  5200 solver.cpp:239] Iteration 3796 (1.67084 iter/s, 15.561s/26 iters), loss = 0.0261651
I0526 02:15:19.461751  5200 solver.cpp:258]     Train net output #0: loss = 0.0232314 (* 1 = 0.0232314 loss)
I0526 02:15:19.461760  5200 sgd_solver.cpp:112] Iteration 3796, lr = 0.01
I0526 02:15:35.043090  5200 solver.cpp:239] Iteration 3822 (1.6687 iter/s, 15.581s/26 iters), loss = 0.0284732
I0526 02:15:35.043146  5200 solver.cpp:258]     Train net output #0: loss = 0.141064 (* 1 = 0.141064 loss)
I0526 02:15:35.043154  5200 sgd_solver.cpp:112] Iteration 3822, lr = 0.01
I0526 02:15:50.629874  5200 solver.cpp:239] Iteration 3848 (1.66816 iter/s, 15.586s/26 iters), loss = 0.0119921
I0526 02:15:50.630028  5200 solver.cpp:258]     Train net output #0: loss = 0.0228628 (* 1 = 0.0228628 loss)
I0526 02:15:50.630036  5200 sgd_solver.cpp:112] Iteration 3848, lr = 0.01
I0526 02:15:51.230923  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_3850.caffemodel
I0526 02:15:51.231617  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_3850.solverstate
I0526 02:15:51.231930  5200 solver.cpp:347] Iteration 3850, Testing net (#0)
I0526 02:16:02.239626  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9896
I0526 02:16:02.239675  5200 solver.cpp:414]     Test net output #1: loss = 0.0256984 (* 1 = 0.0256984 loss)
I0526 02:16:02.239679  5200 solver.cpp:347] Iteration 3850, Testing net (#1)
I0526 02:16:23.805397  5200 solver.cpp:414]     Test net output #0: accuracy = 0.765319
I0526 02:16:23.805533  5200 solver.cpp:414]     Test net output #1: loss = 1.01516 (* 1 = 1.01516 loss)
I0526 02:16:23.805539  5200 solver.cpp:347] Iteration 3850, Testing net (#2)
I0526 02:17:14.672652  5200 solver.cpp:414]     Test net output #0: accuracy = 0.980181
I0526 02:17:14.672804  5200 solver.cpp:414]     Test net output #1: loss = 0.0655104 (* 1 = 0.0655104 loss)
I0526 02:17:29.693553  5200 solver.cpp:239] Iteration 3874 (0.262459 iter/s, 99.063s/26 iters), loss = 0.0236723
I0526 02:17:29.693615  5200 solver.cpp:258]     Train net output #0: loss = 0.0111135 (* 1 = 0.0111135 loss)
I0526 02:17:29.693622  5200 sgd_solver.cpp:112] Iteration 3874, lr = 0.01
I0526 02:17:45.272934  5200 solver.cpp:239] Iteration 3900 (1.66891 iter/s, 15.579s/26 iters), loss = 0.0308745
I0526 02:17:45.273036  5200 solver.cpp:258]     Train net output #0: loss = 0.0389555 (* 1 = 0.0389555 loss)
I0526 02:17:45.273043  5200 sgd_solver.cpp:112] Iteration 3900, lr = 0.01
I0526 02:18:00.868361  5200 solver.cpp:239] Iteration 3926 (1.6672 iter/s, 15.595s/26 iters), loss = 0.0218154
I0526 02:18:00.868415  5200 solver.cpp:258]     Train net output #0: loss = 0.0136973 (* 1 = 0.0136973 loss)
I0526 02:18:00.868422  5200 sgd_solver.cpp:112] Iteration 3926, lr = 0.01
I0526 02:18:16.483319  5200 solver.cpp:239] Iteration 3952 (1.66517 iter/s, 15.614s/26 iters), loss = 0.0188619
I0526 02:18:16.483480  5200 solver.cpp:258]     Train net output #0: loss = 0.00201962 (* 1 = 0.00201962 loss)
I0526 02:18:16.483489  5200 sgd_solver.cpp:112] Iteration 3952, lr = 0.01
I0526 02:18:32.079605  5200 solver.cpp:239] Iteration 3978 (1.66709 iter/s, 15.596s/26 iters), loss = 0.0245164
I0526 02:18:32.079658  5200 solver.cpp:258]     Train net output #0: loss = 0.0425794 (* 1 = 0.0425794 loss)
I0526 02:18:32.079666  5200 sgd_solver.cpp:112] Iteration 3978, lr = 0.01
I0526 02:18:47.674741  5200 solver.cpp:239] Iteration 4004 (1.6672 iter/s, 15.595s/26 iters), loss = 0.0162589
I0526 02:18:47.674928  5200 solver.cpp:258]     Train net output #0: loss = 0.00169819 (* 1 = 0.00169819 loss)
I0526 02:18:47.674937  5200 sgd_solver.cpp:112] Iteration 4004, lr = 0.01
I0526 02:19:03.280210  5200 solver.cpp:239] Iteration 4030 (1.66613 iter/s, 15.605s/26 iters), loss = 0.0312856
I0526 02:19:03.280262  5200 solver.cpp:258]     Train net output #0: loss = 0.0304031 (* 1 = 0.0304031 loss)
I0526 02:19:03.280270  5200 sgd_solver.cpp:112] Iteration 4030, lr = 0.01
I0526 02:19:18.884174  5200 solver.cpp:239] Iteration 4056 (1.66635 iter/s, 15.603s/26 iters), loss = 0.132674
I0526 02:19:18.884315  5200 solver.cpp:258]     Train net output #0: loss = 0.0611701 (* 1 = 0.0611701 loss)
I0526 02:19:18.884322  5200 sgd_solver.cpp:112] Iteration 4056, lr = 0.01
I0526 02:19:34.516885  5200 solver.cpp:239] Iteration 4082 (1.66325 iter/s, 15.632s/26 iters), loss = 0.0920785
I0526 02:19:34.516937  5200 solver.cpp:258]     Train net output #0: loss = 0.068058 (* 1 = 0.068058 loss)
I0526 02:19:34.516943  5200 sgd_solver.cpp:112] Iteration 4082, lr = 0.01
I0526 02:19:50.150909  5200 solver.cpp:239] Iteration 4108 (1.66315 iter/s, 15.633s/26 iters), loss = 0.0391518
I0526 02:19:50.151075  5200 solver.cpp:258]     Train net output #0: loss = 0.0189856 (* 1 = 0.0189856 loss)
I0526 02:19:50.151083  5200 sgd_solver.cpp:112] Iteration 4108, lr = 0.01
I0526 02:20:05.784060  5200 solver.cpp:239] Iteration 4134 (1.66325 iter/s, 15.632s/26 iters), loss = 0.0247342
I0526 02:20:05.784111  5200 solver.cpp:258]     Train net output #0: loss = 0.0342808 (* 1 = 0.0342808 loss)
I0526 02:20:05.784118  5200 sgd_solver.cpp:112] Iteration 4134, lr = 0.01
I0526 02:20:21.397862  5200 solver.cpp:239] Iteration 4160 (1.66528 iter/s, 15.613s/26 iters), loss = 0.0299204
I0526 02:20:21.398002  5200 solver.cpp:258]     Train net output #0: loss = 0.0263353 (* 1 = 0.0263353 loss)
I0526 02:20:21.398011  5200 sgd_solver.cpp:112] Iteration 4160, lr = 0.01
I0526 02:20:36.970106  5200 solver.cpp:239] Iteration 4186 (1.66966 iter/s, 15.572s/26 iters), loss = 0.0280161
I0526 02:20:36.970162  5200 solver.cpp:258]     Train net output #0: loss = 0.151362 (* 1 = 0.151362 loss)
I0526 02:20:36.970170  5200 sgd_solver.cpp:112] Iteration 4186, lr = 0.01
I0526 02:20:52.519858  5200 solver.cpp:239] Iteration 4212 (1.67213 iter/s, 15.549s/26 iters), loss = 0.0398851
I0526 02:20:52.520013  5200 solver.cpp:258]     Train net output #0: loss = 0.00435576 (* 1 = 0.00435576 loss)
I0526 02:20:52.520021  5200 sgd_solver.cpp:112] Iteration 4212, lr = 0.01
I0526 02:21:05.780786  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_4235.caffemodel
I0526 02:21:05.781450  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_4235.solverstate
I0526 02:21:05.781764  5200 solver.cpp:347] Iteration 4235, Testing net (#0)
I0526 02:21:16.904479  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9944
I0526 02:21:16.904531  5200 solver.cpp:414]     Test net output #1: loss = 0.0174417 (* 1 = 0.0174417 loss)
I0526 02:21:16.904537  5200 solver.cpp:347] Iteration 4235, Testing net (#1)
I0526 02:21:39.010514  5200 solver.cpp:414]     Test net output #0: accuracy = 0.827021
I0526 02:21:39.010673  5200 solver.cpp:414]     Test net output #1: loss = 0.495312 (* 1 = 0.495312 loss)
I0526 02:21:39.010681  5200 solver.cpp:347] Iteration 4235, Testing net (#2)
I0526 02:22:29.125607  5200 solver.cpp:414]     Test net output #0: accuracy = 0.984054
I0526 02:22:29.125753  5200 solver.cpp:414]     Test net output #1: loss = 0.0506751 (* 1 = 0.0506751 loss)
I0526 02:22:31.520947  5200 solver.cpp:239] Iteration 4238 (0.262626 iter/s, 99s/26 iters), loss = 0.0194974
I0526 02:22:31.520996  5200 solver.cpp:258]     Train net output #0: loss = 0.0393888 (* 1 = 0.0393888 loss)
I0526 02:22:31.521004  5200 sgd_solver.cpp:112] Iteration 4238, lr = 0.01
I0526 02:22:47.076150  5200 solver.cpp:239] Iteration 4264 (1.67149 iter/s, 15.555s/26 iters), loss = 0.034085
I0526 02:22:47.076205  5200 solver.cpp:258]     Train net output #0: loss = 0.0328529 (* 1 = 0.0328529 loss)
I0526 02:22:47.076211  5200 sgd_solver.cpp:112] Iteration 4264, lr = 0.01
I0526 02:23:02.629549  5200 solver.cpp:239] Iteration 4290 (1.6717 iter/s, 15.553s/26 iters), loss = 0.0257256
I0526 02:23:02.629746  5200 solver.cpp:258]     Train net output #0: loss = 0.0056137 (* 1 = 0.0056137 loss)
I0526 02:23:02.629755  5200 sgd_solver.cpp:112] Iteration 4290, lr = 0.01
I0526 02:23:18.178737  5200 solver.cpp:239] Iteration 4316 (1.67213 iter/s, 15.549s/26 iters), loss = 0.0432409
I0526 02:23:18.178794  5200 solver.cpp:258]     Train net output #0: loss = 0.0234342 (* 1 = 0.0234342 loss)
I0526 02:23:18.178802  5200 sgd_solver.cpp:112] Iteration 4316, lr = 0.01
I0526 02:23:33.727861  5200 solver.cpp:239] Iteration 4342 (1.67213 iter/s, 15.549s/26 iters), loss = 0.0183651
I0526 02:23:33.728063  5200 solver.cpp:258]     Train net output #0: loss = 0.00193017 (* 1 = 0.00193017 loss)
I0526 02:23:33.728071  5200 sgd_solver.cpp:112] Iteration 4342, lr = 0.01
I0526 02:23:49.271986  5200 solver.cpp:239] Iteration 4368 (1.67278 iter/s, 15.543s/26 iters), loss = 0.0333215
I0526 02:23:49.272039  5200 solver.cpp:258]     Train net output #0: loss = 0.0195285 (* 1 = 0.0195285 loss)
I0526 02:23:49.272047  5200 sgd_solver.cpp:112] Iteration 4368, lr = 0.01
I0526 02:24:04.840024  5200 solver.cpp:239] Iteration 4394 (1.6702 iter/s, 15.567s/26 iters), loss = 0.0260275
I0526 02:24:04.840159  5200 solver.cpp:258]     Train net output #0: loss = 0.0225991 (* 1 = 0.0225991 loss)
I0526 02:24:04.840168  5200 sgd_solver.cpp:112] Iteration 4394, lr = 0.01
I0526 02:24:20.391693  5200 solver.cpp:239] Iteration 4420 (1.67192 iter/s, 15.551s/26 iters), loss = 0.0293639
I0526 02:24:20.391744  5200 solver.cpp:258]     Train net output #0: loss = 0.00879741 (* 1 = 0.00879741 loss)
I0526 02:24:20.391752  5200 sgd_solver.cpp:112] Iteration 4420, lr = 0.01
I0526 02:24:35.938866  5200 solver.cpp:239] Iteration 4446 (1.67235 iter/s, 15.547s/26 iters), loss = 0.0258084
I0526 02:24:35.939043  5200 solver.cpp:258]     Train net output #0: loss = 0.00590562 (* 1 = 0.00590562 loss)
I0526 02:24:35.939050  5200 sgd_solver.cpp:112] Iteration 4446, lr = 0.01
I0526 02:24:51.583930  5200 solver.cpp:239] Iteration 4472 (1.66198 iter/s, 15.644s/26 iters), loss = 0.0189661
I0526 02:24:51.583974  5200 solver.cpp:258]     Train net output #0: loss = 0.000842054 (* 1 = 0.000842054 loss)
I0526 02:24:51.583981  5200 sgd_solver.cpp:112] Iteration 4472, lr = 0.01
I0526 02:25:07.421990  5200 solver.cpp:239] Iteration 4498 (1.64162 iter/s, 15.838s/26 iters), loss = 0.0302743
I0526 02:25:07.422117  5200 solver.cpp:258]     Train net output #0: loss = 0.00301821 (* 1 = 0.00301821 loss)
I0526 02:25:07.422127  5200 sgd_solver.cpp:112] Iteration 4498, lr = 0.01
I0526 02:25:23.225080  5200 solver.cpp:239] Iteration 4524 (1.64536 iter/s, 15.802s/26 iters), loss = 0.0273908
I0526 02:25:23.225136  5200 solver.cpp:258]     Train net output #0: loss = 0.0114158 (* 1 = 0.0114158 loss)
I0526 02:25:23.225145  5200 sgd_solver.cpp:112] Iteration 4524, lr = 0.01
I0526 02:25:39.025595  5200 solver.cpp:239] Iteration 4550 (1.64557 iter/s, 15.8s/26 iters), loss = 0.0284677
I0526 02:25:39.025744  5200 solver.cpp:258]     Train net output #0: loss = 0.0398904 (* 1 = 0.0398904 loss)
I0526 02:25:39.025753  5200 sgd_solver.cpp:112] Iteration 4550, lr = 0.01
I0526 02:25:54.810063  5200 solver.cpp:239] Iteration 4576 (1.64724 iter/s, 15.784s/26 iters), loss = 0.023739
I0526 02:25:54.810106  5200 solver.cpp:258]     Train net output #0: loss = 0.00312337 (* 1 = 0.00312337 loss)
I0526 02:25:54.810114  5200 sgd_solver.cpp:112] Iteration 4576, lr = 0.01
I0526 02:26:10.617712  5200 solver.cpp:239] Iteration 4602 (1.64484 iter/s, 15.807s/26 iters), loss = 0.013813
I0526 02:26:10.617899  5200 solver.cpp:258]     Train net output #0: loss = 0.00904372 (* 1 = 0.00904372 loss)
I0526 02:26:10.617908  5200 sgd_solver.cpp:112] Iteration 4602, lr = 0.01
I0526 02:26:20.951158  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_4620.caffemodel
I0526 02:26:20.951828  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_4620.solverstate
I0526 02:26:20.952143  5200 solver.cpp:347] Iteration 4620, Testing net (#0)
I0526 02:26:32.208472  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9832
I0526 02:26:32.208523  5200 solver.cpp:414]     Test net output #1: loss = 0.0478524 (* 1 = 0.0478524 loss)
I0526 02:26:32.208528  5200 solver.cpp:347] Iteration 4620, Testing net (#1)
I0526 02:26:54.677686  5200 solver.cpp:414]     Test net output #0: accuracy = 0.809574
I0526 02:26:54.677805  5200 solver.cpp:414]     Test net output #1: loss = 0.698396 (* 1 = 0.698396 loss)
I0526 02:26:54.677814  5200 solver.cpp:347] Iteration 4620, Testing net (#2)
I0526 02:27:45.551508  5200 solver.cpp:414]     Test net output #0: accuracy = 0.974055
I0526 02:27:45.553452  5200 solver.cpp:414]     Test net output #1: loss = 0.0757021 (* 1 = 0.0757021 loss)
I0526 02:27:51.039752  5200 solver.cpp:239] Iteration 4628 (0.25891 iter/s, 100.421s/26 iters), loss = 0.031691
I0526 02:27:51.039803  5200 solver.cpp:258]     Train net output #0: loss = 0.00374652 (* 1 = 0.00374652 loss)
I0526 02:27:51.039811  5200 sgd_solver.cpp:112] Iteration 4628, lr = 0.005
I0526 02:28:06.836880  5200 solver.cpp:239] Iteration 4654 (1.64588 iter/s, 15.797s/26 iters), loss = 0.020272
I0526 02:28:06.836933  5200 solver.cpp:258]     Train net output #0: loss = 0.0731869 (* 1 = 0.0731869 loss)
I0526 02:28:06.836941  5200 sgd_solver.cpp:112] Iteration 4654, lr = 0.005
I0526 02:28:22.676847  5200 solver.cpp:239] Iteration 4680 (1.64152 iter/s, 15.839s/26 iters), loss = 0.0213451
I0526 02:28:22.676997  5200 solver.cpp:258]     Train net output #0: loss = 0.0550132 (* 1 = 0.0550132 loss)
I0526 02:28:22.677006  5200 sgd_solver.cpp:112] Iteration 4680, lr = 0.005
I0526 02:28:38.511785  5200 solver.cpp:239] Iteration 4706 (1.64204 iter/s, 15.834s/26 iters), loss = 0.0120465
I0526 02:28:38.511838  5200 solver.cpp:258]     Train net output #0: loss = 0.0161383 (* 1 = 0.0161383 loss)
I0526 02:28:38.511845  5200 sgd_solver.cpp:112] Iteration 4706, lr = 0.005
I0526 02:28:54.370888  5200 solver.cpp:239] Iteration 4732 (1.63945 iter/s, 15.859s/26 iters), loss = 0.0289292
I0526 02:28:54.371037  5200 solver.cpp:258]     Train net output #0: loss = 0.00409436 (* 1 = 0.00409436 loss)
I0526 02:28:54.371045  5200 sgd_solver.cpp:112] Iteration 4732, lr = 0.005
I0526 02:29:10.210311  5200 solver.cpp:239] Iteration 4758 (1.64152 iter/s, 15.839s/26 iters), loss = 0.0140596
I0526 02:29:10.210366  5200 solver.cpp:258]     Train net output #0: loss = 0.0300793 (* 1 = 0.0300793 loss)
I0526 02:29:10.210374  5200 sgd_solver.cpp:112] Iteration 4758, lr = 0.005
I0526 02:29:26.067210  5200 solver.cpp:239] Iteration 4784 (1.63976 iter/s, 15.856s/26 iters), loss = 0.0113954
I0526 02:29:26.067354  5200 solver.cpp:258]     Train net output #0: loss = 0.00553349 (* 1 = 0.00553349 loss)
I0526 02:29:26.067363  5200 sgd_solver.cpp:112] Iteration 4784, lr = 0.005
I0526 02:29:41.886993  5200 solver.cpp:239] Iteration 4810 (1.64359 iter/s, 15.819s/26 iters), loss = 0.0119674
I0526 02:29:41.887038  5200 solver.cpp:258]     Train net output #0: loss = 0.00437592 (* 1 = 0.00437592 loss)
I0526 02:29:41.887045  5200 sgd_solver.cpp:112] Iteration 4810, lr = 0.005
I0526 02:29:57.725486  5200 solver.cpp:239] Iteration 4836 (1.64162 iter/s, 15.838s/26 iters), loss = 0.0174325
I0526 02:29:57.725723  5200 solver.cpp:258]     Train net output #0: loss = 0.0115583 (* 1 = 0.0115583 loss)
I0526 02:29:57.725731  5200 sgd_solver.cpp:112] Iteration 4836, lr = 0.005
I0526 02:30:13.577314  5200 solver.cpp:239] Iteration 4862 (1.64028 iter/s, 15.851s/26 iters), loss = 0.0211914
I0526 02:30:13.577373  5200 solver.cpp:258]     Train net output #0: loss = 0.00685476 (* 1 = 0.00685476 loss)
I0526 02:30:13.577379  5200 sgd_solver.cpp:112] Iteration 4862, lr = 0.005
I0526 02:30:29.403035  5200 solver.cpp:239] Iteration 4888 (1.64297 iter/s, 15.825s/26 iters), loss = 0.0236309
I0526 02:30:29.403215  5200 solver.cpp:258]     Train net output #0: loss = 0.00185912 (* 1 = 0.00185912 loss)
I0526 02:30:29.403224  5200 sgd_solver.cpp:112] Iteration 4888, lr = 0.005
I0526 02:30:45.230974  5200 solver.cpp:239] Iteration 4914 (1.64276 iter/s, 15.827s/26 iters), loss = 0.0142948
I0526 02:30:45.231029  5200 solver.cpp:258]     Train net output #0: loss = 0.00319916 (* 1 = 0.00319916 loss)
I0526 02:30:45.231035  5200 sgd_solver.cpp:112] Iteration 4914, lr = 0.005
I0526 02:31:01.069672  5200 solver.cpp:239] Iteration 4940 (1.64162 iter/s, 15.838s/26 iters), loss = 0.0122592
I0526 02:31:01.069839  5200 solver.cpp:258]     Train net output #0: loss = 0.000806198 (* 1 = 0.000806198 loss)
I0526 02:31:01.069846  5200 sgd_solver.cpp:112] Iteration 4940, lr = 0.005
I0526 02:31:16.880239  5200 solver.cpp:239] Iteration 4966 (1.64453 iter/s, 15.81s/26 iters), loss = 0.0205148
I0526 02:31:16.880295  5200 solver.cpp:258]     Train net output #0: loss = 0.00263884 (* 1 = 0.00263884 loss)
I0526 02:31:16.880302  5200 sgd_solver.cpp:112] Iteration 4966, lr = 0.005
I0526 02:31:32.726487  5200 solver.cpp:239] Iteration 4992 (1.64079 iter/s, 15.846s/26 iters), loss = 0.0169851
I0526 02:31:32.726637  5200 solver.cpp:258]     Train net output #0: loss = 0.00400893 (* 1 = 0.00400893 loss)
I0526 02:31:32.726645  5200 sgd_solver.cpp:112] Iteration 4992, lr = 0.005
I0526 02:31:40.036137  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_5005.caffemodel
I0526 02:31:40.037233  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_5005.solverstate
I0526 02:31:40.037700  5200 solver.cpp:347] Iteration 5005, Testing net (#0)
I0526 02:31:51.217589  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9856
I0526 02:31:51.217640  5200 solver.cpp:414]     Test net output #1: loss = 0.0358711 (* 1 = 0.0358711 loss)
I0526 02:31:51.217645  5200 solver.cpp:347] Iteration 5005, Testing net (#1)
I0526 02:32:13.051190  5200 solver.cpp:414]     Test net output #0: accuracy = 0.661489
I0526 02:32:13.051352  5200 solver.cpp:414]     Test net output #1: loss = 1.27077 (* 1 = 1.27077 loss)
I0526 02:32:13.051358  5200 solver.cpp:347] Iteration 5005, Testing net (#2)
I0526 02:33:04.167608  5200 solver.cpp:414]     Test net output #0: accuracy = 0.965315
I0526 02:33:04.167774  5200 solver.cpp:414]     Test net output #1: loss = 0.100215 (* 1 = 0.100215 loss)
I0526 02:33:12.697180  5200 solver.cpp:239] Iteration 5018 (0.260078 iter/s, 99.97s/26 iters), loss = 0.0200049
I0526 02:33:12.697234  5200 solver.cpp:258]     Train net output #0: loss = 0.0110299 (* 1 = 0.0110299 loss)
I0526 02:33:12.697242  5200 sgd_solver.cpp:112] Iteration 5018, lr = 0.005
I0526 02:33:28.536727  5200 solver.cpp:239] Iteration 5044 (1.64152 iter/s, 15.839s/26 iters), loss = 0.0253625
I0526 02:33:28.536780  5200 solver.cpp:258]     Train net output #0: loss = 0.0130159 (* 1 = 0.0130159 loss)
I0526 02:33:28.536789  5200 sgd_solver.cpp:112] Iteration 5044, lr = 0.005
I0526 02:33:44.350356  5200 solver.cpp:239] Iteration 5070 (1.64422 iter/s, 15.813s/26 iters), loss = 0.0164284
I0526 02:33:44.350519  5200 solver.cpp:258]     Train net output #0: loss = 0.00639684 (* 1 = 0.00639684 loss)
I0526 02:33:44.350528  5200 sgd_solver.cpp:112] Iteration 5070, lr = 0.005
I0526 02:34:00.159103  5200 solver.cpp:239] Iteration 5096 (1.64474 iter/s, 15.808s/26 iters), loss = 0.0189236
I0526 02:34:00.159157  5200 solver.cpp:258]     Train net output #0: loss = 0.00910976 (* 1 = 0.00910976 loss)
I0526 02:34:00.159165  5200 sgd_solver.cpp:112] Iteration 5096, lr = 0.005
I0526 02:34:16.000068  5200 solver.cpp:239] Iteration 5122 (1.64141 iter/s, 15.84s/26 iters), loss = 0.0148967
I0526 02:34:16.000236  5200 solver.cpp:258]     Train net output #0: loss = 0.000711185 (* 1 = 0.000711185 loss)
I0526 02:34:16.000244  5200 sgd_solver.cpp:112] Iteration 5122, lr = 0.005
I0526 02:34:31.824851  5200 solver.cpp:239] Iteration 5148 (1.64307 iter/s, 15.824s/26 iters), loss = 0.0263046
I0526 02:34:31.824903  5200 solver.cpp:258]     Train net output #0: loss = 0.0525371 (* 1 = 0.0525371 loss)
I0526 02:34:31.824910  5200 sgd_solver.cpp:112] Iteration 5148, lr = 0.005
I0526 02:34:47.670399  5200 solver.cpp:239] Iteration 5174 (1.6409 iter/s, 15.845s/26 iters), loss = 0.0267815
I0526 02:34:47.670580  5200 solver.cpp:258]     Train net output #0: loss = 0.0565551 (* 1 = 0.0565551 loss)
I0526 02:34:47.670588  5200 sgd_solver.cpp:112] Iteration 5174, lr = 0.005
I0526 02:35:03.494884  5200 solver.cpp:239] Iteration 5200 (1.64307 iter/s, 15.824s/26 iters), loss = 0.0136907
I0526 02:35:03.494966  5200 solver.cpp:258]     Train net output #0: loss = 0.00143641 (* 1 = 0.00143641 loss)
I0526 02:35:03.494974  5200 sgd_solver.cpp:112] Iteration 5200, lr = 0.005
I0526 02:35:19.337829  5200 solver.cpp:239] Iteration 5226 (1.64121 iter/s, 15.842s/26 iters), loss = 0.0357064
I0526 02:35:19.337998  5200 solver.cpp:258]     Train net output #0: loss = 0.119123 (* 1 = 0.119123 loss)
I0526 02:35:19.338006  5200 sgd_solver.cpp:112] Iteration 5226, lr = 0.005
I0526 02:35:35.151111  5200 solver.cpp:239] Iteration 5252 (1.64422 iter/s, 15.813s/26 iters), loss = 0.0331235
I0526 02:35:35.151165  5200 solver.cpp:258]     Train net output #0: loss = 0.0462856 (* 1 = 0.0462856 loss)
I0526 02:35:35.151171  5200 sgd_solver.cpp:112] Iteration 5252, lr = 0.005
I0526 02:35:50.948189  5200 solver.cpp:239] Iteration 5278 (1.64588 iter/s, 15.797s/26 iters), loss = 0.0346174
I0526 02:35:50.948441  5200 solver.cpp:258]     Train net output #0: loss = 0.0414444 (* 1 = 0.0414444 loss)
I0526 02:35:50.948449  5200 sgd_solver.cpp:112] Iteration 5278, lr = 0.005
I0526 02:36:06.746490  5200 solver.cpp:239] Iteration 5304 (1.64578 iter/s, 15.798s/26 iters), loss = 0.0190117
I0526 02:36:06.746544  5200 solver.cpp:258]     Train net output #0: loss = 0.00353126 (* 1 = 0.00353126 loss)
I0526 02:36:06.746551  5200 sgd_solver.cpp:112] Iteration 5304, lr = 0.005
I0526 02:36:22.517905  5200 solver.cpp:239] Iteration 5330 (1.6486 iter/s, 15.771s/26 iters), loss = 0.0238445
I0526 02:36:22.518059  5200 solver.cpp:258]     Train net output #0: loss = 0.0390881 (* 1 = 0.0390881 loss)
I0526 02:36:22.518066  5200 sgd_solver.cpp:112] Iteration 5330, lr = 0.005
I0526 02:36:38.339149  5200 solver.cpp:239] Iteration 5356 (1.64339 iter/s, 15.821s/26 iters), loss = 0.0130659
I0526 02:36:38.339202  5200 solver.cpp:258]     Train net output #0: loss = 0.0285064 (* 1 = 0.0285064 loss)
I0526 02:36:38.339210  5200 sgd_solver.cpp:112] Iteration 5356, lr = 0.005
I0526 02:36:54.325062  5200 solver.cpp:239] Iteration 5382 (1.62652 iter/s, 15.985s/26 iters), loss = 0.0307074
I0526 02:36:54.325282  5200 solver.cpp:258]     Train net output #0: loss = 0.0184078 (* 1 = 0.0184078 loss)
I0526 02:36:54.325290  5200 sgd_solver.cpp:112] Iteration 5382, lr = 0.005
I0526 02:36:58.596601  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_5390.caffemodel
I0526 02:36:58.597263  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_5390.solverstate
I0526 02:36:58.597580  5200 solver.cpp:347] Iteration 5390, Testing net (#0)
I0526 02:37:09.844306  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9892
I0526 02:37:09.844352  5200 solver.cpp:414]     Test net output #1: loss = 0.0285247 (* 1 = 0.0285247 loss)
I0526 02:37:09.844358  5200 solver.cpp:347] Iteration 5390, Testing net (#1)
I0526 02:37:32.211853  5200 solver.cpp:414]     Test net output #0: accuracy = 0.650425
I0526 02:37:32.212008  5200 solver.cpp:414]     Test net output #1: loss = 1.34259 (* 1 = 1.34259 loss)
I0526 02:37:32.212016  5200 solver.cpp:347] Iteration 5390, Testing net (#2)
I0526 02:38:22.942286  5200 solver.cpp:414]     Test net output #0: accuracy = 0.96
I0526 02:38:22.942433  5200 solver.cpp:414]     Test net output #1: loss = 0.111634 (* 1 = 0.111634 loss)
I0526 02:38:34.471801  5200 solver.cpp:239] Iteration 5408 (0.259621 iter/s, 100.146s/26 iters), loss = 0.0178805
I0526 02:38:34.471856  5200 solver.cpp:258]     Train net output #0: loss = 0.0487897 (* 1 = 0.0487897 loss)
I0526 02:38:34.471863  5200 sgd_solver.cpp:112] Iteration 5408, lr = 0.005
I0526 02:38:50.269435  5200 solver.cpp:239] Iteration 5434 (1.64588 iter/s, 15.797s/26 iters), loss = 0.0115056
I0526 02:38:50.269492  5200 solver.cpp:258]     Train net output #0: loss = 0.00817316 (* 1 = 0.00817316 loss)
I0526 02:38:50.269500  5200 sgd_solver.cpp:112] Iteration 5434, lr = 0.005
I0526 02:39:06.061280  5200 solver.cpp:239] Iteration 5460 (1.64651 iter/s, 15.791s/26 iters), loss = 0.0135396
I0526 02:39:06.061437  5200 solver.cpp:258]     Train net output #0: loss = 0.00913338 (* 1 = 0.00913338 loss)
I0526 02:39:06.061446  5200 sgd_solver.cpp:112] Iteration 5460, lr = 0.005
I0526 02:39:21.867305  5200 solver.cpp:239] Iteration 5486 (1.64505 iter/s, 15.805s/26 iters), loss = 0.0176471
I0526 02:39:21.867359  5200 solver.cpp:258]     Train net output #0: loss = 0.000225468 (* 1 = 0.000225468 loss)
I0526 02:39:21.867367  5200 sgd_solver.cpp:112] Iteration 5486, lr = 0.005
I0526 02:39:37.666425  5200 solver.cpp:239] Iteration 5512 (1.64567 iter/s, 15.799s/26 iters), loss = 0.0164227
I0526 02:39:37.666574  5200 solver.cpp:258]     Train net output #0: loss = 0.0262963 (* 1 = 0.0262963 loss)
I0526 02:39:37.666581  5200 sgd_solver.cpp:112] Iteration 5512, lr = 0.005
I0526 02:39:53.467619  5200 solver.cpp:239] Iteration 5538 (1.64547 iter/s, 15.801s/26 iters), loss = 0.0138501
I0526 02:39:53.467675  5200 solver.cpp:258]     Train net output #0: loss = 0.0549177 (* 1 = 0.0549177 loss)
I0526 02:39:53.467684  5200 sgd_solver.cpp:112] Iteration 5538, lr = 0.005
I0526 02:40:09.292666  5200 solver.cpp:239] Iteration 5564 (1.64307 iter/s, 15.824s/26 iters), loss = 0.0180675
I0526 02:40:09.292811  5200 solver.cpp:258]     Train net output #0: loss = 0.0209129 (* 1 = 0.0209129 loss)
I0526 02:40:09.292820  5200 sgd_solver.cpp:112] Iteration 5564, lr = 0.005
I0526 02:40:25.120648  5200 solver.cpp:239] Iteration 5590 (1.64276 iter/s, 15.827s/26 iters), loss = 0.0160746
I0526 02:40:25.120705  5200 solver.cpp:258]     Train net output #0: loss = 0.0715148 (* 1 = 0.0715148 loss)
I0526 02:40:25.120713  5200 sgd_solver.cpp:112] Iteration 5590, lr = 0.005
I0526 02:40:40.929301  5200 solver.cpp:239] Iteration 5616 (1.64474 iter/s, 15.808s/26 iters), loss = 0.0221457
I0526 02:40:40.929467  5200 solver.cpp:258]     Train net output #0: loss = 0.00327926 (* 1 = 0.00327926 loss)
I0526 02:40:40.929476  5200 sgd_solver.cpp:112] Iteration 5616, lr = 0.005
I0526 02:40:56.740473  5200 solver.cpp:239] Iteration 5642 (1.64442 iter/s, 15.811s/26 iters), loss = 0.010998
I0526 02:40:56.740530  5200 solver.cpp:258]     Train net output #0: loss = 0.00168466 (* 1 = 0.00168466 loss)
I0526 02:40:56.740536  5200 sgd_solver.cpp:112] Iteration 5642, lr = 0.005
I0526 02:41:12.548666  5200 solver.cpp:239] Iteration 5668 (1.64474 iter/s, 15.808s/26 iters), loss = 0.0246984
I0526 02:41:12.548833  5200 solver.cpp:258]     Train net output #0: loss = 0.00638407 (* 1 = 0.00638407 loss)
I0526 02:41:12.548841  5200 sgd_solver.cpp:112] Iteration 5668, lr = 0.005
I0526 02:41:28.358006  5200 solver.cpp:239] Iteration 5694 (1.64463 iter/s, 15.809s/26 iters), loss = 0.0188873
I0526 02:41:28.358058  5200 solver.cpp:258]     Train net output #0: loss = 0.0442229 (* 1 = 0.0442229 loss)
I0526 02:41:28.358065  5200 sgd_solver.cpp:112] Iteration 5694, lr = 0.005
I0526 02:41:44.164330  5200 solver.cpp:239] Iteration 5720 (1.64495 iter/s, 15.806s/26 iters), loss = 0.0354216
I0526 02:41:44.164489  5200 solver.cpp:258]     Train net output #0: loss = 0.0455827 (* 1 = 0.0455827 loss)
I0526 02:41:44.164497  5200 sgd_solver.cpp:112] Iteration 5720, lr = 0.005
I0526 02:41:59.948345  5200 solver.cpp:239] Iteration 5746 (1.64734 iter/s, 15.783s/26 iters), loss = 0.0197144
I0526 02:41:59.948391  5200 solver.cpp:258]     Train net output #0: loss = 0.00814302 (* 1 = 0.00814302 loss)
I0526 02:41:59.948400  5200 sgd_solver.cpp:112] Iteration 5746, lr = 0.005
I0526 02:42:15.718235  5200 solver.cpp:239] Iteration 5772 (1.6488 iter/s, 15.769s/26 iters), loss = 0.0125552
I0526 02:42:15.718408  5200 solver.cpp:258]     Train net output #0: loss = 0.00706959 (* 1 = 0.00706959 loss)
I0526 02:42:15.718426  5200 sgd_solver.cpp:112] Iteration 5772, lr = 0.005
I0526 02:42:16.930442  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_5775.caffemodel
I0526 02:42:16.931125  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_5775.solverstate
I0526 02:42:16.931437  5200 solver.cpp:347] Iteration 5775, Testing net (#0)
I0526 02:42:28.168612  5200 solver.cpp:414]     Test net output #0: accuracy = 0.996
I0526 02:42:28.168653  5200 solver.cpp:414]     Test net output #1: loss = 0.0128565 (* 1 = 0.0128565 loss)
I0526 02:42:28.168660  5200 solver.cpp:347] Iteration 5775, Testing net (#1)
I0526 02:42:50.551883  5200 solver.cpp:414]     Test net output #0: accuracy = 0.788085
I0526 02:42:50.552047  5200 solver.cpp:414]     Test net output #1: loss = 0.707888 (* 1 = 0.707888 loss)
I0526 02:42:50.552054  5200 solver.cpp:347] Iteration 5775, Testing net (#2)
I0526 02:43:41.307477  5200 solver.cpp:414]     Test net output #0: accuracy = 0.986217
I0526 02:43:41.307631  5200 solver.cpp:414]     Test net output #1: loss = 0.0442299 (* 1 = 0.0442299 loss)
I0526 02:43:55.870837  5200 solver.cpp:239] Iteration 5798 (0.259605 iter/s, 100.152s/26 iters), loss = 0.0122804
I0526 02:43:55.870900  5200 solver.cpp:258]     Train net output #0: loss = 0.00179166 (* 1 = 0.00179166 loss)
I0526 02:43:55.870908  5200 sgd_solver.cpp:112] Iteration 5798, lr = 0.005
I0526 02:44:11.622937  5200 solver.cpp:239] Iteration 5824 (1.65058 iter/s, 15.752s/26 iters), loss = 0.0112465
I0526 02:44:11.623106  5200 solver.cpp:258]     Train net output #0: loss = 0.0040938 (* 1 = 0.0040938 loss)
I0526 02:44:11.623114  5200 sgd_solver.cpp:112] Iteration 5824, lr = 0.005
I0526 02:44:27.360867  5200 solver.cpp:239] Iteration 5850 (1.65216 iter/s, 15.737s/26 iters), loss = 0.0193215
I0526 02:44:27.360919  5200 solver.cpp:258]     Train net output #0: loss = 0.109499 (* 1 = 0.109499 loss)
I0526 02:44:27.360926  5200 sgd_solver.cpp:112] Iteration 5850, lr = 0.005
I0526 02:44:43.124011  5200 solver.cpp:239] Iteration 5876 (1.64943 iter/s, 15.763s/26 iters), loss = 0.013018
I0526 02:44:43.124172  5200 solver.cpp:258]     Train net output #0: loss = 0.00742434 (* 1 = 0.00742434 loss)
I0526 02:44:43.124181  5200 sgd_solver.cpp:112] Iteration 5876, lr = 0.005
I0526 02:44:58.885885  5200 solver.cpp:239] Iteration 5902 (1.64964 iter/s, 15.761s/26 iters), loss = 0.0232788
I0526 02:44:58.885931  5200 solver.cpp:258]     Train net output #0: loss = 0.00138303 (* 1 = 0.00138303 loss)
I0526 02:44:58.885938  5200 sgd_solver.cpp:112] Iteration 5902, lr = 0.005
I0526 02:45:14.648986  5200 solver.cpp:239] Iteration 5928 (1.64943 iter/s, 15.763s/26 iters), loss = 0.0174219
I0526 02:45:14.649152  5200 solver.cpp:258]     Train net output #0: loss = 0.00273133 (* 1 = 0.00273133 loss)
I0526 02:45:14.649160  5200 sgd_solver.cpp:112] Iteration 5928, lr = 0.005
I0526 02:45:30.438284  5200 solver.cpp:239] Iteration 5954 (1.64672 iter/s, 15.789s/26 iters), loss = 0.0119193
I0526 02:45:30.438340  5200 solver.cpp:258]     Train net output #0: loss = 0.00931975 (* 1 = 0.00931975 loss)
I0526 02:45:30.438349  5200 sgd_solver.cpp:112] Iteration 5954, lr = 0.005
I0526 02:45:46.190517  5200 solver.cpp:239] Iteration 5980 (1.65058 iter/s, 15.752s/26 iters), loss = 0.0171447
I0526 02:45:46.190656  5200 solver.cpp:258]     Train net output #0: loss = 0.000816068 (* 1 = 0.000816068 loss)
I0526 02:45:46.190665  5200 sgd_solver.cpp:112] Iteration 5980, lr = 0.005
I0526 02:46:01.958179  5200 solver.cpp:239] Iteration 6006 (1.64901 iter/s, 15.767s/26 iters), loss = 0.00797315
I0526 02:46:01.958232  5200 solver.cpp:258]     Train net output #0: loss = 0.000374311 (* 1 = 0.000374311 loss)
I0526 02:46:01.958240  5200 sgd_solver.cpp:112] Iteration 6006, lr = 0.005
I0526 02:46:17.741623  5200 solver.cpp:239] Iteration 6032 (1.64734 iter/s, 15.783s/26 iters), loss = 0.0160321
I0526 02:46:17.741802  5200 solver.cpp:258]     Train net output #0: loss = 0.00651225 (* 1 = 0.00651225 loss)
I0526 02:46:17.741811  5200 sgd_solver.cpp:112] Iteration 6032, lr = 0.005
I0526 02:46:33.498347  5200 solver.cpp:239] Iteration 6058 (1.65017 iter/s, 15.756s/26 iters), loss = 0.0151507
I0526 02:46:33.498404  5200 solver.cpp:258]     Train net output #0: loss = 0.000835793 (* 1 = 0.000835793 loss)
I0526 02:46:33.498412  5200 sgd_solver.cpp:112] Iteration 6058, lr = 0.005
I0526 02:46:49.369201  5200 solver.cpp:239] Iteration 6084 (1.63831 iter/s, 15.87s/26 iters), loss = 0.016318
I0526 02:46:49.369371  5200 solver.cpp:258]     Train net output #0: loss = 0.00173075 (* 1 = 0.00173075 loss)
I0526 02:46:49.369381  5200 sgd_solver.cpp:112] Iteration 6084, lr = 0.005
I0526 02:47:05.164710  5200 solver.cpp:239] Iteration 6110 (1.64609 iter/s, 15.795s/26 iters), loss = 0.0189398
I0526 02:47:05.164767  5200 solver.cpp:258]     Train net output #0: loss = 0.00115367 (* 1 = 0.00115367 loss)
I0526 02:47:05.164775  5200 sgd_solver.cpp:112] Iteration 6110, lr = 0.005
I0526 02:47:20.990015  5200 solver.cpp:239] Iteration 6136 (1.64297 iter/s, 15.825s/26 iters), loss = 0.0112462
I0526 02:47:20.990257  5200 solver.cpp:258]     Train net output #0: loss = 0.0019504 (* 1 = 0.0019504 loss)
I0526 02:47:20.990265  5200 sgd_solver.cpp:112] Iteration 6136, lr = 0.005
I0526 02:47:34.963702  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_6160.caffemodel
I0526 02:47:34.964370  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_6160.solverstate
I0526 02:47:34.964681  5200 solver.cpp:347] Iteration 6160, Testing net (#0)
I0526 02:47:46.119499  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9956
I0526 02:47:46.119544  5200 solver.cpp:414]     Test net output #1: loss = 0.0162763 (* 1 = 0.0162763 loss)
I0526 02:47:46.119551  5200 solver.cpp:347] Iteration 6160, Testing net (#1)
I0526 02:48:08.259359  5200 solver.cpp:414]     Test net output #0: accuracy = 0.799362
I0526 02:48:08.259588  5200 solver.cpp:414]     Test net output #1: loss = 0.745416 (* 1 = 0.745416 loss)
I0526 02:48:08.259595  5200 solver.cpp:347] Iteration 6160, Testing net (#2)
I0526 02:48:58.979684  5200 solver.cpp:414]     Test net output #0: accuracy = 0.983154
I0526 02:48:58.979899  5200 solver.cpp:414]     Test net output #1: loss = 0.0459925 (* 1 = 0.0459925 loss)
I0526 02:49:00.806963  5200 solver.cpp:239] Iteration 6162 (0.260479 iter/s, 99.816s/26 iters), loss = 0.0269793
I0526 02:49:00.807019  5200 solver.cpp:258]     Train net output #0: loss = 0.00807127 (* 1 = 0.00807127 loss)
I0526 02:49:00.807027  5200 sgd_solver.cpp:112] Iteration 6162, lr = 0.005
I0526 02:49:16.568085  5200 solver.cpp:239] Iteration 6188 (1.64964 iter/s, 15.761s/26 iters), loss = 0.0130127
I0526 02:49:16.568127  5200 solver.cpp:258]     Train net output #0: loss = 0.0259785 (* 1 = 0.0259785 loss)
I0526 02:49:16.568135  5200 sgd_solver.cpp:112] Iteration 6188, lr = 0.005
I0526 02:49:32.333359  5200 solver.cpp:239] Iteration 6214 (1.64922 iter/s, 15.765s/26 iters), loss = 0.0151558
I0526 02:49:32.333509  5200 solver.cpp:258]     Train net output #0: loss = 0.0376416 (* 1 = 0.0376416 loss)
I0526 02:49:32.333516  5200 sgd_solver.cpp:112] Iteration 6214, lr = 0.005
I0526 02:49:48.159840  5200 solver.cpp:239] Iteration 6240 (1.64287 iter/s, 15.826s/26 iters), loss = 0.0150271
I0526 02:49:48.159880  5200 solver.cpp:258]     Train net output #0: loss = 0.0160143 (* 1 = 0.0160143 loss)
I0526 02:49:48.159888  5200 sgd_solver.cpp:112] Iteration 6240, lr = 0.005
I0526 02:50:03.781354  5200 solver.cpp:239] Iteration 6266 (1.66443 iter/s, 15.621s/26 iters), loss = 0.00826742
I0526 02:50:03.781602  5200 solver.cpp:258]     Train net output #0: loss = 0.000794902 (* 1 = 0.000794902 loss)
I0526 02:50:03.781610  5200 sgd_solver.cpp:112] Iteration 6266, lr = 0.005
I0526 02:50:19.377154  5200 solver.cpp:239] Iteration 6292 (1.6672 iter/s, 15.595s/26 iters), loss = 0.00640053
I0526 02:50:19.377207  5200 solver.cpp:258]     Train net output #0: loss = 0.00236365 (* 1 = 0.00236365 loss)
I0526 02:50:19.377214  5200 sgd_solver.cpp:112] Iteration 6292, lr = 0.005
I0526 02:50:34.960675  5200 solver.cpp:239] Iteration 6318 (1.66848 iter/s, 15.583s/26 iters), loss = 0.0226425
I0526 02:50:34.960855  5200 solver.cpp:258]     Train net output #0: loss = 0.0300138 (* 1 = 0.0300138 loss)
I0526 02:50:34.960865  5200 sgd_solver.cpp:112] Iteration 6318, lr = 0.005
I0526 02:50:50.530886  5200 solver.cpp:239] Iteration 6344 (1.66988 iter/s, 15.57s/26 iters), loss = 0.0151146
I0526 02:50:50.530961  5200 solver.cpp:258]     Train net output #0: loss = 0.0244509 (* 1 = 0.0244509 loss)
I0526 02:50:50.530968  5200 sgd_solver.cpp:112] Iteration 6344, lr = 0.005
I0526 02:51:06.114866  5200 solver.cpp:239] Iteration 6370 (1.66848 iter/s, 15.583s/26 iters), loss = 0.012931
I0526 02:51:06.115033  5200 solver.cpp:258]     Train net output #0: loss = 0.0031322 (* 1 = 0.0031322 loss)
I0526 02:51:06.115043  5200 sgd_solver.cpp:112] Iteration 6370, lr = 0.005
I0526 02:51:21.700246  5200 solver.cpp:239] Iteration 6396 (1.66827 iter/s, 15.585s/26 iters), loss = 0.0357783
I0526 02:51:21.700304  5200 solver.cpp:258]     Train net output #0: loss = 0.0192679 (* 1 = 0.0192679 loss)
I0526 02:51:21.700310  5200 sgd_solver.cpp:112] Iteration 6396, lr = 0.005
I0526 02:51:37.312295  5200 solver.cpp:239] Iteration 6422 (1.66549 iter/s, 15.611s/26 iters), loss = 0.0101913
I0526 02:51:37.312525  5200 solver.cpp:258]     Train net output #0: loss = 0.00185074 (* 1 = 0.00185074 loss)
I0526 02:51:37.312534  5200 sgd_solver.cpp:112] Iteration 6422, lr = 0.005
I0526 02:51:52.989145  5200 solver.cpp:239] Iteration 6448 (1.65859 iter/s, 15.676s/26 iters), loss = 0.0174287
I0526 02:51:52.989202  5200 solver.cpp:258]     Train net output #0: loss = 0.0140108 (* 1 = 0.0140108 loss)
I0526 02:51:52.989209  5200 sgd_solver.cpp:112] Iteration 6448, lr = 0.005
I0526 02:52:08.614226  5200 solver.cpp:239] Iteration 6474 (1.664 iter/s, 15.625s/26 iters), loss = 0.0114281
I0526 02:52:08.614466  5200 solver.cpp:258]     Train net output #0: loss = 0.00143629 (* 1 = 0.00143629 loss)
I0526 02:52:08.614475  5200 sgd_solver.cpp:112] Iteration 6474, lr = 0.005
I0526 02:52:24.220752  5200 solver.cpp:239] Iteration 6500 (1.66603 iter/s, 15.606s/26 iters), loss = 0.009843
I0526 02:52:24.220804  5200 solver.cpp:258]     Train net output #0: loss = 0.00142972 (* 1 = 0.00142972 loss)
I0526 02:52:24.220813  5200 sgd_solver.cpp:112] Iteration 6500, lr = 0.005
I0526 02:52:39.799360  5200 solver.cpp:239] Iteration 6526 (1.66902 iter/s, 15.578s/26 iters), loss = 0.0177468
I0526 02:52:39.799496  5200 solver.cpp:258]     Train net output #0: loss = 0.00359826 (* 1 = 0.00359826 loss)
I0526 02:52:39.799504  5200 sgd_solver.cpp:112] Iteration 6526, lr = 0.005
I0526 02:52:50.612439  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_6545.caffemodel
I0526 02:52:50.613101  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_6545.solverstate
I0526 02:52:50.613413  5200 solver.cpp:347] Iteration 6545, Testing net (#0)
I0526 02:53:01.633574  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9972
I0526 02:53:01.633625  5200 solver.cpp:414]     Test net output #1: loss = 0.010864 (* 1 = 0.010864 loss)
I0526 02:53:01.633630  5200 solver.cpp:347] Iteration 6545, Testing net (#1)
I0526 02:53:23.204442  5200 solver.cpp:414]     Test net output #0: accuracy = 0.783404
I0526 02:53:23.204663  5200 solver.cpp:414]     Test net output #1: loss = 0.802364 (* 1 = 0.802364 loss)
I0526 02:53:23.204670  5200 solver.cpp:347] Iteration 6545, Testing net (#2)
I0526 02:54:13.848466  5200 solver.cpp:414]     Test net output #0: accuracy = 0.985496
I0526 02:54:13.848618  5200 solver.cpp:414]     Test net output #1: loss = 0.0510195 (* 1 = 0.0510195 loss)
I0526 02:54:18.652328  5200 solver.cpp:239] Iteration 6552 (0.263019 iter/s, 98.852s/26 iters), loss = 0.0152559
I0526 02:54:18.652380  5200 solver.cpp:258]     Train net output #0: loss = 0.0468467 (* 1 = 0.0468467 loss)
I0526 02:54:18.652387  5200 sgd_solver.cpp:112] Iteration 6552, lr = 0.005
I0526 02:54:34.429253  5200 solver.cpp:239] Iteration 6578 (1.64807 iter/s, 15.776s/26 iters), loss = 0.016419
I0526 02:54:34.429299  5200 solver.cpp:258]     Train net output #0: loss = 0.0135204 (* 1 = 0.0135204 loss)
I0526 02:54:34.429308  5200 sgd_solver.cpp:112] Iteration 6578, lr = 0.005
I0526 02:54:50.247514  5200 solver.cpp:239] Iteration 6604 (1.6437 iter/s, 15.818s/26 iters), loss = 0.00650167
I0526 02:54:50.247699  5200 solver.cpp:258]     Train net output #0: loss = 0.000592679 (* 1 = 0.000592679 loss)
I0526 02:54:50.247711  5200 sgd_solver.cpp:112] Iteration 6604, lr = 0.005
I0526 02:55:06.052364  5200 solver.cpp:239] Iteration 6630 (1.64515 iter/s, 15.804s/26 iters), loss = 0.0174805
I0526 02:55:06.052420  5200 solver.cpp:258]     Train net output #0: loss = 0.0213871 (* 1 = 0.0213871 loss)
I0526 02:55:06.052430  5200 sgd_solver.cpp:112] Iteration 6630, lr = 0.005
I0526 02:55:21.673326  5200 solver.cpp:239] Iteration 6656 (1.66453 iter/s, 15.62s/26 iters), loss = 0.0255761
I0526 02:55:21.673542  5200 solver.cpp:258]     Train net output #0: loss = 0.00465409 (* 1 = 0.00465409 loss)
I0526 02:55:21.673552  5200 sgd_solver.cpp:112] Iteration 6656, lr = 0.005
I0526 02:55:37.279085  5200 solver.cpp:239] Iteration 6682 (1.66613 iter/s, 15.605s/26 iters), loss = 0.00902079
I0526 02:55:37.279139  5200 solver.cpp:258]     Train net output #0: loss = 0.004517 (* 1 = 0.004517 loss)
I0526 02:55:37.279146  5200 sgd_solver.cpp:112] Iteration 6682, lr = 0.005
I0526 02:55:52.915009  5200 solver.cpp:239] Iteration 6708 (1.66294 iter/s, 15.635s/26 iters), loss = 0.020076
I0526 02:55:52.915163  5200 solver.cpp:258]     Train net output #0: loss = 0.0410408 (* 1 = 0.0410408 loss)
I0526 02:55:52.915171  5200 sgd_solver.cpp:112] Iteration 6708, lr = 0.005
I0526 02:56:08.555729  5200 solver.cpp:239] Iteration 6734 (1.6624 iter/s, 15.64s/26 iters), loss = 0.0105462
I0526 02:56:08.555784  5200 solver.cpp:258]     Train net output #0: loss = 0.0557043 (* 1 = 0.0557043 loss)
I0526 02:56:08.555791  5200 sgd_solver.cpp:112] Iteration 6734, lr = 0.005
I0526 02:56:24.186436  5200 solver.cpp:239] Iteration 6760 (1.66347 iter/s, 15.63s/26 iters), loss = 0.0128747
I0526 02:56:24.186589  5200 solver.cpp:258]     Train net output #0: loss = 0.00769653 (* 1 = 0.00769653 loss)
I0526 02:56:24.186596  5200 sgd_solver.cpp:112] Iteration 6760, lr = 0.005
I0526 02:56:39.805400  5200 solver.cpp:239] Iteration 6786 (1.66475 iter/s, 15.618s/26 iters), loss = 0.0230372
I0526 02:56:39.805454  5200 solver.cpp:258]     Train net output #0: loss = 0.00084455 (* 1 = 0.00084455 loss)
I0526 02:56:39.805461  5200 sgd_solver.cpp:112] Iteration 6786, lr = 0.005
I0526 02:56:55.556530  5200 solver.cpp:239] Iteration 6812 (1.65069 iter/s, 15.751s/26 iters), loss = 0.0125397
I0526 02:56:55.556766  5200 solver.cpp:258]     Train net output #0: loss = 0.00627524 (* 1 = 0.00627524 loss)
I0526 02:56:55.556774  5200 sgd_solver.cpp:112] Iteration 6812, lr = 0.005
I0526 02:57:11.130643  5200 solver.cpp:239] Iteration 6838 (1.66956 iter/s, 15.573s/26 iters), loss = 0.0155753
I0526 02:57:11.130698  5200 solver.cpp:258]     Train net output #0: loss = 0.0366053 (* 1 = 0.0366053 loss)
I0526 02:57:11.130705  5200 sgd_solver.cpp:112] Iteration 6838, lr = 0.005
I0526 02:57:26.674726  5200 solver.cpp:239] Iteration 6864 (1.67267 iter/s, 15.544s/26 iters), loss = 0.0181626
I0526 02:57:26.674962  5200 solver.cpp:258]     Train net output #0: loss = 0.00712999 (* 1 = 0.00712999 loss)
I0526 02:57:26.674971  5200 sgd_solver.cpp:112] Iteration 6864, lr = 0.005
I0526 02:57:42.242862  5200 solver.cpp:239] Iteration 6890 (1.6702 iter/s, 15.567s/26 iters), loss = 0.0178441
I0526 02:57:42.242938  5200 solver.cpp:258]     Train net output #0: loss = 0.00504012 (* 1 = 0.00504012 loss)
I0526 02:57:42.242945  5200 sgd_solver.cpp:112] Iteration 6890, lr = 0.005
I0526 02:57:57.802902  5200 solver.cpp:239] Iteration 6916 (1.67106 iter/s, 15.559s/26 iters), loss = 0.0139087
I0526 02:57:57.803081  5200 solver.cpp:258]     Train net output #0: loss = 0.00536789 (* 1 = 0.00536789 loss)
I0526 02:57:57.803089  5200 sgd_solver.cpp:112] Iteration 6916, lr = 0.005
I0526 02:58:05.589707  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_6930.caffemodel
I0526 02:58:05.590381  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_6930.solverstate
I0526 02:58:05.590692  5200 solver.cpp:347] Iteration 6930, Testing net (#0)
I0526 02:58:16.707305  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9944
I0526 02:58:16.707353  5200 solver.cpp:414]     Test net output #1: loss = 0.0118633 (* 1 = 0.0118633 loss)
I0526 02:58:16.707360  5200 solver.cpp:347] Iteration 6930, Testing net (#1)
I0526 02:58:38.787894  5200 solver.cpp:414]     Test net output #0: accuracy = 0.828085
I0526 02:58:38.788053  5200 solver.cpp:414]     Test net output #1: loss = 0.526862 (* 1 = 0.526862 loss)
I0526 02:58:38.788060  5200 solver.cpp:347] Iteration 6930, Testing net (#2)
I0526 02:59:28.784502  5200 solver.cpp:414]     Test net output #0: accuracy = 0.988559
I0526 02:59:28.784659  5200 solver.cpp:414]     Test net output #1: loss = 0.0311966 (* 1 = 0.0311966 loss)
I0526 02:59:36.592159  5200 solver.cpp:239] Iteration 6942 (0.263187 iter/s, 98.789s/26 iters), loss = 0.0157401
I0526 02:59:36.592213  5200 solver.cpp:258]     Train net output #0: loss = 0.00241039 (* 1 = 0.00241039 loss)
I0526 02:59:36.592221  5200 sgd_solver.cpp:112] Iteration 6942, lr = 0.005
I0526 02:59:52.148617  5200 solver.cpp:239] Iteration 6968 (1.67138 iter/s, 15.556s/26 iters), loss = 0.00971004
I0526 02:59:52.148669  5200 solver.cpp:258]     Train net output #0: loss = 0.0034014 (* 1 = 0.0034014 loss)
I0526 02:59:52.148676  5200 sgd_solver.cpp:112] Iteration 6968, lr = 0.005
I0526 03:00:07.713124  5200 solver.cpp:239] Iteration 6994 (1.67052 iter/s, 15.564s/26 iters), loss = 0.0169076
I0526 03:00:07.713289  5200 solver.cpp:258]     Train net output #0: loss = 0.00115428 (* 1 = 0.00115428 loss)
I0526 03:00:07.713297  5200 sgd_solver.cpp:112] Iteration 6994, lr = 0.005
I0526 03:00:23.279817  5200 solver.cpp:239] Iteration 7020 (1.67031 iter/s, 15.566s/26 iters), loss = 0.0104245
I0526 03:00:23.279863  5200 solver.cpp:258]     Train net output #0: loss = 0.0187964 (* 1 = 0.0187964 loss)
I0526 03:00:23.279870  5200 sgd_solver.cpp:112] Iteration 7020, lr = 0.005
I0526 03:00:38.825660  5200 solver.cpp:239] Iteration 7046 (1.67256 iter/s, 15.545s/26 iters), loss = 0.00802481
I0526 03:00:38.825807  5200 solver.cpp:258]     Train net output #0: loss = 0.00522487 (* 1 = 0.00522487 loss)
I0526 03:00:38.825815  5200 sgd_solver.cpp:112] Iteration 7046, lr = 0.005
I0526 03:00:54.408437  5200 solver.cpp:239] Iteration 7072 (1.66859 iter/s, 15.582s/26 iters), loss = 0.00800253
I0526 03:00:54.408493  5200 solver.cpp:258]     Train net output #0: loss = 0.00596093 (* 1 = 0.00596093 loss)
I0526 03:00:54.408500  5200 sgd_solver.cpp:112] Iteration 7072, lr = 0.005
I0526 03:01:10.065085  5200 solver.cpp:239] Iteration 7098 (1.66071 iter/s, 15.656s/26 iters), loss = 0.0142536
I0526 03:01:10.065294  5200 solver.cpp:258]     Train net output #0: loss = 0.00103279 (* 1 = 0.00103279 loss)
I0526 03:01:10.065302  5200 sgd_solver.cpp:112] Iteration 7098, lr = 0.005
I0526 03:01:25.713009  5200 solver.cpp:239] Iteration 7124 (1.66166 iter/s, 15.647s/26 iters), loss = 0.00987467
I0526 03:01:25.713064  5200 solver.cpp:258]     Train net output #0: loss = 0.000350735 (* 1 = 0.000350735 loss)
I0526 03:01:25.713073  5200 sgd_solver.cpp:112] Iteration 7124, lr = 0.005
I0526 03:01:41.397501  5200 solver.cpp:239] Iteration 7150 (1.65774 iter/s, 15.684s/26 iters), loss = 0.00894435
I0526 03:01:41.397640  5200 solver.cpp:258]     Train net output #0: loss = 0.000483059 (* 1 = 0.000483059 loss)
I0526 03:01:41.397650  5200 sgd_solver.cpp:112] Iteration 7150, lr = 0.005
I0526 03:01:57.052371  5200 solver.cpp:239] Iteration 7176 (1.66092 iter/s, 15.654s/26 iters), loss = 0.00962292
I0526 03:01:57.052424  5200 solver.cpp:258]     Train net output #0: loss = 0.000262757 (* 1 = 0.000262757 loss)
I0526 03:01:57.052431  5200 sgd_solver.cpp:112] Iteration 7176, lr = 0.005
I0526 03:02:12.731988  5200 solver.cpp:239] Iteration 7202 (1.65827 iter/s, 15.679s/26 iters), loss = 0.0158308
I0526 03:02:12.732165  5200 solver.cpp:258]     Train net output #0: loss = 0.00121207 (* 1 = 0.00121207 loss)
I0526 03:02:12.732174  5200 sgd_solver.cpp:112] Iteration 7202, lr = 0.005
I0526 03:02:28.370769  5200 solver.cpp:239] Iteration 7228 (1.66262 iter/s, 15.638s/26 iters), loss = 0.00367637
I0526 03:02:28.370827  5200 solver.cpp:258]     Train net output #0: loss = 0.000497778 (* 1 = 0.000497778 loss)
I0526 03:02:28.370834  5200 sgd_solver.cpp:112] Iteration 7228, lr = 0.005
I0526 03:02:44.009279  5200 solver.cpp:239] Iteration 7254 (1.66262 iter/s, 15.638s/26 iters), loss = 0.0174488
I0526 03:02:44.009526  5200 solver.cpp:258]     Train net output #0: loss = 0.0555081 (* 1 = 0.0555081 loss)
I0526 03:02:44.009536  5200 sgd_solver.cpp:112] Iteration 7254, lr = 0.005
I0526 03:02:59.634591  5200 solver.cpp:239] Iteration 7280 (1.664 iter/s, 15.625s/26 iters), loss = 0.0216064
I0526 03:02:59.634649  5200 solver.cpp:258]     Train net output #0: loss = 0.00154616 (* 1 = 0.00154616 loss)
I0526 03:02:59.634656  5200 sgd_solver.cpp:112] Iteration 7280, lr = 0.005
I0526 03:03:15.240830  5200 solver.cpp:239] Iteration 7306 (1.66603 iter/s, 15.606s/26 iters), loss = 0.0237568
I0526 03:03:15.241061  5200 solver.cpp:258]     Train net output #0: loss = 0.0131198 (* 1 = 0.0131198 loss)
I0526 03:03:15.241070  5200 sgd_solver.cpp:112] Iteration 7306, lr = 0.005
I0526 03:03:20.046916  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_7315.caffemodel
I0526 03:03:20.047580  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_7315.solverstate
I0526 03:03:20.047894  5200 solver.cpp:347] Iteration 7315, Testing net (#0)
I0526 03:03:31.073781  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9968
I0526 03:03:31.073832  5200 solver.cpp:414]     Test net output #1: loss = 0.0116487 (* 1 = 0.0116487 loss)
I0526 03:03:31.073837  5200 solver.cpp:347] Iteration 7315, Testing net (#1)
I0526 03:03:52.638948  5200 solver.cpp:414]     Test net output #0: accuracy = 0.800638
I0526 03:03:52.639123  5200 solver.cpp:414]     Test net output #1: loss = 0.572988 (* 1 = 0.572988 loss)
I0526 03:03:52.639130  5200 solver.cpp:347] Iteration 7315, Testing net (#2)
I0526 03:04:43.094301  5200 solver.cpp:414]     Test net output #0: accuracy = 0.980811
I0526 03:04:43.094511  5200 solver.cpp:414]     Test net output #1: loss = 0.059277 (* 1 = 0.059277 loss)
I0526 03:04:53.929697  5200 solver.cpp:239] Iteration 7332 (0.263457 iter/s, 98.688s/26 iters), loss = 0.008638
I0526 03:04:53.929751  5200 solver.cpp:258]     Train net output #0: loss = 0.0284863 (* 1 = 0.0284863 loss)
I0526 03:04:53.929759  5200 sgd_solver.cpp:112] Iteration 7332, lr = 0.005
I0526 03:05:09.587222  5200 solver.cpp:239] Iteration 7358 (1.6606 iter/s, 15.657s/26 iters), loss = 0.00554711
I0526 03:05:09.587278  5200 solver.cpp:258]     Train net output #0: loss = 0.000551265 (* 1 = 0.000551265 loss)
I0526 03:05:09.587286  5200 sgd_solver.cpp:112] Iteration 7358, lr = 0.005
I0526 03:05:25.233409  5200 solver.cpp:239] Iteration 7384 (1.66177 iter/s, 15.646s/26 iters), loss = 0.0137425
I0526 03:05:25.233541  5200 solver.cpp:258]     Train net output #0: loss = 0.0817022 (* 1 = 0.0817022 loss)
I0526 03:05:25.233548  5200 sgd_solver.cpp:112] Iteration 7384, lr = 0.005
I0526 03:05:40.831686  5200 solver.cpp:239] Iteration 7410 (1.66688 iter/s, 15.598s/26 iters), loss = 0.0123101
I0526 03:05:40.831740  5200 solver.cpp:258]     Train net output #0: loss = 0.00342423 (* 1 = 0.00342423 loss)
I0526 03:05:40.831748  5200 sgd_solver.cpp:112] Iteration 7410, lr = 0.005
I0526 03:05:56.457549  5200 solver.cpp:239] Iteration 7436 (1.664 iter/s, 15.625s/26 iters), loss = 0.0208569
I0526 03:05:56.457717  5200 solver.cpp:258]     Train net output #0: loss = 0.00685246 (* 1 = 0.00685246 loss)
I0526 03:05:56.457726  5200 sgd_solver.cpp:112] Iteration 7436, lr = 0.005
I0526 03:06:12.084527  5200 solver.cpp:239] Iteration 7462 (1.66389 iter/s, 15.626s/26 iters), loss = 0.0102879
I0526 03:06:12.084583  5200 solver.cpp:258]     Train net output #0: loss = 0.0475894 (* 1 = 0.0475894 loss)
I0526 03:06:12.084589  5200 sgd_solver.cpp:112] Iteration 7462, lr = 0.005
I0526 03:06:27.709749  5200 solver.cpp:239] Iteration 7488 (1.664 iter/s, 15.625s/26 iters), loss = 0.0213839
I0526 03:06:27.709909  5200 solver.cpp:258]     Train net output #0: loss = 0.00192752 (* 1 = 0.00192752 loss)
I0526 03:06:27.709918  5200 sgd_solver.cpp:112] Iteration 7488, lr = 0.005
I0526 03:06:43.410318  5200 solver.cpp:239] Iteration 7514 (1.65605 iter/s, 15.7s/26 iters), loss = 0.00843018
I0526 03:06:43.410375  5200 solver.cpp:258]     Train net output #0: loss = 0.00318561 (* 1 = 0.00318561 loss)
I0526 03:06:43.410383  5200 sgd_solver.cpp:112] Iteration 7514, lr = 0.005
I0526 03:06:59.057292  5200 solver.cpp:239] Iteration 7540 (1.66177 iter/s, 15.646s/26 iters), loss = 0.0160244
I0526 03:06:59.057421  5200 solver.cpp:258]     Train net output #0: loss = 0.00305965 (* 1 = 0.00305965 loss)
I0526 03:06:59.057430  5200 sgd_solver.cpp:112] Iteration 7540, lr = 0.005
I0526 03:07:14.675487  5200 solver.cpp:239] Iteration 7566 (1.66475 iter/s, 15.618s/26 iters), loss = 0.021851
I0526 03:07:14.675540  5200 solver.cpp:258]     Train net output #0: loss = 0.00161586 (* 1 = 0.00161586 loss)
I0526 03:07:14.675549  5200 sgd_solver.cpp:112] Iteration 7566, lr = 0.005
I0526 03:07:30.257052  5200 solver.cpp:239] Iteration 7592 (1.6687 iter/s, 15.581s/26 iters), loss = 0.00960915
I0526 03:07:30.257287  5200 solver.cpp:258]     Train net output #0: loss = 0.000806426 (* 1 = 0.000806426 loss)
I0526 03:07:30.257297  5200 sgd_solver.cpp:112] Iteration 7592, lr = 0.005
I0526 03:07:45.830446  5200 solver.cpp:239] Iteration 7618 (1.66956 iter/s, 15.573s/26 iters), loss = 0.00985141
I0526 03:07:45.830492  5200 solver.cpp:258]     Train net output #0: loss = 0.000513092 (* 1 = 0.000513092 loss)
I0526 03:07:45.830500  5200 sgd_solver.cpp:112] Iteration 7618, lr = 0.005
I0526 03:08:01.383283  5200 solver.cpp:239] Iteration 7644 (1.67181 iter/s, 15.552s/26 iters), loss = 0.00860347
I0526 03:08:01.383417  5200 solver.cpp:258]     Train net output #0: loss = 0.00160204 (* 1 = 0.00160204 loss)
I0526 03:08:01.383425  5200 sgd_solver.cpp:112] Iteration 7644, lr = 0.005
I0526 03:08:16.959717  5200 solver.cpp:239] Iteration 7670 (1.66923 iter/s, 15.576s/26 iters), loss = 0.0139444
I0526 03:08:16.959769  5200 solver.cpp:258]     Train net output #0: loss = 0.00680775 (* 1 = 0.00680775 loss)
I0526 03:08:16.959777  5200 sgd_solver.cpp:112] Iteration 7670, lr = 0.005
I0526 03:08:32.536161  5200 solver.cpp:239] Iteration 7696 (1.66923 iter/s, 15.576s/26 iters), loss = 0.0170475
I0526 03:08:32.536372  5200 solver.cpp:258]     Train net output #0: loss = 0.00626553 (* 1 = 0.00626553 loss)
I0526 03:08:32.536381  5200 sgd_solver.cpp:112] Iteration 7696, lr = 0.005
I0526 03:08:34.344815  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_7700.caffemodel
I0526 03:08:34.345484  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_7700.solverstate
I0526 03:08:34.345798  5200 solver.cpp:347] Iteration 7700, Testing net (#0)
I0526 03:08:45.435259  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9956
I0526 03:08:45.435310  5200 solver.cpp:414]     Test net output #1: loss = 0.0138019 (* 1 = 0.0138019 loss)
I0526 03:08:45.435317  5200 solver.cpp:347] Iteration 7700, Testing net (#1)
I0526 03:09:07.402091  5200 solver.cpp:414]     Test net output #0: accuracy = 0.730213
I0526 03:09:07.402225  5200 solver.cpp:414]     Test net output #1: loss = 0.95333 (* 1 = 0.95333 loss)
I0526 03:09:07.402233  5200 solver.cpp:347] Iteration 7700, Testing net (#2)
I0526 03:09:57.193491  5200 solver.cpp:414]     Test net output #0: accuracy = 0.979009
I0526 03:09:57.193709  5200 solver.cpp:414]     Test net output #1: loss = 0.0665768 (* 1 = 0.0665768 loss)
I0526 03:10:10.977654  5200 solver.cpp:239] Iteration 7722 (0.264118 iter/s, 98.441s/26 iters), loss = 0.019554
I0526 03:10:10.977711  5200 solver.cpp:258]     Train net output #0: loss = 0.0187069 (* 1 = 0.0187069 loss)
I0526 03:10:10.977718  5200 sgd_solver.cpp:112] Iteration 7722, lr = 0.005
I0526 03:10:26.547184  5200 solver.cpp:239] Iteration 7748 (1.66999 iter/s, 15.569s/26 iters), loss = 0.0292151
I0526 03:10:26.547237  5200 solver.cpp:258]     Train net output #0: loss = 0.0542592 (* 1 = 0.0542592 loss)
I0526 03:10:26.547245  5200 sgd_solver.cpp:112] Iteration 7748, lr = 0.005
I0526 03:10:42.104703  5200 solver.cpp:239] Iteration 7774 (1.67127 iter/s, 15.557s/26 iters), loss = 0.0163598
I0526 03:10:42.104862  5200 solver.cpp:258]     Train net output #0: loss = 0.00196471 (* 1 = 0.00196471 loss)
I0526 03:10:42.104871  5200 sgd_solver.cpp:112] Iteration 7774, lr = 0.005
I0526 03:10:57.679931  5200 solver.cpp:239] Iteration 7800 (1.66934 iter/s, 15.575s/26 iters), loss = 0.010045
I0526 03:10:57.679986  5200 solver.cpp:258]     Train net output #0: loss = 0.00193929 (* 1 = 0.00193929 loss)
I0526 03:10:57.679993  5200 sgd_solver.cpp:112] Iteration 7800, lr = 0.005
I0526 03:11:13.268636  5200 solver.cpp:239] Iteration 7826 (1.66795 iter/s, 15.588s/26 iters), loss = 0.016925
I0526 03:11:13.268803  5200 solver.cpp:258]     Train net output #0: loss = 0.012906 (* 1 = 0.012906 loss)
I0526 03:11:13.268811  5200 sgd_solver.cpp:112] Iteration 7826, lr = 0.005
I0526 03:11:28.840438  5200 solver.cpp:239] Iteration 7852 (1.66977 iter/s, 15.571s/26 iters), loss = 0.0129999
I0526 03:11:28.840494  5200 solver.cpp:258]     Train net output #0: loss = 0.00387311 (* 1 = 0.00387311 loss)
I0526 03:11:28.840502  5200 sgd_solver.cpp:112] Iteration 7852, lr = 0.005
I0526 03:11:44.446794  5200 solver.cpp:239] Iteration 7878 (1.66603 iter/s, 15.606s/26 iters), loss = 0.00688579
I0526 03:11:44.446930  5200 solver.cpp:258]     Train net output #0: loss = 0.0383471 (* 1 = 0.0383471 loss)
I0526 03:11:44.446949  5200 sgd_solver.cpp:112] Iteration 7878, lr = 0.005
I0526 03:12:00.019371  5200 solver.cpp:239] Iteration 7904 (1.66966 iter/s, 15.572s/26 iters), loss = 0.0127533
I0526 03:12:00.019423  5200 solver.cpp:258]     Train net output #0: loss = 0.00726652 (* 1 = 0.00726652 loss)
I0526 03:12:00.019429  5200 sgd_solver.cpp:112] Iteration 7904, lr = 0.005
I0526 03:12:15.594952  5200 solver.cpp:239] Iteration 7930 (1.66934 iter/s, 15.575s/26 iters), loss = 0.00897227
I0526 03:12:15.595116  5200 solver.cpp:258]     Train net output #0: loss = 0.00985923 (* 1 = 0.00985923 loss)
I0526 03:12:15.595124  5200 sgd_solver.cpp:112] Iteration 7930, lr = 0.005
I0526 03:12:31.169749  5200 solver.cpp:239] Iteration 7956 (1.66945 iter/s, 15.574s/26 iters), loss = 0.00623426
I0526 03:12:31.169807  5200 solver.cpp:258]     Train net output #0: loss = 0.000632927 (* 1 = 0.000632927 loss)
I0526 03:12:31.169816  5200 sgd_solver.cpp:112] Iteration 7956, lr = 0.005
I0526 03:12:46.746814  5200 solver.cpp:239] Iteration 7982 (1.66913 iter/s, 15.577s/26 iters), loss = 0.0106891
I0526 03:12:46.746966  5200 solver.cpp:258]     Train net output #0: loss = 0.000381161 (* 1 = 0.000381161 loss)
I0526 03:12:46.746975  5200 sgd_solver.cpp:112] Iteration 7982, lr = 0.005
I0526 03:13:02.327378  5200 solver.cpp:239] Iteration 8008 (1.66881 iter/s, 15.58s/26 iters), loss = 0.00715979
I0526 03:13:02.327427  5200 solver.cpp:258]     Train net output #0: loss = 0.0336804 (* 1 = 0.0336804 loss)
I0526 03:13:02.327433  5200 sgd_solver.cpp:112] Iteration 8008, lr = 0.005
I0526 03:13:17.906149  5200 solver.cpp:239] Iteration 8034 (1.66902 iter/s, 15.578s/26 iters), loss = 0.0175507
I0526 03:13:17.906301  5200 solver.cpp:258]     Train net output #0: loss = 0.00253426 (* 1 = 0.00253426 loss)
I0526 03:13:17.906309  5200 sgd_solver.cpp:112] Iteration 8034, lr = 0.005
I0526 03:13:33.513671  5200 solver.cpp:239] Iteration 8060 (1.66592 iter/s, 15.607s/26 iters), loss = 0.0136965
I0526 03:13:33.513728  5200 solver.cpp:258]     Train net output #0: loss = 0.00185673 (* 1 = 0.00185673 loss)
I0526 03:13:33.513736  5200 sgd_solver.cpp:112] Iteration 8060, lr = 0.005
I0526 03:13:47.949800  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_8085.caffemodel
I0526 03:13:47.950582  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_8085.solverstate
I0526 03:13:47.950914  5200 solver.cpp:347] Iteration 8085, Testing net (#0)
I0526 03:13:58.994943  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9964
I0526 03:13:58.994993  5200 solver.cpp:414]     Test net output #1: loss = 0.0110302 (* 1 = 0.0110302 loss)
I0526 03:13:58.994998  5200 solver.cpp:347] Iteration 8085, Testing net (#1)
I0526 03:14:20.455365  5200 solver.cpp:414]     Test net output #0: accuracy = 0.848724
I0526 03:14:20.455577  5200 solver.cpp:414]     Test net output #1: loss = 0.426056 (* 1 = 0.426056 loss)
I0526 03:14:20.455585  5200 solver.cpp:347] Iteration 8085, Testing net (#2)
I0526 03:15:10.402523  5200 solver.cpp:414]     Test net output #0: accuracy = 0.990901
I0526 03:15:10.402737  5200 solver.cpp:414]     Test net output #1: loss = 0.0317582 (* 1 = 0.0317582 loss)
I0526 03:15:11.617715  5200 solver.cpp:239] Iteration 8086 (0.265028 iter/s, 98.103s/26 iters), loss = 0.0105668
I0526 03:15:11.617770  5200 solver.cpp:258]     Train net output #0: loss = 0.00522992 (* 1 = 0.00522992 loss)
I0526 03:15:11.617779  5200 sgd_solver.cpp:112] Iteration 8086, lr = 0.005
I0526 03:15:27.239323  5200 solver.cpp:239] Iteration 8112 (1.66443 iter/s, 15.621s/26 iters), loss = 0.00739716
I0526 03:15:27.239377  5200 solver.cpp:258]     Train net output #0: loss = 0.00405509 (* 1 = 0.00405509 loss)
I0526 03:15:27.239384  5200 sgd_solver.cpp:112] Iteration 8112, lr = 0.005
I0526 03:15:42.884137  5200 solver.cpp:239] Iteration 8138 (1.66198 iter/s, 15.644s/26 iters), loss = 0.0126882
I0526 03:15:42.884305  5200 solver.cpp:258]     Train net output #0: loss = 0.00161046 (* 1 = 0.00161046 loss)
I0526 03:15:42.884322  5200 sgd_solver.cpp:112] Iteration 8138, lr = 0.005
I0526 03:15:58.536104  5200 solver.cpp:239] Iteration 8164 (1.66124 iter/s, 15.651s/26 iters), loss = 0.00596602
I0526 03:15:58.536157  5200 solver.cpp:258]     Train net output #0: loss = 0.0128816 (* 1 = 0.0128816 loss)
I0526 03:15:58.536165  5200 sgd_solver.cpp:112] Iteration 8164, lr = 0.005
I0526 03:16:14.183070  5200 solver.cpp:239] Iteration 8190 (1.66177 iter/s, 15.646s/26 iters), loss = 0.0146406
I0526 03:16:14.183209  5200 solver.cpp:258]     Train net output #0: loss = 0.0353137 (* 1 = 0.0353137 loss)
I0526 03:16:14.183226  5200 sgd_solver.cpp:112] Iteration 8190, lr = 0.005
I0526 03:16:29.830317  5200 solver.cpp:239] Iteration 8216 (1.66166 iter/s, 15.647s/26 iters), loss = 0.0123075
I0526 03:16:29.830376  5200 solver.cpp:258]     Train net output #0: loss = 0.0296376 (* 1 = 0.0296376 loss)
I0526 03:16:29.830384  5200 sgd_solver.cpp:112] Iteration 8216, lr = 0.005
I0526 03:16:45.616111  5200 solver.cpp:239] Iteration 8242 (1.64713 iter/s, 15.785s/26 iters), loss = 0.011693
I0526 03:16:45.616259  5200 solver.cpp:258]     Train net output #0: loss = 0.00421093 (* 1 = 0.00421093 loss)
I0526 03:16:45.616277  5200 sgd_solver.cpp:112] Iteration 8242, lr = 0.005
I0526 03:17:01.273025  5200 solver.cpp:239] Iteration 8268 (1.66071 iter/s, 15.656s/26 iters), loss = 0.00832031
I0526 03:17:01.273078  5200 solver.cpp:258]     Train net output #0: loss = 0.00413625 (* 1 = 0.00413625 loss)
I0526 03:17:01.273084  5200 sgd_solver.cpp:112] Iteration 8268, lr = 0.005
I0526 03:17:16.918306  5200 solver.cpp:239] Iteration 8294 (1.66187 iter/s, 15.645s/26 iters), loss = 0.00724318
I0526 03:17:16.918435  5200 solver.cpp:258]     Train net output #0: loss = 0.00598203 (* 1 = 0.00598203 loss)
I0526 03:17:16.918444  5200 sgd_solver.cpp:112] Iteration 8294, lr = 0.005
I0526 03:17:32.547075  5200 solver.cpp:239] Iteration 8320 (1.66368 iter/s, 15.628s/26 iters), loss = 0.00557212
I0526 03:17:32.547129  5200 solver.cpp:258]     Train net output #0: loss = 0.000451424 (* 1 = 0.000451424 loss)
I0526 03:17:32.547137  5200 sgd_solver.cpp:112] Iteration 8320, lr = 0.005
I0526 03:17:48.136224  5200 solver.cpp:239] Iteration 8346 (1.66784 iter/s, 15.589s/26 iters), loss = 0.00981111
I0526 03:17:48.136417  5200 solver.cpp:258]     Train net output #0: loss = 0.0434334 (* 1 = 0.0434334 loss)
I0526 03:17:48.136437  5200 sgd_solver.cpp:112] Iteration 8346, lr = 0.005
I0526 03:18:03.698103  5200 solver.cpp:239] Iteration 8372 (1.67084 iter/s, 15.561s/26 iters), loss = 0.011979
I0526 03:18:03.698158  5200 solver.cpp:258]     Train net output #0: loss = 0.0681676 (* 1 = 0.0681676 loss)
I0526 03:18:03.698165  5200 sgd_solver.cpp:112] Iteration 8372, lr = 0.005
I0526 03:18:19.261227  5200 solver.cpp:239] Iteration 8398 (1.67063 iter/s, 15.563s/26 iters), loss = 0.0208926
I0526 03:18:19.261385  5200 solver.cpp:258]     Train net output #0: loss = 0.0189901 (* 1 = 0.0189901 loss)
I0526 03:18:19.261394  5200 sgd_solver.cpp:112] Iteration 8398, lr = 0.005
I0526 03:18:34.816824  5200 solver.cpp:239] Iteration 8424 (1.67149 iter/s, 15.555s/26 iters), loss = 0.00859776
I0526 03:18:34.816874  5200 solver.cpp:258]     Train net output #0: loss = 0.00178604 (* 1 = 0.00178604 loss)
I0526 03:18:34.816881  5200 sgd_solver.cpp:112] Iteration 8424, lr = 0.005
I0526 03:18:50.371258  5200 solver.cpp:239] Iteration 8450 (1.6716 iter/s, 15.554s/26 iters), loss = 0.00776586
I0526 03:18:50.371384  5200 solver.cpp:258]     Train net output #0: loss = 0.0328562 (* 1 = 0.0328562 loss)
I0526 03:18:50.371393  5200 sgd_solver.cpp:112] Iteration 8450, lr = 0.005
I0526 03:19:01.789378  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_8470.caffemodel
I0526 03:19:01.790061  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_8470.solverstate
I0526 03:19:01.790372  5200 solver.cpp:347] Iteration 8470, Testing net (#0)
I0526 03:19:12.820261  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9972
I0526 03:19:12.820313  5200 solver.cpp:414]     Test net output #1: loss = 0.00597888 (* 1 = 0.00597888 loss)
I0526 03:19:12.820318  5200 solver.cpp:347] Iteration 8470, Testing net (#1)
I0526 03:19:34.261458  5200 solver.cpp:414]     Test net output #0: accuracy = 0.670638
I0526 03:19:34.261626  5200 solver.cpp:414]     Test net output #1: loss = 1.37863 (* 1 = 1.37863 loss)
I0526 03:19:34.261641  5200 solver.cpp:347] Iteration 8470, Testing net (#2)
I0526 03:20:24.538947  5200 solver.cpp:414]     Test net output #0: accuracy = 0.966937
I0526 03:20:24.539077  5200 solver.cpp:414]     Test net output #1: loss = 0.102166 (* 1 = 0.102166 loss)
I0526 03:20:28.812043  5200 solver.cpp:239] Iteration 8476 (0.26412 iter/s, 98.44s/26 iters), loss = 0.00809217
I0526 03:20:28.812098  5200 solver.cpp:258]     Train net output #0: loss = 0.0012215 (* 1 = 0.0012215 loss)
I0526 03:20:28.812106  5200 sgd_solver.cpp:112] Iteration 8476, lr = 0.005
I0526 03:20:44.641197  5200 solver.cpp:239] Iteration 8502 (1.64255 iter/s, 15.829s/26 iters), loss = 0.0151778
I0526 03:20:44.641248  5200 solver.cpp:258]     Train net output #0: loss = 0.018212 (* 1 = 0.018212 loss)
I0526 03:20:44.641255  5200 sgd_solver.cpp:112] Iteration 8502, lr = 0.005
I0526 03:21:00.492628  5200 solver.cpp:239] Iteration 8528 (1.64028 iter/s, 15.851s/26 iters), loss = 0.0147389
I0526 03:21:00.492830  5200 solver.cpp:258]     Train net output #0: loss = 0.0101696 (* 1 = 0.0101696 loss)
I0526 03:21:00.492837  5200 sgd_solver.cpp:112] Iteration 8528, lr = 0.005
I0526 03:21:16.310063  5200 solver.cpp:239] Iteration 8554 (1.6438 iter/s, 15.817s/26 iters), loss = 0.0172053
I0526 03:21:16.310107  5200 solver.cpp:258]     Train net output #0: loss = 0.00269839 (* 1 = 0.00269839 loss)
I0526 03:21:16.310113  5200 sgd_solver.cpp:112] Iteration 8554, lr = 0.005
I0526 03:21:32.103983  5200 solver.cpp:239] Iteration 8580 (1.6463 iter/s, 15.793s/26 iters), loss = 0.0108821
I0526 03:21:32.104163  5200 solver.cpp:258]     Train net output #0: loss = 0.00101886 (* 1 = 0.00101886 loss)
I0526 03:21:32.104171  5200 sgd_solver.cpp:112] Iteration 8580, lr = 0.005
I0526 03:21:48.062623  5200 solver.cpp:239] Iteration 8606 (1.62928 iter/s, 15.958s/26 iters), loss = 0.0111897
I0526 03:21:48.062683  5200 solver.cpp:258]     Train net output #0: loss = 0.0141466 (* 1 = 0.0141466 loss)
I0526 03:21:48.062690  5200 sgd_solver.cpp:112] Iteration 8606, lr = 0.005
I0526 03:22:03.900041  5200 solver.cpp:239] Iteration 8632 (1.64173 iter/s, 15.837s/26 iters), loss = 0.00752269
I0526 03:22:03.900225  5200 solver.cpp:258]     Train net output #0: loss = 0.00255766 (* 1 = 0.00255766 loss)
I0526 03:22:03.900235  5200 sgd_solver.cpp:112] Iteration 8632, lr = 0.005
I0526 03:22:19.774755  5200 solver.cpp:239] Iteration 8658 (1.6379 iter/s, 15.874s/26 iters), loss = 0.0146154
I0526 03:22:19.774812  5200 solver.cpp:258]     Train net output #0: loss = 0.00214039 (* 1 = 0.00214039 loss)
I0526 03:22:19.774821  5200 sgd_solver.cpp:112] Iteration 8658, lr = 0.005
I0526 03:22:35.637012  5200 solver.cpp:239] Iteration 8684 (1.63914 iter/s, 15.862s/26 iters), loss = 0.0137531
I0526 03:22:35.637164  5200 solver.cpp:258]     Train net output #0: loss = 0.00271982 (* 1 = 0.00271982 loss)
I0526 03:22:35.637173  5200 sgd_solver.cpp:112] Iteration 8684, lr = 0.005
I0526 03:22:51.486342  5200 solver.cpp:239] Iteration 8710 (1.64048 iter/s, 15.849s/26 iters), loss = 0.0058701
I0526 03:22:51.486399  5200 solver.cpp:258]     Train net output #0: loss = 0.00127512 (* 1 = 0.00127512 loss)
I0526 03:22:51.486407  5200 sgd_solver.cpp:112] Iteration 8710, lr = 0.005
I0526 03:23:07.361109  5200 solver.cpp:239] Iteration 8736 (1.6379 iter/s, 15.874s/26 iters), loss = 0.00824652
I0526 03:23:07.361272  5200 solver.cpp:258]     Train net output #0: loss = 0.00211146 (* 1 = 0.00211146 loss)
I0526 03:23:07.361290  5200 sgd_solver.cpp:112] Iteration 8736, lr = 0.005
I0526 03:23:23.184146  5200 solver.cpp:239] Iteration 8762 (1.64328 iter/s, 15.822s/26 iters), loss = 0.0135805
I0526 03:23:23.184202  5200 solver.cpp:258]     Train net output #0: loss = 0.0181644 (* 1 = 0.0181644 loss)
I0526 03:23:23.184209  5200 sgd_solver.cpp:112] Iteration 8762, lr = 0.005
I0526 03:23:39.000274  5200 solver.cpp:239] Iteration 8788 (1.6439 iter/s, 15.816s/26 iters), loss = 0.0110037
I0526 03:23:39.000449  5200 solver.cpp:258]     Train net output #0: loss = 0.00614083 (* 1 = 0.00614083 loss)
I0526 03:23:39.000468  5200 sgd_solver.cpp:112] Iteration 8788, lr = 0.005
I0526 03:23:54.855724  5200 solver.cpp:239] Iteration 8814 (1.63986 iter/s, 15.855s/26 iters), loss = 0.00831364
I0526 03:23:54.855777  5200 solver.cpp:258]     Train net output #0: loss = 0.0150442 (* 1 = 0.0150442 loss)
I0526 03:23:54.855784  5200 sgd_solver.cpp:112] Iteration 8814, lr = 0.005
I0526 03:24:10.698738  5200 solver.cpp:239] Iteration 8840 (1.64121 iter/s, 15.842s/26 iters), loss = 0.0106236
I0526 03:24:10.698873  5200 solver.cpp:258]     Train net output #0: loss = 0.00607183 (* 1 = 0.00607183 loss)
I0526 03:24:10.698880  5200 sgd_solver.cpp:112] Iteration 8840, lr = 0.005
I0526 03:24:19.194243  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_8855.caffemodel
I0526 03:24:19.197834  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_8855.solverstate
I0526 03:24:19.198278  5200 solver.cpp:347] Iteration 8855, Testing net (#0)
I0526 03:24:30.465332  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9964
I0526 03:24:30.465378  5200 solver.cpp:414]     Test net output #1: loss = 0.00997234 (* 1 = 0.00997234 loss)
I0526 03:24:30.465384  5200 solver.cpp:347] Iteration 8855, Testing net (#1)
I0526 03:24:52.576648  5200 solver.cpp:414]     Test net output #0: accuracy = 0.861489
I0526 03:24:52.576848  5200 solver.cpp:414]     Test net output #1: loss = 0.413318 (* 1 = 0.413318 loss)
I0526 03:24:52.576858  5200 solver.cpp:347] Iteration 8855, Testing net (#2)
I0526 03:25:43.137420  5200 solver.cpp:414]     Test net output #0: accuracy = 0.991622
I0526 03:25:43.137552  5200 solver.cpp:414]     Test net output #1: loss = 0.0340703 (* 1 = 0.0340703 loss)
I0526 03:25:50.439666  5200 solver.cpp:239] Iteration 8866 (0.260678 iter/s, 99.74s/26 iters), loss = 0.00849568
I0526 03:25:50.439721  5200 solver.cpp:258]     Train net output #0: loss = 0.0011161 (* 1 = 0.0011161 loss)
I0526 03:25:50.439729  5200 sgd_solver.cpp:112] Iteration 8866, lr = 0.005
I0526 03:26:06.252036  5200 solver.cpp:239] Iteration 8892 (1.64432 iter/s, 15.812s/26 iters), loss = 0.00816382
I0526 03:26:06.252095  5200 solver.cpp:258]     Train net output #0: loss = 0.000829375 (* 1 = 0.000829375 loss)
I0526 03:26:06.252104  5200 sgd_solver.cpp:112] Iteration 8892, lr = 0.005
I0526 03:26:22.088883  5200 solver.cpp:239] Iteration 8918 (1.64183 iter/s, 15.836s/26 iters), loss = 0.0117646
I0526 03:26:22.089098  5200 solver.cpp:258]     Train net output #0: loss = 0.00307414 (* 1 = 0.00307414 loss)
I0526 03:26:22.089107  5200 sgd_solver.cpp:112] Iteration 8918, lr = 0.005
I0526 03:26:37.887104  5200 solver.cpp:239] Iteration 8944 (1.64578 iter/s, 15.798s/26 iters), loss = 0.00670167
I0526 03:26:37.887158  5200 solver.cpp:258]     Train net output #0: loss = 0.0107072 (* 1 = 0.0107072 loss)
I0526 03:26:37.887166  5200 sgd_solver.cpp:112] Iteration 8944, lr = 0.005
I0526 03:26:53.738680  5200 solver.cpp:239] Iteration 8970 (1.64028 iter/s, 15.851s/26 iters), loss = 0.00441454
I0526 03:26:53.738860  5200 solver.cpp:258]     Train net output #0: loss = 0.000240978 (* 1 = 0.000240978 loss)
I0526 03:26:53.738878  5200 sgd_solver.cpp:112] Iteration 8970, lr = 0.005
I0526 03:27:09.529441  5200 solver.cpp:239] Iteration 8996 (1.64661 iter/s, 15.79s/26 iters), loss = 0.0157901
I0526 03:27:09.529494  5200 solver.cpp:258]     Train net output #0: loss = 0.0010777 (* 1 = 0.0010777 loss)
I0526 03:27:09.529500  5200 sgd_solver.cpp:112] Iteration 8996, lr = 0.005
I0526 03:27:25.186273  5200 solver.cpp:239] Iteration 9022 (1.66071 iter/s, 15.656s/26 iters), loss = 0.00409988
I0526 03:27:25.186444  5200 solver.cpp:258]     Train net output #0: loss = 0.00280492 (* 1 = 0.00280492 loss)
I0526 03:27:25.186452  5200 sgd_solver.cpp:112] Iteration 9022, lr = 0.005
I0526 03:27:40.837137  5200 solver.cpp:239] Iteration 9048 (1.66134 iter/s, 15.65s/26 iters), loss = 0.0169097
I0526 03:27:40.837189  5200 solver.cpp:258]     Train net output #0: loss = 0.00193813 (* 1 = 0.00193813 loss)
I0526 03:27:40.837196  5200 sgd_solver.cpp:112] Iteration 9048, lr = 0.005
I0526 03:27:56.496932  5200 solver.cpp:239] Iteration 9074 (1.66039 iter/s, 15.659s/26 iters), loss = 0.0177445
I0526 03:27:56.497167  5200 solver.cpp:258]     Train net output #0: loss = 0.00339052 (* 1 = 0.00339052 loss)
I0526 03:27:56.497176  5200 sgd_solver.cpp:112] Iteration 9074, lr = 0.005
I0526 03:28:12.131296  5200 solver.cpp:239] Iteration 9100 (1.66304 iter/s, 15.634s/26 iters), loss = 0.0143953
I0526 03:28:12.131347  5200 solver.cpp:258]     Train net output #0: loss = 0.0174698 (* 1 = 0.0174698 loss)
I0526 03:28:12.131356  5200 sgd_solver.cpp:112] Iteration 9100, lr = 0.005
I0526 03:28:27.797921  5200 solver.cpp:239] Iteration 9126 (1.65965 iter/s, 15.666s/26 iters), loss = 0.0118097
I0526 03:28:27.798086  5200 solver.cpp:258]     Train net output #0: loss = 0.00304496 (* 1 = 0.00304496 loss)
I0526 03:28:27.798094  5200 sgd_solver.cpp:112] Iteration 9126, lr = 0.005
I0526 03:28:43.463064  5200 solver.cpp:239] Iteration 9152 (1.65986 iter/s, 15.664s/26 iters), loss = 0.0126972
I0526 03:28:43.463117  5200 solver.cpp:258]     Train net output #0: loss = 0.00123125 (* 1 = 0.00123125 loss)
I0526 03:28:43.463125  5200 sgd_solver.cpp:112] Iteration 9152, lr = 0.005
I0526 03:28:59.067291  5200 solver.cpp:239] Iteration 9178 (1.66624 iter/s, 15.604s/26 iters), loss = 0.0105333
I0526 03:28:59.067445  5200 solver.cpp:258]     Train net output #0: loss = 0.000813894 (* 1 = 0.000813894 loss)
I0526 03:28:59.067453  5200 sgd_solver.cpp:112] Iteration 9178, lr = 0.005
I0526 03:29:14.665300  5200 solver.cpp:239] Iteration 9204 (1.66699 iter/s, 15.597s/26 iters), loss = 0.00791617
I0526 03:29:14.665352  5200 solver.cpp:258]     Train net output #0: loss = 0.0144164 (* 1 = 0.0144164 loss)
I0526 03:29:14.665360  5200 sgd_solver.cpp:112] Iteration 9204, lr = 0.005
I0526 03:29:30.271762  5200 solver.cpp:239] Iteration 9230 (1.66603 iter/s, 15.606s/26 iters), loss = 0.0091302
I0526 03:29:30.271965  5200 solver.cpp:258]     Train net output #0: loss = 0.00062249 (* 1 = 0.00062249 loss)
I0526 03:29:30.271975  5200 sgd_solver.cpp:112] Iteration 9230, lr = 0.0025
I0526 03:29:35.689400  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_9240.caffemodel
I0526 03:29:35.693003  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_9240.solverstate
I0526 03:29:35.693446  5200 solver.cpp:347] Iteration 9240, Testing net (#0)
I0526 03:29:46.749927  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9988
I0526 03:29:46.749977  5200 solver.cpp:414]     Test net output #1: loss = 0.00327309 (* 1 = 0.00327309 loss)
I0526 03:29:46.749982  5200 solver.cpp:347] Iteration 9240, Testing net (#1)
I0526 03:30:08.339705  5200 solver.cpp:414]     Test net output #0: accuracy = 0.861702
I0526 03:30:08.339946  5200 solver.cpp:414]     Test net output #1: loss = 0.378257 (* 1 = 0.378257 loss)
I0526 03:30:08.339952  5200 solver.cpp:347] Iteration 9240, Testing net (#2)
I0526 03:30:58.126286  5200 solver.cpp:414]     Test net output #0: accuracy = 0.990631
I0526 03:30:58.126488  5200 solver.cpp:414]     Test net output #1: loss = 0.0332394 (* 1 = 0.0332394 loss)
I0526 03:31:08.327244  5200 solver.cpp:239] Iteration 9256 (0.265157 iter/s, 98.055s/26 iters), loss = 0.00888546
I0526 03:31:08.327297  5200 solver.cpp:258]     Train net output #0: loss = 0.0139712 (* 1 = 0.0139712 loss)
I0526 03:31:08.327306  5200 sgd_solver.cpp:112] Iteration 9256, lr = 0.0025
I0526 03:31:23.902962  5200 solver.cpp:239] Iteration 9282 (1.66934 iter/s, 15.575s/26 iters), loss = 0.00383341
I0526 03:31:23.903017  5200 solver.cpp:258]     Train net output #0: loss = 0.00619974 (* 1 = 0.00619974 loss)
I0526 03:31:23.903025  5200 sgd_solver.cpp:112] Iteration 9282, lr = 0.0025
I0526 03:31:39.479624  5200 solver.cpp:239] Iteration 9308 (1.66923 iter/s, 15.576s/26 iters), loss = 0.00724152
I0526 03:31:39.479809  5200 solver.cpp:258]     Train net output #0: loss = 0.00130448 (* 1 = 0.00130448 loss)
I0526 03:31:39.479818  5200 sgd_solver.cpp:112] Iteration 9308, lr = 0.0025
I0526 03:31:55.150707  5200 solver.cpp:239] Iteration 9334 (1.65922 iter/s, 15.67s/26 iters), loss = 0.0109261
I0526 03:31:55.150763  5200 solver.cpp:258]     Train net output #0: loss = 0.00160399 (* 1 = 0.00160399 loss)
I0526 03:31:55.150769  5200 sgd_solver.cpp:112] Iteration 9334, lr = 0.0025
I0526 03:32:10.740651  5200 solver.cpp:239] Iteration 9360 (1.66784 iter/s, 15.589s/26 iters), loss = 0.0145459
I0526 03:32:10.740800  5200 solver.cpp:258]     Train net output #0: loss = 0.000855345 (* 1 = 0.000855345 loss)
I0526 03:32:10.740819  5200 sgd_solver.cpp:112] Iteration 9360, lr = 0.0025
I0526 03:32:26.304065  5200 solver.cpp:239] Iteration 9386 (1.67063 iter/s, 15.563s/26 iters), loss = 0.00767194
I0526 03:32:26.304119  5200 solver.cpp:258]     Train net output #0: loss = 0.00687374 (* 1 = 0.00687374 loss)
I0526 03:32:26.304126  5200 sgd_solver.cpp:112] Iteration 9386, lr = 0.0025
I0526 03:32:41.860474  5200 solver.cpp:239] Iteration 9412 (1.67138 iter/s, 15.556s/26 iters), loss = 0.00737125
I0526 03:32:41.860697  5200 solver.cpp:258]     Train net output #0: loss = 0.000471889 (* 1 = 0.000471889 loss)
I0526 03:32:41.860705  5200 sgd_solver.cpp:112] Iteration 9412, lr = 0.0025
I0526 03:32:57.459156  5200 solver.cpp:239] Iteration 9438 (1.66688 iter/s, 15.598s/26 iters), loss = 0.0041056
I0526 03:32:57.459208  5200 solver.cpp:258]     Train net output #0: loss = 0.000316697 (* 1 = 0.000316697 loss)
I0526 03:32:57.459215  5200 sgd_solver.cpp:112] Iteration 9438, lr = 0.0025
I0526 03:33:13.034713  5200 solver.cpp:239] Iteration 9464 (1.66934 iter/s, 15.575s/26 iters), loss = 0.00763915
I0526 03:33:13.034868  5200 solver.cpp:258]     Train net output #0: loss = 0.00595752 (* 1 = 0.00595752 loss)
I0526 03:33:13.034875  5200 sgd_solver.cpp:112] Iteration 9464, lr = 0.0025
I0526 03:33:28.611472  5200 solver.cpp:239] Iteration 9490 (1.66923 iter/s, 15.576s/26 iters), loss = 0.00532481
I0526 03:33:28.611526  5200 solver.cpp:258]     Train net output #0: loss = 0.000389251 (* 1 = 0.000389251 loss)
I0526 03:33:28.611534  5200 sgd_solver.cpp:112] Iteration 9490, lr = 0.0025
I0526 03:33:44.181779  5200 solver.cpp:239] Iteration 9516 (1.66988 iter/s, 15.57s/26 iters), loss = 0.00467671
I0526 03:33:44.181962  5200 solver.cpp:258]     Train net output #0: loss = 0.000317982 (* 1 = 0.000317982 loss)
I0526 03:33:44.181970  5200 sgd_solver.cpp:112] Iteration 9516, lr = 0.0025
I0526 03:33:59.742067  5200 solver.cpp:239] Iteration 9542 (1.67095 iter/s, 15.56s/26 iters), loss = 0.00576836
I0526 03:33:59.742125  5200 solver.cpp:258]     Train net output #0: loss = 0.000542045 (* 1 = 0.000542045 loss)
I0526 03:33:59.742132  5200 sgd_solver.cpp:112] Iteration 9542, lr = 0.0025
I0526 03:34:15.302579  5200 solver.cpp:239] Iteration 9568 (1.67095 iter/s, 15.56s/26 iters), loss = 0.00225467
I0526 03:34:15.302749  5200 solver.cpp:258]     Train net output #0: loss = 0.000320483 (* 1 = 0.000320483 loss)
I0526 03:34:15.302757  5200 sgd_solver.cpp:112] Iteration 9568, lr = 0.0025
I0526 03:34:30.866799  5200 solver.cpp:239] Iteration 9594 (1.67052 iter/s, 15.564s/26 iters), loss = 0.00389712
I0526 03:34:30.866858  5200 solver.cpp:258]     Train net output #0: loss = 0.00136979 (* 1 = 0.00136979 loss)
I0526 03:34:30.866865  5200 sgd_solver.cpp:112] Iteration 9594, lr = 0.0025
I0526 03:34:46.442600  5200 solver.cpp:239] Iteration 9620 (1.66934 iter/s, 15.575s/26 iters), loss = 0.00761084
I0526 03:34:46.442764  5200 solver.cpp:258]     Train net output #0: loss = 0.000679905 (* 1 = 0.000679905 loss)
I0526 03:34:46.442772  5200 sgd_solver.cpp:112] Iteration 9620, lr = 0.0025
I0526 03:34:48.837574  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_9625.caffemodel
I0526 03:34:48.838243  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_9625.solverstate
I0526 03:34:48.838562  5200 solver.cpp:347] Iteration 9625, Testing net (#0)
I0526 03:34:59.918998  5200 solver.cpp:414]     Test net output #0: accuracy = 0.998
I0526 03:34:59.919047  5200 solver.cpp:414]     Test net output #1: loss = 0.00602192 (* 1 = 0.00602192 loss)
I0526 03:34:59.919054  5200 solver.cpp:347] Iteration 9625, Testing net (#1)
I0526 03:35:21.888641  5200 solver.cpp:414]     Test net output #0: accuracy = 0.751277
I0526 03:35:21.888806  5200 solver.cpp:414]     Test net output #1: loss = 0.887918 (* 1 = 0.887918 loss)
I0526 03:35:21.888814  5200 solver.cpp:347] Iteration 9625, Testing net (#2)
I0526 03:36:11.708854  5200 solver.cpp:414]     Test net output #0: accuracy = 0.979189
I0526 03:36:11.708987  5200 solver.cpp:414]     Test net output #1: loss = 0.0604873 (* 1 = 0.0604873 loss)
I0526 03:36:24.884853  5200 solver.cpp:239] Iteration 9646 (0.264115 iter/s, 98.442s/26 iters), loss = 0.010084
I0526 03:36:24.884909  5200 solver.cpp:258]     Train net output #0: loss = 0.00256988 (* 1 = 0.00256988 loss)
I0526 03:36:24.884917  5200 sgd_solver.cpp:112] Iteration 9646, lr = 0.0025
I0526 03:36:40.517544  5200 solver.cpp:239] Iteration 9672 (1.66325 iter/s, 15.632s/26 iters), loss = 0.00487179
I0526 03:36:40.517602  5200 solver.cpp:258]     Train net output #0: loss = 0.000708199 (* 1 = 0.000708199 loss)
I0526 03:36:40.517613  5200 sgd_solver.cpp:112] Iteration 9672, lr = 0.0025
I0526 03:36:56.172044  5200 solver.cpp:239] Iteration 9698 (1.66092 iter/s, 15.654s/26 iters), loss = 0.00883235
I0526 03:36:56.172179  5200 solver.cpp:258]     Train net output #0: loss = 0.00196946 (* 1 = 0.00196946 loss)
I0526 03:36:56.172188  5200 sgd_solver.cpp:112] Iteration 9698, lr = 0.0025
I0526 03:37:11.771795  5200 solver.cpp:239] Iteration 9724 (1.66677 iter/s, 15.599s/26 iters), loss = 0.0103057
I0526 03:37:11.771848  5200 solver.cpp:258]     Train net output #0: loss = 0.00410451 (* 1 = 0.00410451 loss)
I0526 03:37:11.771857  5200 sgd_solver.cpp:112] Iteration 9724, lr = 0.0025
I0526 03:37:27.352021  5200 solver.cpp:239] Iteration 9750 (1.66881 iter/s, 15.58s/26 iters), loss = 0.00651644
I0526 03:37:27.352197  5200 solver.cpp:258]     Train net output #0: loss = 0.000856506 (* 1 = 0.000856506 loss)
I0526 03:37:27.352205  5200 sgd_solver.cpp:112] Iteration 9750, lr = 0.0025
I0526 03:37:42.945330  5200 solver.cpp:239] Iteration 9776 (1.66741 iter/s, 15.593s/26 iters), loss = 0.00963152
I0526 03:37:42.945384  5200 solver.cpp:258]     Train net output #0: loss = 0.00246255 (* 1 = 0.00246255 loss)
I0526 03:37:42.945391  5200 sgd_solver.cpp:112] Iteration 9776, lr = 0.0025
I0526 03:37:58.539228  5200 solver.cpp:239] Iteration 9802 (1.66741 iter/s, 15.593s/26 iters), loss = 0.0114123
I0526 03:37:58.539397  5200 solver.cpp:258]     Train net output #0: loss = 0.00355491 (* 1 = 0.00355491 loss)
I0526 03:37:58.539414  5200 sgd_solver.cpp:112] Iteration 9802, lr = 0.0025
I0526 03:38:14.128334  5200 solver.cpp:239] Iteration 9828 (1.66795 iter/s, 15.588s/26 iters), loss = 0.0105106
I0526 03:38:14.128381  5200 solver.cpp:258]     Train net output #0: loss = 0.101401 (* 1 = 0.101401 loss)
I0526 03:38:14.128388  5200 sgd_solver.cpp:112] Iteration 9828, lr = 0.0025
I0526 03:38:29.724823  5200 solver.cpp:239] Iteration 9854 (1.66709 iter/s, 15.596s/26 iters), loss = 0.00956986
I0526 03:38:29.725011  5200 solver.cpp:258]     Train net output #0: loss = 0.000990725 (* 1 = 0.000990725 loss)
I0526 03:38:29.725019  5200 sgd_solver.cpp:112] Iteration 9854, lr = 0.0025
I0526 03:38:45.317796  5200 solver.cpp:239] Iteration 9880 (1.66752 iter/s, 15.592s/26 iters), loss = 0.00483049
I0526 03:38:45.317847  5200 solver.cpp:258]     Train net output #0: loss = 0.00117177 (* 1 = 0.00117177 loss)
I0526 03:38:45.317855  5200 sgd_solver.cpp:112] Iteration 9880, lr = 0.0025
I0526 03:39:00.899274  5200 solver.cpp:239] Iteration 9906 (1.6687 iter/s, 15.581s/26 iters), loss = 0.0105158
I0526 03:39:00.899451  5200 solver.cpp:258]     Train net output #0: loss = 0.000757876 (* 1 = 0.000757876 loss)
I0526 03:39:00.899468  5200 sgd_solver.cpp:112] Iteration 9906, lr = 0.0025
I0526 03:39:16.479833  5200 solver.cpp:239] Iteration 9932 (1.66881 iter/s, 15.58s/26 iters), loss = 0.00369849
I0526 03:39:16.479887  5200 solver.cpp:258]     Train net output #0: loss = 0.000190061 (* 1 = 0.000190061 loss)
I0526 03:39:16.479893  5200 sgd_solver.cpp:112] Iteration 9932, lr = 0.0025
I0526 03:39:32.061667  5200 solver.cpp:239] Iteration 9958 (1.6687 iter/s, 15.581s/26 iters), loss = 0.00636893
I0526 03:39:32.061820  5200 solver.cpp:258]     Train net output #0: loss = 0.0010279 (* 1 = 0.0010279 loss)
I0526 03:39:32.061828  5200 sgd_solver.cpp:112] Iteration 9958, lr = 0.0025
I0526 03:39:47.650792  5200 solver.cpp:239] Iteration 9984 (1.66795 iter/s, 15.588s/26 iters), loss = 0.00157606
I0526 03:39:47.650846  5200 solver.cpp:258]     Train net output #0: loss = 0.000289519 (* 1 = 0.000289519 loss)
I0526 03:39:47.650853  5200 sgd_solver.cpp:112] Iteration 9984, lr = 0.0025
I0526 03:40:02.636170  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_10010.caffemodel
I0526 03:40:02.636896  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_10010.solverstate
I0526 03:40:02.637202  5200 solver.cpp:347] Iteration 10010, Testing net (#0)
I0526 03:40:13.687651  5200 solver.cpp:414]     Test net output #0: accuracy = 0.996
I0526 03:40:13.687700  5200 solver.cpp:414]     Test net output #1: loss = 0.0087432 (* 1 = 0.0087432 loss)
I0526 03:40:13.687705  5200 solver.cpp:347] Iteration 10010, Testing net (#1)
I0526 03:40:35.654584  5200 solver.cpp:414]     Test net output #0: accuracy = 0.770851
I0526 03:40:35.654716  5200 solver.cpp:414]     Test net output #1: loss = 0.812923 (* 1 = 0.812923 loss)
I0526 03:40:35.654722  5200 solver.cpp:347] Iteration 10010, Testing net (#2)
I0526 03:41:25.504066  5200 solver.cpp:414]     Test net output #0: accuracy = 0.984685
I0526 03:41:25.504231  5200 solver.cpp:414]     Test net output #1: loss = 0.0437992 (* 1 = 0.0437992 loss)
I0526 03:41:26.104900  5200 solver.cpp:239] Iteration 10010 (0.264083 iter/s, 98.454s/26 iters), loss = 0.00546871
I0526 03:41:26.104955  5200 solver.cpp:258]     Train net output #0: loss = 0.00134722 (* 1 = 0.00134722 loss)
I0526 03:41:26.104964  5200 sgd_solver.cpp:112] Iteration 10010, lr = 0.0025
I0526 03:41:41.716114  5200 solver.cpp:239] Iteration 10036 (1.66549 iter/s, 15.611s/26 iters), loss = 0.0104757
I0526 03:41:41.716168  5200 solver.cpp:258]     Train net output #0: loss = 0.000869627 (* 1 = 0.000869627 loss)
I0526 03:41:41.716176  5200 sgd_solver.cpp:112] Iteration 10036, lr = 0.0025
I0526 03:41:57.387795  5200 solver.cpp:239] Iteration 10062 (1.65912 iter/s, 15.671s/26 iters), loss = 0.0137546
I0526 03:41:57.388067  5200 solver.cpp:258]     Train net output #0: loss = 0.00178917 (* 1 = 0.00178917 loss)
I0526 03:41:57.388077  5200 sgd_solver.cpp:112] Iteration 10062, lr = 0.0025
I0526 03:42:13.045398  5200 solver.cpp:239] Iteration 10088 (1.6606 iter/s, 15.657s/26 iters), loss = 0.00745176
I0526 03:42:13.045454  5200 solver.cpp:258]     Train net output #0: loss = 0.0103103 (* 1 = 0.0103103 loss)
I0526 03:42:13.045462  5200 sgd_solver.cpp:112] Iteration 10088, lr = 0.0025
I0526 03:42:28.702980  5200 solver.cpp:239] Iteration 10114 (1.6606 iter/s, 15.657s/26 iters), loss = 0.00235866
I0526 03:42:28.703112  5200 solver.cpp:258]     Train net output #0: loss = 0.000562068 (* 1 = 0.000562068 loss)
I0526 03:42:28.703121  5200 sgd_solver.cpp:112] Iteration 10114, lr = 0.0025
I0526 03:42:44.366029  5200 solver.cpp:239] Iteration 10140 (1.66007 iter/s, 15.662s/26 iters), loss = 0.00322628
I0526 03:42:44.366082  5200 solver.cpp:258]     Train net output #0: loss = 0.0203092 (* 1 = 0.0203092 loss)
I0526 03:42:44.366088  5200 sgd_solver.cpp:112] Iteration 10140, lr = 0.0025
I0526 03:43:00.037562  5200 solver.cpp:239] Iteration 10166 (1.65912 iter/s, 15.671s/26 iters), loss = 0.00542828
I0526 03:43:00.037760  5200 solver.cpp:258]     Train net output #0: loss = 0.00971781 (* 1 = 0.00971781 loss)
I0526 03:43:00.037768  5200 sgd_solver.cpp:112] Iteration 10166, lr = 0.0025
I0526 03:43:15.705556  5200 solver.cpp:239] Iteration 10192 (1.65954 iter/s, 15.667s/26 iters), loss = 0.0068673
I0526 03:43:15.705613  5200 solver.cpp:258]     Train net output #0: loss = 0.000536499 (* 1 = 0.000536499 loss)
I0526 03:43:15.705621  5200 sgd_solver.cpp:112] Iteration 10192, lr = 0.0025
I0526 03:43:31.426178  5200 solver.cpp:239] Iteration 10218 (1.65394 iter/s, 15.72s/26 iters), loss = 0.0112079
I0526 03:43:31.426378  5200 solver.cpp:258]     Train net output #0: loss = 0.0441376 (* 1 = 0.0441376 loss)
I0526 03:43:31.426388  5200 sgd_solver.cpp:112] Iteration 10218, lr = 0.0025
I0526 03:43:47.260393  5200 solver.cpp:239] Iteration 10244 (1.64204 iter/s, 15.834s/26 iters), loss = 0.00829285
I0526 03:43:47.260437  5200 solver.cpp:258]     Train net output #0: loss = 0.000609483 (* 1 = 0.000609483 loss)
I0526 03:43:47.260443  5200 sgd_solver.cpp:112] Iteration 10244, lr = 0.0025
I0526 03:44:02.904253  5200 solver.cpp:239] Iteration 10270 (1.66209 iter/s, 15.643s/26 iters), loss = 0.00629661
I0526 03:44:02.904409  5200 solver.cpp:258]     Train net output #0: loss = 0.000259152 (* 1 = 0.000259152 loss)
I0526 03:44:02.904417  5200 sgd_solver.cpp:112] Iteration 10270, lr = 0.0025
I0526 03:44:18.489543  5200 solver.cpp:239] Iteration 10296 (1.66827 iter/s, 15.585s/26 iters), loss = 0.00533656
I0526 03:44:18.489598  5200 solver.cpp:258]     Train net output #0: loss = 0.00310013 (* 1 = 0.00310013 loss)
I0526 03:44:18.489604  5200 sgd_solver.cpp:112] Iteration 10296, lr = 0.0025
I0526 03:44:34.065785  5200 solver.cpp:239] Iteration 10322 (1.66923 iter/s, 15.576s/26 iters), loss = 0.00581879
I0526 03:44:34.065929  5200 solver.cpp:258]     Train net output #0: loss = 0.00305765 (* 1 = 0.00305765 loss)
I0526 03:44:34.065948  5200 sgd_solver.cpp:112] Iteration 10322, lr = 0.0025
I0526 03:44:49.703930  5200 solver.cpp:239] Iteration 10348 (1.66262 iter/s, 15.638s/26 iters), loss = 0.00179426
I0526 03:44:49.703984  5200 solver.cpp:258]     Train net output #0: loss = 0.000332376 (* 1 = 0.000332376 loss)
I0526 03:44:49.703992  5200 sgd_solver.cpp:112] Iteration 10348, lr = 0.0025
I0526 03:45:05.370033  5200 solver.cpp:239] Iteration 10374 (1.65965 iter/s, 15.666s/26 iters), loss = 0.0144929
I0526 03:45:05.370218  5200 solver.cpp:258]     Train net output #0: loss = 0.00165143 (* 1 = 0.00165143 loss)
I0526 03:45:05.370225  5200 sgd_solver.cpp:112] Iteration 10374, lr = 0.0025
I0526 03:45:17.416687  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_10395.caffemodel
I0526 03:45:17.417363  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_10395.solverstate
I0526 03:45:17.417678  5200 solver.cpp:347] Iteration 10395, Testing net (#0)
I0526 03:45:28.472481  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9996
I0526 03:45:28.472530  5200 solver.cpp:414]     Test net output #1: loss = 0.00343967 (* 1 = 0.00343967 loss)
I0526 03:45:28.472534  5200 solver.cpp:347] Iteration 10395, Testing net (#1)
I0526 03:45:49.933431  5200 solver.cpp:414]     Test net output #0: accuracy = 0.798085
I0526 03:45:49.933604  5200 solver.cpp:414]     Test net output #1: loss = 0.607547 (* 1 = 0.607547 loss)
I0526 03:45:49.933620  5200 solver.cpp:347] Iteration 10395, Testing net (#2)
I0526 03:46:40.140622  5200 solver.cpp:414]     Test net output #0: accuracy = 0.985496
I0526 03:46:40.140771  5200 solver.cpp:414]     Test net output #1: loss = 0.0465558 (* 1 = 0.0465558 loss)
I0526 03:46:43.798207  5200 solver.cpp:239] Iteration 10400 (0.264155 iter/s, 98.427s/26 iters), loss = 0.00700856
I0526 03:46:43.798264  5200 solver.cpp:258]     Train net output #0: loss = 0.000465038 (* 1 = 0.000465038 loss)
I0526 03:46:43.798272  5200 sgd_solver.cpp:112] Iteration 10400, lr = 0.0025
I0526 03:46:59.411448  5200 solver.cpp:239] Iteration 10426 (1.66528 iter/s, 15.613s/26 iters), loss = 0.00559484
I0526 03:46:59.411504  5200 solver.cpp:258]     Train net output #0: loss = 0.00286673 (* 1 = 0.00286673 loss)
I0526 03:46:59.411510  5200 sgd_solver.cpp:112] Iteration 10426, lr = 0.0025
I0526 03:47:15.005437  5200 solver.cpp:239] Iteration 10452 (1.66741 iter/s, 15.593s/26 iters), loss = 0.00203422
I0526 03:47:15.005600  5200 solver.cpp:258]     Train net output #0: loss = 0.0041426 (* 1 = 0.0041426 loss)
I0526 03:47:15.005609  5200 sgd_solver.cpp:112] Iteration 10452, lr = 0.0025
I0526 03:47:30.598189  5200 solver.cpp:239] Iteration 10478 (1.66752 iter/s, 15.592s/26 iters), loss = 0.00562827
I0526 03:47:30.598248  5200 solver.cpp:258]     Train net output #0: loss = 0.0003289 (* 1 = 0.0003289 loss)
I0526 03:47:30.598255  5200 sgd_solver.cpp:112] Iteration 10478, lr = 0.0025
I0526 03:47:46.175596  5200 solver.cpp:239] Iteration 10504 (1.66913 iter/s, 15.577s/26 iters), loss = 0.00706781
I0526 03:47:46.175729  5200 solver.cpp:258]     Train net output #0: loss = 0.000294208 (* 1 = 0.000294208 loss)
I0526 03:47:46.175747  5200 sgd_solver.cpp:112] Iteration 10504, lr = 0.0025
I0526 03:48:01.753257  5200 solver.cpp:239] Iteration 10530 (1.66913 iter/s, 15.577s/26 iters), loss = 0.00298127
I0526 03:48:01.753315  5200 solver.cpp:258]     Train net output #0: loss = 0.000329524 (* 1 = 0.000329524 loss)
I0526 03:48:01.753324  5200 sgd_solver.cpp:112] Iteration 10530, lr = 0.0025
I0526 03:48:17.333688  5200 solver.cpp:239] Iteration 10556 (1.66881 iter/s, 15.58s/26 iters), loss = 0.00369782
I0526 03:48:17.333856  5200 solver.cpp:258]     Train net output #0: loss = 0.000348508 (* 1 = 0.000348508 loss)
I0526 03:48:17.333865  5200 sgd_solver.cpp:112] Iteration 10556, lr = 0.0025
I0526 03:48:32.913511  5200 solver.cpp:239] Iteration 10582 (1.66891 iter/s, 15.579s/26 iters), loss = 0.00209473
I0526 03:48:32.913566  5200 solver.cpp:258]     Train net output #0: loss = 0.000525235 (* 1 = 0.000525235 loss)
I0526 03:48:32.913573  5200 sgd_solver.cpp:112] Iteration 10582, lr = 0.0025
I0526 03:48:48.505089  5200 solver.cpp:239] Iteration 10608 (1.66763 iter/s, 15.591s/26 iters), loss = 0.00985995
I0526 03:48:48.505265  5200 solver.cpp:258]     Train net output #0: loss = 0.027735 (* 1 = 0.027735 loss)
I0526 03:48:48.505275  5200 sgd_solver.cpp:112] Iteration 10608, lr = 0.0025
I0526 03:49:04.093055  5200 solver.cpp:239] Iteration 10634 (1.66806 iter/s, 15.587s/26 iters), loss = 0.00789526
I0526 03:49:04.093112  5200 solver.cpp:258]     Train net output #0: loss = 8.69625e-05 (* 1 = 8.69625e-05 loss)
I0526 03:49:04.093119  5200 sgd_solver.cpp:112] Iteration 10634, lr = 0.0025
I0526 03:49:19.679664  5200 solver.cpp:239] Iteration 10660 (1.66816 iter/s, 15.586s/26 iters), loss = 0.00726014
I0526 03:49:19.679821  5200 solver.cpp:258]     Train net output #0: loss = 0.00797015 (* 1 = 0.00797015 loss)
I0526 03:49:19.679828  5200 sgd_solver.cpp:112] Iteration 10660, lr = 0.0025
I0526 03:49:35.271209  5200 solver.cpp:239] Iteration 10686 (1.66763 iter/s, 15.591s/26 iters), loss = 0.00372579
I0526 03:49:35.271262  5200 solver.cpp:258]     Train net output #0: loss = 0.0014615 (* 1 = 0.0014615 loss)
I0526 03:49:35.271270  5200 sgd_solver.cpp:112] Iteration 10686, lr = 0.0025
I0526 03:49:50.919368  5200 solver.cpp:239] Iteration 10712 (1.66155 iter/s, 15.648s/26 iters), loss = 0.007671
I0526 03:49:50.919519  5200 solver.cpp:258]     Train net output #0: loss = 0.0143001 (* 1 = 0.0143001 loss)
I0526 03:49:50.919528  5200 sgd_solver.cpp:112] Iteration 10712, lr = 0.0025
I0526 03:50:06.579385  5200 solver.cpp:239] Iteration 10738 (1.66039 iter/s, 15.659s/26 iters), loss = 0.0018881
I0526 03:50:06.579440  5200 solver.cpp:258]     Train net output #0: loss = 0.000333449 (* 1 = 0.000333449 loss)
I0526 03:50:06.579447  5200 sgd_solver.cpp:112] Iteration 10738, lr = 0.0025
I0526 03:50:22.247592  5200 solver.cpp:239] Iteration 10764 (1.65943 iter/s, 15.668s/26 iters), loss = 0.00915164
I0526 03:50:22.247792  5200 solver.cpp:258]     Train net output #0: loss = 0.00161965 (* 1 = 0.00161965 loss)
I0526 03:50:22.247802  5200 sgd_solver.cpp:112] Iteration 10764, lr = 0.0025
I0526 03:50:31.290263  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_10780.caffemodel
I0526 03:50:31.290966  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_10780.solverstate
I0526 03:50:31.291277  5200 solver.cpp:347] Iteration 10780, Testing net (#0)
I0526 03:50:42.344108  5200 solver.cpp:414]     Test net output #0: accuracy = 0.998
I0526 03:50:42.344158  5200 solver.cpp:414]     Test net output #1: loss = 0.00580485 (* 1 = 0.00580485 loss)
I0526 03:50:42.344163  5200 solver.cpp:347] Iteration 10780, Testing net (#1)
I0526 03:51:04.439795  5200 solver.cpp:414]     Test net output #0: accuracy = 0.665319
I0526 03:51:04.439929  5200 solver.cpp:414]     Test net output #1: loss = 1.33736 (* 1 = 1.33736 loss)
I0526 03:51:04.439937  5200 solver.cpp:347] Iteration 10780, Testing net (#2)
I0526 03:51:54.985539  5200 solver.cpp:414]     Test net output #0: accuracy = 0.968018
I0526 03:51:54.985671  5200 solver.cpp:414]     Test net output #1: loss = 0.102941 (* 1 = 0.102941 loss)
I0526 03:52:01.705391  5200 solver.cpp:239] Iteration 10790 (0.26142 iter/s, 99.457s/26 iters), loss = 0.0184253
I0526 03:52:01.705441  5200 solver.cpp:258]     Train net output #0: loss = 0.00160212 (* 1 = 0.00160212 loss)
I0526 03:52:01.705449  5200 sgd_solver.cpp:112] Iteration 10790, lr = 0.0025
I0526 03:52:17.545351  5200 solver.cpp:239] Iteration 10816 (1.64152 iter/s, 15.839s/26 iters), loss = 0.00974888
I0526 03:52:17.545408  5200 solver.cpp:258]     Train net output #0: loss = 0.0113446 (* 1 = 0.0113446 loss)
I0526 03:52:17.545414  5200 sgd_solver.cpp:112] Iteration 10816, lr = 0.0025
I0526 03:52:33.360878  5200 solver.cpp:239] Iteration 10842 (1.64401 iter/s, 15.815s/26 iters), loss = 0.00852871
I0526 03:52:33.361066  5200 solver.cpp:258]     Train net output #0: loss = 0.00470351 (* 1 = 0.00470351 loss)
I0526 03:52:33.361074  5200 sgd_solver.cpp:112] Iteration 10842, lr = 0.0025
I0526 03:52:49.166041  5200 solver.cpp:239] Iteration 10868 (1.64515 iter/s, 15.804s/26 iters), loss = 0.00493283
I0526 03:52:49.166092  5200 solver.cpp:258]     Train net output #0: loss = 0.00104377 (* 1 = 0.00104377 loss)
I0526 03:52:49.166100  5200 sgd_solver.cpp:112] Iteration 10868, lr = 0.0025
I0526 03:53:04.991490  5200 solver.cpp:239] Iteration 10894 (1.64297 iter/s, 15.825s/26 iters), loss = 0.00808483
I0526 03:53:04.991667  5200 solver.cpp:258]     Train net output #0: loss = 0.000318539 (* 1 = 0.000318539 loss)
I0526 03:53:04.991675  5200 sgd_solver.cpp:112] Iteration 10894, lr = 0.0025
I0526 03:53:20.802229  5200 solver.cpp:239] Iteration 10920 (1.64453 iter/s, 15.81s/26 iters), loss = 0.0120313
I0526 03:53:20.802286  5200 solver.cpp:258]     Train net output #0: loss = 0.00146443 (* 1 = 0.00146443 loss)
I0526 03:53:20.802294  5200 sgd_solver.cpp:112] Iteration 10920, lr = 0.0025
I0526 03:53:36.624632  5200 solver.cpp:239] Iteration 10946 (1.64328 iter/s, 15.822s/26 iters), loss = 0.0116197
I0526 03:53:36.624836  5200 solver.cpp:258]     Train net output #0: loss = 0.00891766 (* 1 = 0.00891766 loss)
I0526 03:53:36.624845  5200 sgd_solver.cpp:112] Iteration 10946, lr = 0.0025
I0526 03:53:52.519647  5200 solver.cpp:239] Iteration 10972 (1.63584 iter/s, 15.894s/26 iters), loss = 0.00827977
I0526 03:53:52.519690  5200 solver.cpp:258]     Train net output #0: loss = 0.00106119 (* 1 = 0.00106119 loss)
I0526 03:53:52.519698  5200 sgd_solver.cpp:112] Iteration 10972, lr = 0.0025
I0526 03:54:08.409474  5200 solver.cpp:239] Iteration 10998 (1.63635 iter/s, 15.889s/26 iters), loss = 0.00646546
I0526 03:54:08.409642  5200 solver.cpp:258]     Train net output #0: loss = 0.000845982 (* 1 = 0.000845982 loss)
I0526 03:54:08.409651  5200 sgd_solver.cpp:112] Iteration 10998, lr = 0.0025
I0526 03:54:24.251559  5200 solver.cpp:239] Iteration 11024 (1.64131 iter/s, 15.841s/26 iters), loss = 0.00289662
I0526 03:54:24.251612  5200 solver.cpp:258]     Train net output #0: loss = 0.000862835 (* 1 = 0.000862835 loss)
I0526 03:54:24.251619  5200 sgd_solver.cpp:112] Iteration 11024, lr = 0.0025
I0526 03:54:40.107408  5200 solver.cpp:239] Iteration 11050 (1.63986 iter/s, 15.855s/26 iters), loss = 0.00505782
I0526 03:54:40.107564  5200 solver.cpp:258]     Train net output #0: loss = 0.00162572 (* 1 = 0.00162572 loss)
I0526 03:54:40.107573  5200 sgd_solver.cpp:112] Iteration 11050, lr = 0.0025
I0526 03:54:55.966336  5200 solver.cpp:239] Iteration 11076 (1.63955 iter/s, 15.858s/26 iters), loss = 0.004866
I0526 03:54:55.966378  5200 solver.cpp:258]     Train net output #0: loss = 0.000612954 (* 1 = 0.000612954 loss)
I0526 03:54:55.966387  5200 sgd_solver.cpp:112] Iteration 11076, lr = 0.0025
I0526 03:55:11.772279  5200 solver.cpp:239] Iteration 11102 (1.64505 iter/s, 15.805s/26 iters), loss = 0.00521329
I0526 03:55:11.772440  5200 solver.cpp:258]     Train net output #0: loss = 0.0347355 (* 1 = 0.0347355 loss)
I0526 03:55:11.772459  5200 sgd_solver.cpp:112] Iteration 11102, lr = 0.0025
I0526 03:55:27.548244  5200 solver.cpp:239] Iteration 11128 (1.64818 iter/s, 15.775s/26 iters), loss = 0.00229373
I0526 03:55:27.548298  5200 solver.cpp:258]     Train net output #0: loss = 0.000492551 (* 1 = 0.000492551 loss)
I0526 03:55:27.548305  5200 sgd_solver.cpp:112] Iteration 11128, lr = 0.0025
I0526 03:55:43.314307  5200 solver.cpp:239] Iteration 11154 (1.64912 iter/s, 15.766s/26 iters), loss = 0.0071457
I0526 03:55:43.314456  5200 solver.cpp:258]     Train net output #0: loss = 0.00574954 (* 1 = 0.00574954 loss)
I0526 03:55:43.314481  5200 sgd_solver.cpp:112] Iteration 11154, lr = 0.0025
I0526 03:55:49.374130  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_11165.caffemodel
I0526 03:55:49.374797  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_11165.solverstate
I0526 03:55:49.375140  5200 solver.cpp:347] Iteration 11165, Testing net (#0)
I0526 03:56:00.617717  5200 solver.cpp:414]     Test net output #0: accuracy = 0.998
I0526 03:56:00.617767  5200 solver.cpp:414]     Test net output #1: loss = 0.00424265 (* 1 = 0.00424265 loss)
I0526 03:56:00.617772  5200 solver.cpp:347] Iteration 11165, Testing net (#1)
I0526 03:56:22.870736  5200 solver.cpp:414]     Test net output #0: accuracy = 0.819149
I0526 03:56:22.870916  5200 solver.cpp:414]     Test net output #1: loss = 0.578482 (* 1 = 0.578482 loss)
I0526 03:56:22.870924  5200 solver.cpp:347] Iteration 11165, Testing net (#2)
I0526 03:57:13.452389  5200 solver.cpp:414]     Test net output #0: accuracy = 0.982793
I0526 03:57:13.452531  5200 solver.cpp:414]     Test net output #1: loss = 0.0527415 (* 1 = 0.0527415 loss)
I0526 03:57:23.177878  5200 solver.cpp:239] Iteration 11180 (0.260357 iter/s, 99.863s/26 iters), loss = 0.0110508
I0526 03:57:23.177934  5200 solver.cpp:258]     Train net output #0: loss = 0.00104684 (* 1 = 0.00104684 loss)
I0526 03:57:23.177943  5200 sgd_solver.cpp:112] Iteration 11180, lr = 0.0025
I0526 03:57:38.973434  5200 solver.cpp:239] Iteration 11206 (1.64609 iter/s, 15.795s/26 iters), loss = 0.00602755
I0526 03:57:38.973490  5200 solver.cpp:258]     Train net output #0: loss = 0.000284399 (* 1 = 0.000284399 loss)
I0526 03:57:38.973498  5200 sgd_solver.cpp:112] Iteration 11206, lr = 0.0025
I0526 03:57:54.754523  5200 solver.cpp:239] Iteration 11232 (1.64755 iter/s, 15.781s/26 iters), loss = 0.00944642
I0526 03:57:54.754647  5200 solver.cpp:258]     Train net output #0: loss = 0.000941523 (* 1 = 0.000941523 loss)
I0526 03:57:54.754668  5200 sgd_solver.cpp:112] Iteration 11232, lr = 0.0025
I0526 03:58:10.592592  5200 solver.cpp:239] Iteration 11258 (1.64173 iter/s, 15.837s/26 iters), loss = 0.00395009
I0526 03:58:10.592644  5200 solver.cpp:258]     Train net output #0: loss = 0.00132926 (* 1 = 0.00132926 loss)
I0526 03:58:10.592651  5200 sgd_solver.cpp:112] Iteration 11258, lr = 0.0025
I0526 03:58:26.418756  5200 solver.cpp:239] Iteration 11284 (1.64287 iter/s, 15.826s/26 iters), loss = 0.00484509
I0526 03:58:26.418910  5200 solver.cpp:258]     Train net output #0: loss = 0.00309485 (* 1 = 0.00309485 loss)
I0526 03:58:26.418928  5200 sgd_solver.cpp:112] Iteration 11284, lr = 0.0025
I0526 03:58:42.201642  5200 solver.cpp:239] Iteration 11310 (1.64745 iter/s, 15.782s/26 iters), loss = 0.00858111
I0526 03:58:42.201697  5200 solver.cpp:258]     Train net output #0: loss = 0.0839733 (* 1 = 0.0839733 loss)
I0526 03:58:42.201704  5200 sgd_solver.cpp:112] Iteration 11310, lr = 0.0025
I0526 03:58:57.999315  5200 solver.cpp:239] Iteration 11336 (1.64588 iter/s, 15.797s/26 iters), loss = 0.0077467
I0526 03:58:57.999502  5200 solver.cpp:258]     Train net output #0: loss = 0.000525698 (* 1 = 0.000525698 loss)
I0526 03:58:57.999511  5200 sgd_solver.cpp:112] Iteration 11336, lr = 0.0025
I0526 03:59:13.830435  5200 solver.cpp:239] Iteration 11362 (1.64245 iter/s, 15.83s/26 iters), loss = 0.00515489
I0526 03:59:13.830493  5200 solver.cpp:258]     Train net output #0: loss = 9.112e-05 (* 1 = 9.112e-05 loss)
I0526 03:59:13.830502  5200 sgd_solver.cpp:112] Iteration 11362, lr = 0.0025
I0526 03:59:29.654347  5200 solver.cpp:239] Iteration 11388 (1.64318 iter/s, 15.823s/26 iters), loss = 0.0033187
I0526 03:59:29.654568  5200 solver.cpp:258]     Train net output #0: loss = 0.00155354 (* 1 = 0.00155354 loss)
I0526 03:59:29.654577  5200 sgd_solver.cpp:112] Iteration 11388, lr = 0.0025
I0526 03:59:45.504298  5200 solver.cpp:239] Iteration 11414 (1.64048 iter/s, 15.849s/26 iters), loss = 0.00444258
I0526 03:59:45.504354  5200 solver.cpp:258]     Train net output #0: loss = 0.00729858 (* 1 = 0.00729858 loss)
I0526 03:59:45.504362  5200 sgd_solver.cpp:112] Iteration 11414, lr = 0.0025
I0526 04:00:01.324440  5200 solver.cpp:239] Iteration 11440 (1.64349 iter/s, 15.82s/26 iters), loss = 0.00893884
I0526 04:00:01.324685  5200 solver.cpp:258]     Train net output #0: loss = 0.00051711 (* 1 = 0.00051711 loss)
I0526 04:00:01.324694  5200 sgd_solver.cpp:112] Iteration 11440, lr = 0.0025
I0526 04:00:17.151312  5200 solver.cpp:239] Iteration 11466 (1.64287 iter/s, 15.826s/26 iters), loss = 0.0115507
I0526 04:00:17.151367  5200 solver.cpp:258]     Train net output #0: loss = 0.00162668 (* 1 = 0.00162668 loss)
I0526 04:00:17.151376  5200 sgd_solver.cpp:112] Iteration 11466, lr = 0.0025
I0526 04:00:32.966583  5200 solver.cpp:239] Iteration 11492 (1.64401 iter/s, 15.815s/26 iters), loss = 0.00404746
I0526 04:00:32.966765  5200 solver.cpp:258]     Train net output #0: loss = 0.00101105 (* 1 = 0.00101105 loss)
I0526 04:00:32.966774  5200 sgd_solver.cpp:112] Iteration 11492, lr = 0.0025
I0526 04:00:48.840343  5200 solver.cpp:239] Iteration 11518 (1.638 iter/s, 15.873s/26 iters), loss = 0.00445719
I0526 04:00:48.840399  5200 solver.cpp:258]     Train net output #0: loss = 0.000150159 (* 1 = 0.000150159 loss)
I0526 04:00:48.840406  5200 sgd_solver.cpp:112] Iteration 11518, lr = 0.0025
I0526 04:01:04.710364  5200 solver.cpp:239] Iteration 11544 (1.63841 iter/s, 15.869s/26 iters), loss = 0.00417296
I0526 04:01:04.710587  5200 solver.cpp:258]     Train net output #0: loss = 0.000194822 (* 1 = 0.000194822 loss)
I0526 04:01:04.710595  5200 sgd_solver.cpp:112] Iteration 11544, lr = 0.0025
I0526 04:01:07.766697  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_11550.caffemodel
I0526 04:01:07.767377  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_11550.solverstate
I0526 04:01:07.767705  5200 solver.cpp:347] Iteration 11550, Testing net (#0)
I0526 04:01:19.045287  5200 solver.cpp:414]     Test net output #0: accuracy = 0.998
I0526 04:01:19.045336  5200 solver.cpp:414]     Test net output #1: loss = 0.00454429 (* 1 = 0.00454429 loss)
I0526 04:01:19.045341  5200 solver.cpp:347] Iteration 11550, Testing net (#1)
I0526 04:01:40.920724  5200 solver.cpp:414]     Test net output #0: accuracy = 0.79766
I0526 04:01:40.920964  5200 solver.cpp:414]     Test net output #1: loss = 0.695971 (* 1 = 0.695971 loss)
I0526 04:01:40.920972  5200 solver.cpp:347] Iteration 11550, Testing net (#2)
I0526 04:02:31.734472  5200 solver.cpp:414]     Test net output #0: accuracy = 0.984955
I0526 04:02:31.734647  5200 solver.cpp:414]     Test net output #1: loss = 0.0475673 (* 1 = 0.0475673 loss)
I0526 04:02:44.574488  5200 solver.cpp:239] Iteration 11570 (0.260357 iter/s, 99.863s/26 iters), loss = 0.00672987
I0526 04:02:44.574546  5200 solver.cpp:258]     Train net output #0: loss = 0.000579328 (* 1 = 0.000579328 loss)
I0526 04:02:44.574555  5200 sgd_solver.cpp:112] Iteration 11570, lr = 0.0025
I0526 04:03:00.491220  5200 solver.cpp:239] Iteration 11596 (1.63358 iter/s, 15.916s/26 iters), loss = 0.0057127
I0526 04:03:00.491266  5200 solver.cpp:258]     Train net output #0: loss = 0.00310654 (* 1 = 0.00310654 loss)
I0526 04:03:00.491273  5200 sgd_solver.cpp:112] Iteration 11596, lr = 0.0025
I0526 04:03:16.397615  5200 solver.cpp:239] Iteration 11622 (1.6346 iter/s, 15.906s/26 iters), loss = 0.00802474
I0526 04:03:16.397785  5200 solver.cpp:258]     Train net output #0: loss = 0.000701255 (* 1 = 0.000701255 loss)
I0526 04:03:16.397794  5200 sgd_solver.cpp:112] Iteration 11622, lr = 0.0025
I0526 04:03:32.308776  5200 solver.cpp:239] Iteration 11648 (1.63409 iter/s, 15.911s/26 iters), loss = 0.00780904
I0526 04:03:32.308832  5200 solver.cpp:258]     Train net output #0: loss = 0.0246963 (* 1 = 0.0246963 loss)
I0526 04:03:32.308840  5200 sgd_solver.cpp:112] Iteration 11648, lr = 0.0025
I0526 04:03:48.207396  5200 solver.cpp:239] Iteration 11674 (1.63543 iter/s, 15.898s/26 iters), loss = 0.00283498
I0526 04:03:48.207576  5200 solver.cpp:258]     Train net output #0: loss = 0.00025984 (* 1 = 0.00025984 loss)
I0526 04:03:48.207583  5200 sgd_solver.cpp:112] Iteration 11674, lr = 0.0025
I0526 04:04:04.105532  5200 solver.cpp:239] Iteration 11700 (1.63553 iter/s, 15.897s/26 iters), loss = 0.00568892
I0526 04:04:04.105589  5200 solver.cpp:258]     Train net output #0: loss = 0.000758699 (* 1 = 0.000758699 loss)
I0526 04:04:04.105597  5200 sgd_solver.cpp:112] Iteration 11700, lr = 0.0025
I0526 04:04:19.997846  5200 solver.cpp:239] Iteration 11726 (1.63604 iter/s, 15.892s/26 iters), loss = 0.00666501
I0526 04:04:19.998005  5200 solver.cpp:258]     Train net output #0: loss = 0.000939335 (* 1 = 0.000939335 loss)
I0526 04:04:19.998014  5200 sgd_solver.cpp:112] Iteration 11726, lr = 0.0025
I0526 04:04:35.885655  5200 solver.cpp:239] Iteration 11752 (1.63656 iter/s, 15.887s/26 iters), loss = 0.00715886
I0526 04:04:35.885711  5200 solver.cpp:258]     Train net output #0: loss = 0.00803544 (* 1 = 0.00803544 loss)
I0526 04:04:35.885720  5200 sgd_solver.cpp:112] Iteration 11752, lr = 0.0025
I0526 04:04:51.776937  5200 solver.cpp:239] Iteration 11778 (1.63615 iter/s, 15.891s/26 iters), loss = 0.00591122
I0526 04:04:51.777101  5200 solver.cpp:258]     Train net output #0: loss = 0.00266701 (* 1 = 0.00266701 loss)
I0526 04:04:51.777108  5200 sgd_solver.cpp:112] Iteration 11778, lr = 0.0025
I0526 04:05:07.666837  5200 solver.cpp:239] Iteration 11804 (1.63635 iter/s, 15.889s/26 iters), loss = 0.00947496
I0526 04:05:07.666900  5200 solver.cpp:258]     Train net output #0: loss = 0.0051493 (* 1 = 0.0051493 loss)
I0526 04:05:07.666908  5200 sgd_solver.cpp:112] Iteration 11804, lr = 0.0025
I0526 04:05:23.538584  5200 solver.cpp:239] Iteration 11830 (1.63821 iter/s, 15.871s/26 iters), loss = 0.00623058
I0526 04:05:23.538727  5200 solver.cpp:258]     Train net output #0: loss = 0.000560633 (* 1 = 0.000560633 loss)
I0526 04:05:23.538734  5200 sgd_solver.cpp:112] Iteration 11830, lr = 0.0025
I0526 04:05:39.412467  5200 solver.cpp:239] Iteration 11856 (1.638 iter/s, 15.873s/26 iters), loss = 0.00337373
I0526 04:05:39.412520  5200 solver.cpp:258]     Train net output #0: loss = 0.000643425 (* 1 = 0.000643425 loss)
I0526 04:05:39.412528  5200 sgd_solver.cpp:112] Iteration 11856, lr = 0.0025
I0526 04:05:55.276854  5200 solver.cpp:239] Iteration 11882 (1.63893 iter/s, 15.864s/26 iters), loss = 0.00555838
I0526 04:05:55.276962  5200 solver.cpp:258]     Train net output #0: loss = 0.000161778 (* 1 = 0.000161778 loss)
I0526 04:05:55.276970  5200 sgd_solver.cpp:112] Iteration 11882, lr = 0.0025
I0526 04:06:11.165238  5200 solver.cpp:239] Iteration 11908 (1.63646 iter/s, 15.888s/26 iters), loss = 0.0102821
I0526 04:06:11.165294  5200 solver.cpp:258]     Train net output #0: loss = 0.0298302 (* 1 = 0.0298302 loss)
I0526 04:06:11.165303  5200 sgd_solver.cpp:112] Iteration 11908, lr = 0.0025
I0526 04:06:27.064265  5200 solver.cpp:239] Iteration 11934 (1.63543 iter/s, 15.898s/26 iters), loss = 0.00901821
I0526 04:06:27.064404  5200 solver.cpp:258]     Train net output #0: loss = 0.00336993 (* 1 = 0.00336993 loss)
I0526 04:06:27.064427  5200 sgd_solver.cpp:112] Iteration 11934, lr = 0.0025
I0526 04:06:27.064555  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_11935.caffemodel
I0526 04:06:27.065198  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_11935.solverstate
I0526 04:06:27.065510  5200 solver.cpp:347] Iteration 11935, Testing net (#0)
I0526 04:06:38.292490  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9988
I0526 04:06:38.292539  5200 solver.cpp:414]     Test net output #1: loss = 0.00893814 (* 1 = 0.00893814 loss)
I0526 04:06:38.292544  5200 solver.cpp:347] Iteration 11935, Testing net (#1)
I0526 04:07:00.210273  5200 solver.cpp:414]     Test net output #0: accuracy = 0.780638
I0526 04:07:00.210402  5200 solver.cpp:414]     Test net output #1: loss = 0.757547 (* 1 = 0.757547 loss)
I0526 04:07:00.210407  5200 solver.cpp:347] Iteration 11935, Testing net (#2)
I0526 04:07:51.332201  5200 solver.cpp:414]     Test net output #0: accuracy = 0.981892
I0526 04:07:51.332376  5200 solver.cpp:414]     Test net output #1: loss = 0.0487197 (* 1 = 0.0487197 loss)
I0526 04:08:07.231031  5200 solver.cpp:239] Iteration 11960 (0.259569 iter/s, 100.166s/26 iters), loss = 0.00811553
I0526 04:08:07.231086  5200 solver.cpp:258]     Train net output #0: loss = 0.00381437 (* 1 = 0.00381437 loss)
I0526 04:08:07.231094  5200 sgd_solver.cpp:112] Iteration 11960, lr = 0.0025
I0526 04:08:23.126667  5200 solver.cpp:239] Iteration 11986 (1.63573 iter/s, 15.895s/26 iters), loss = 0.00995104
I0526 04:08:23.126802  5200 solver.cpp:258]     Train net output #0: loss = 0.000942985 (* 1 = 0.000942985 loss)
I0526 04:08:23.126819  5200 sgd_solver.cpp:112] Iteration 11986, lr = 0.0025
I0526 04:08:38.977789  5200 solver.cpp:239] Iteration 12012 (1.64038 iter/s, 15.85s/26 iters), loss = 0.0103698
I0526 04:08:38.977845  5200 solver.cpp:258]     Train net output #0: loss = 0.0187397 (* 1 = 0.0187397 loss)
I0526 04:08:38.977852  5200 sgd_solver.cpp:112] Iteration 12012, lr = 0.0025
I0526 04:08:54.814421  5200 solver.cpp:239] Iteration 12038 (1.64183 iter/s, 15.836s/26 iters), loss = 0.00673692
I0526 04:08:54.814591  5200 solver.cpp:258]     Train net output #0: loss = 0.0213459 (* 1 = 0.0213459 loss)
I0526 04:08:54.814599  5200 sgd_solver.cpp:112] Iteration 12038, lr = 0.0025
I0526 04:09:10.645825  5200 solver.cpp:239] Iteration 12064 (1.64235 iter/s, 15.831s/26 iters), loss = 0.00800061
I0526 04:09:10.645879  5200 solver.cpp:258]     Train net output #0: loss = 0.00175622 (* 1 = 0.00175622 loss)
I0526 04:09:10.645887  5200 sgd_solver.cpp:112] Iteration 12064, lr = 0.0025
I0526 04:09:26.514827  5200 solver.cpp:239] Iteration 12090 (1.63852 iter/s, 15.868s/26 iters), loss = 0.00587418
I0526 04:09:26.514979  5200 solver.cpp:258]     Train net output #0: loss = 0.000516836 (* 1 = 0.000516836 loss)
I0526 04:09:26.514987  5200 sgd_solver.cpp:112] Iteration 12090, lr = 0.0025
I0526 04:09:42.384848  5200 solver.cpp:239] Iteration 12116 (1.63841 iter/s, 15.869s/26 iters), loss = 0.00538751
I0526 04:09:42.384905  5200 solver.cpp:258]     Train net output #0: loss = 0.000356997 (* 1 = 0.000356997 loss)
I0526 04:09:42.384913  5200 sgd_solver.cpp:112] Iteration 12116, lr = 0.0025
I0526 04:09:58.270846  5200 solver.cpp:239] Iteration 12142 (1.63676 iter/s, 15.885s/26 iters), loss = 0.00552976
I0526 04:09:58.271044  5200 solver.cpp:258]     Train net output #0: loss = 0.00285774 (* 1 = 0.00285774 loss)
I0526 04:09:58.271054  5200 sgd_solver.cpp:112] Iteration 12142, lr = 0.0025
I0526 04:10:14.164408  5200 solver.cpp:239] Iteration 12168 (1.63594 iter/s, 15.893s/26 iters), loss = 0.00146715
I0526 04:10:14.164458  5200 solver.cpp:258]     Train net output #0: loss = 0.00221214 (* 1 = 0.00221214 loss)
I0526 04:10:14.164464  5200 sgd_solver.cpp:112] Iteration 12168, lr = 0.0025
I0526 04:10:30.036334  5200 solver.cpp:239] Iteration 12194 (1.63821 iter/s, 15.871s/26 iters), loss = 0.0015806
I0526 04:10:30.036506  5200 solver.cpp:258]     Train net output #0: loss = 0.000304228 (* 1 = 0.000304228 loss)
I0526 04:10:30.036525  5200 sgd_solver.cpp:112] Iteration 12194, lr = 0.0025
I0526 04:10:45.927399  5200 solver.cpp:239] Iteration 12220 (1.63625 iter/s, 15.89s/26 iters), loss = 0.0116266
I0526 04:10:45.927453  5200 solver.cpp:258]     Train net output #0: loss = 0.000122759 (* 1 = 0.000122759 loss)
I0526 04:10:45.927462  5200 sgd_solver.cpp:112] Iteration 12220, lr = 0.0025
I0526 04:11:01.825500  5200 solver.cpp:239] Iteration 12246 (1.63543 iter/s, 15.898s/26 iters), loss = 0.0128893
I0526 04:11:01.825629  5200 solver.cpp:258]     Train net output #0: loss = 0.000660615 (* 1 = 0.000660615 loss)
I0526 04:11:01.825639  5200 sgd_solver.cpp:112] Iteration 12246, lr = 0.0025
I0526 04:11:17.695580  5200 solver.cpp:239] Iteration 12272 (1.63841 iter/s, 15.869s/26 iters), loss = 0.0056381
I0526 04:11:17.695637  5200 solver.cpp:258]     Train net output #0: loss = 0.000364607 (* 1 = 0.000364607 loss)
I0526 04:11:17.695644  5200 sgd_solver.cpp:112] Iteration 12272, lr = 0.0025
I0526 04:11:33.573428  5200 solver.cpp:239] Iteration 12298 (1.63759 iter/s, 15.877s/26 iters), loss = 0.00506408
I0526 04:11:33.573653  5200 solver.cpp:258]     Train net output #0: loss = 0.000925629 (* 1 = 0.000925629 loss)
I0526 04:11:33.573662  5200 sgd_solver.cpp:112] Iteration 12298, lr = 0.0025
I0526 04:11:46.460260  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_12320.caffemodel
I0526 04:11:46.460932  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_12320.solverstate
I0526 04:11:46.461248  5200 solver.cpp:347] Iteration 12320, Testing net (#0)
I0526 04:11:57.715756  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9988
I0526 04:11:57.715797  5200 solver.cpp:414]     Test net output #1: loss = 0.00308142 (* 1 = 0.00308142 loss)
I0526 04:11:57.715802  5200 solver.cpp:347] Iteration 12320, Testing net (#1)
I0526 04:12:19.537940  5200 solver.cpp:414]     Test net output #0: accuracy = 0.745106
I0526 04:12:19.538103  5200 solver.cpp:414]     Test net output #1: loss = 0.882021 (* 1 = 0.882021 loss)
I0526 04:12:19.538120  5200 solver.cpp:347] Iteration 12320, Testing net (#2)
I0526 04:13:10.353471  5200 solver.cpp:414]     Test net output #0: accuracy = 0.977478
I0526 04:13:10.353683  5200 solver.cpp:414]     Test net output #1: loss = 0.0627059 (* 1 = 0.0627059 loss)
I0526 04:13:13.397951  5200 solver.cpp:239] Iteration 12324 (0.260458 iter/s, 99.824s/26 iters), loss = 0.00677967
I0526 04:13:13.398008  5200 solver.cpp:258]     Train net output #0: loss = 0.00211806 (* 1 = 0.00211806 loss)
I0526 04:13:13.398017  5200 sgd_solver.cpp:112] Iteration 12324, lr = 0.0025
I0526 04:13:29.271219  5200 solver.cpp:239] Iteration 12350 (1.638 iter/s, 15.873s/26 iters), loss = 0.00290435
I0526 04:13:29.271271  5200 solver.cpp:258]     Train net output #0: loss = 0.00150763 (* 1 = 0.00150763 loss)
I0526 04:13:29.271278  5200 sgd_solver.cpp:112] Iteration 12350, lr = 0.0025
I0526 04:13:45.084853  5200 solver.cpp:239] Iteration 12376 (1.64422 iter/s, 15.813s/26 iters), loss = 0.0117287
I0526 04:13:45.084982  5200 solver.cpp:258]     Train net output #0: loss = 0.00267735 (* 1 = 0.00267735 loss)
I0526 04:13:45.084991  5200 sgd_solver.cpp:112] Iteration 12376, lr = 0.0025
I0526 04:14:00.890861  5200 solver.cpp:239] Iteration 12402 (1.64505 iter/s, 15.805s/26 iters), loss = 0.00596689
I0526 04:14:00.890923  5200 solver.cpp:258]     Train net output #0: loss = 0.0281031 (* 1 = 0.0281031 loss)
I0526 04:14:00.890930  5200 sgd_solver.cpp:112] Iteration 12402, lr = 0.0025
I0526 04:14:16.698630  5200 solver.cpp:239] Iteration 12428 (1.64484 iter/s, 15.807s/26 iters), loss = 0.0117796
I0526 04:14:16.698789  5200 solver.cpp:258]     Train net output #0: loss = 0.000685096 (* 1 = 0.000685096 loss)
I0526 04:14:16.698797  5200 sgd_solver.cpp:112] Iteration 12428, lr = 0.0025
I0526 04:14:32.505878  5200 solver.cpp:239] Iteration 12454 (1.64484 iter/s, 15.807s/26 iters), loss = 0.0110205
I0526 04:14:32.505939  5200 solver.cpp:258]     Train net output #0: loss = 0.000932091 (* 1 = 0.000932091 loss)
I0526 04:14:32.505946  5200 sgd_solver.cpp:112] Iteration 12454, lr = 0.0025
I0526 04:14:48.330134  5200 solver.cpp:239] Iteration 12480 (1.64307 iter/s, 15.824s/26 iters), loss = 0.00391122
I0526 04:14:48.330369  5200 solver.cpp:258]     Train net output #0: loss = 0.00126158 (* 1 = 0.00126158 loss)
I0526 04:14:48.330379  5200 sgd_solver.cpp:112] Iteration 12480, lr = 0.0025
I0526 04:15:04.186290  5200 solver.cpp:239] Iteration 12506 (1.63986 iter/s, 15.855s/26 iters), loss = 0.00332856
I0526 04:15:04.186347  5200 solver.cpp:258]     Train net output #0: loss = 0.000451841 (* 1 = 0.000451841 loss)
I0526 04:15:04.186355  5200 sgd_solver.cpp:112] Iteration 12506, lr = 0.0025
I0526 04:15:20.010293  5200 solver.cpp:239] Iteration 12532 (1.64318 iter/s, 15.823s/26 iters), loss = 0.00480344
I0526 04:15:20.010454  5200 solver.cpp:258]     Train net output #0: loss = 0.00133509 (* 1 = 0.00133509 loss)
I0526 04:15:20.010462  5200 sgd_solver.cpp:112] Iteration 12532, lr = 0.0025
I0526 04:15:35.830143  5200 solver.cpp:239] Iteration 12558 (1.64359 iter/s, 15.819s/26 iters), loss = 0.00659592
I0526 04:15:35.830200  5200 solver.cpp:258]     Train net output #0: loss = 0.0411002 (* 1 = 0.0411002 loss)
I0526 04:15:35.830207  5200 sgd_solver.cpp:112] Iteration 12558, lr = 0.0025
I0526 04:15:51.652737  5200 solver.cpp:239] Iteration 12584 (1.64328 iter/s, 15.822s/26 iters), loss = 0.00615396
I0526 04:15:51.652848  5200 solver.cpp:258]     Train net output #0: loss = 0.000211632 (* 1 = 0.000211632 loss)
I0526 04:15:51.652855  5200 sgd_solver.cpp:112] Iteration 12584, lr = 0.0025
I0526 04:16:07.509505  5200 solver.cpp:239] Iteration 12610 (1.63976 iter/s, 15.856s/26 iters), loss = 0.00468652
I0526 04:16:07.509562  5200 solver.cpp:258]     Train net output #0: loss = 0.000134107 (* 1 = 0.000134107 loss)
I0526 04:16:07.509569  5200 sgd_solver.cpp:112] Iteration 12610, lr = 0.0025
I0526 04:16:23.397740  5200 solver.cpp:239] Iteration 12636 (1.63646 iter/s, 15.888s/26 iters), loss = 0.011006
I0526 04:16:23.397928  5200 solver.cpp:258]     Train net output #0: loss = 0.000284667 (* 1 = 0.000284667 loss)
I0526 04:16:23.397936  5200 sgd_solver.cpp:112] Iteration 12636, lr = 0.0025
I0526 04:16:39.276624  5200 solver.cpp:239] Iteration 12662 (1.63749 iter/s, 15.878s/26 iters), loss = 0.0122612
I0526 04:16:39.276674  5200 solver.cpp:258]     Train net output #0: loss = 0.00080241 (* 1 = 0.00080241 loss)
I0526 04:16:39.276681  5200 sgd_solver.cpp:112] Iteration 12662, lr = 0.0025
I0526 04:16:55.286594  5200 solver.cpp:239] Iteration 12688 (1.62409 iter/s, 16.009s/26 iters), loss = 0.00385138
I0526 04:16:55.286725  5200 solver.cpp:258]     Train net output #0: loss = 0.000689215 (* 1 = 0.000689215 loss)
I0526 04:16:55.286742  5200 sgd_solver.cpp:112] Iteration 12688, lr = 0.0025
I0526 04:17:05.071236  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_12705.caffemodel
I0526 04:17:05.071911  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_12705.solverstate
I0526 04:17:05.072247  5200 solver.cpp:347] Iteration 12705, Testing net (#0)
I0526 04:17:16.356730  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9996
I0526 04:17:16.356770  5200 solver.cpp:414]     Test net output #1: loss = 0.00308412 (* 1 = 0.00308412 loss)
I0526 04:17:16.356776  5200 solver.cpp:347] Iteration 12705, Testing net (#1)
I0526 04:17:38.581496  5200 solver.cpp:414]     Test net output #0: accuracy = 0.808085
I0526 04:17:38.581665  5200 solver.cpp:414]     Test net output #1: loss = 0.654432 (* 1 = 0.654432 loss)
I0526 04:17:38.581683  5200 solver.cpp:347] Iteration 12705, Testing net (#2)
I0526 04:18:29.266005  5200 solver.cpp:414]     Test net output #0: accuracy = 0.984145
I0526 04:18:29.266165  5200 solver.cpp:414]     Test net output #1: loss = 0.046875 (* 1 = 0.046875 loss)
I0526 04:18:35.378862  5200 solver.cpp:239] Iteration 12714 (0.259761 iter/s, 100.092s/26 iters), loss = 0.00814134
I0526 04:18:35.378927  5200 solver.cpp:258]     Train net output #0: loss = 0.000272478 (* 1 = 0.000272478 loss)
I0526 04:18:35.378935  5200 sgd_solver.cpp:112] Iteration 12714, lr = 0.0025
I0526 04:18:51.243535  5200 solver.cpp:239] Iteration 12740 (1.63893 iter/s, 15.864s/26 iters), loss = 0.00947815
I0526 04:18:51.243582  5200 solver.cpp:258]     Train net output #0: loss = 0.000449211 (* 1 = 0.000449211 loss)
I0526 04:18:51.243589  5200 sgd_solver.cpp:112] Iteration 12740, lr = 0.0025
I0526 04:19:07.093299  5200 solver.cpp:239] Iteration 12766 (1.64048 iter/s, 15.849s/26 iters), loss = 0.0148506
I0526 04:19:07.093431  5200 solver.cpp:258]     Train net output #0: loss = 0.00306355 (* 1 = 0.00306355 loss)
I0526 04:19:07.093441  5200 sgd_solver.cpp:112] Iteration 12766, lr = 0.0025
I0526 04:19:22.939533  5200 solver.cpp:239] Iteration 12792 (1.64079 iter/s, 15.846s/26 iters), loss = 0.00639335
I0526 04:19:22.939589  5200 solver.cpp:258]     Train net output #0: loss = 0.052339 (* 1 = 0.052339 loss)
I0526 04:19:22.939595  5200 sgd_solver.cpp:112] Iteration 12792, lr = 0.0025
I0526 04:19:38.783149  5200 solver.cpp:239] Iteration 12818 (1.6411 iter/s, 15.843s/26 iters), loss = 0.00663136
I0526 04:19:38.783311  5200 solver.cpp:258]     Train net output #0: loss = 0.00151542 (* 1 = 0.00151542 loss)
I0526 04:19:38.783329  5200 sgd_solver.cpp:112] Iteration 12818, lr = 0.0025
I0526 04:19:54.634922  5200 solver.cpp:239] Iteration 12844 (1.64028 iter/s, 15.851s/26 iters), loss = 0.00309799
I0526 04:19:54.634979  5200 solver.cpp:258]     Train net output #0: loss = 0.00172236 (* 1 = 0.00172236 loss)
I0526 04:19:54.634987  5200 sgd_solver.cpp:112] Iteration 12844, lr = 0.0025
I0526 04:20:10.519455  5200 solver.cpp:239] Iteration 12870 (1.63687 iter/s, 15.884s/26 iters), loss = 0.00507011
I0526 04:20:10.519670  5200 solver.cpp:258]     Train net output #0: loss = 0.0101503 (* 1 = 0.0101503 loss)
I0526 04:20:10.519680  5200 sgd_solver.cpp:112] Iteration 12870, lr = 0.0025
I0526 04:20:26.417649  5200 solver.cpp:239] Iteration 12896 (1.63553 iter/s, 15.897s/26 iters), loss = 0.00185926
I0526 04:20:26.417695  5200 solver.cpp:258]     Train net output #0: loss = 0.000267003 (* 1 = 0.000267003 loss)
I0526 04:20:26.417702  5200 sgd_solver.cpp:112] Iteration 12896, lr = 0.0025
I0526 04:20:42.287480  5200 solver.cpp:239] Iteration 12922 (1.63841 iter/s, 15.869s/26 iters), loss = 0.00278999
I0526 04:20:42.287667  5200 solver.cpp:258]     Train net output #0: loss = 0.00026744 (* 1 = 0.00026744 loss)
I0526 04:20:42.287676  5200 sgd_solver.cpp:112] Iteration 12922, lr = 0.0025
I0526 04:20:58.143801  5200 solver.cpp:239] Iteration 12948 (1.63976 iter/s, 15.856s/26 iters), loss = 0.00666067
I0526 04:20:58.143854  5200 solver.cpp:258]     Train net output #0: loss = 0.035617 (* 1 = 0.035617 loss)
I0526 04:20:58.143862  5200 sgd_solver.cpp:112] Iteration 12948, lr = 0.0025
I0526 04:21:14.002279  5200 solver.cpp:239] Iteration 12974 (1.63955 iter/s, 15.858s/26 iters), loss = 0.00259263
I0526 04:21:14.002467  5200 solver.cpp:258]     Train net output #0: loss = 0.000254961 (* 1 = 0.000254961 loss)
I0526 04:21:14.002475  5200 sgd_solver.cpp:112] Iteration 12974, lr = 0.0025
I0526 04:21:29.868461  5200 solver.cpp:239] Iteration 13000 (1.63883 iter/s, 15.865s/26 iters), loss = 0.00436053
I0526 04:21:29.868515  5200 solver.cpp:258]     Train net output #0: loss = 0.00451587 (* 1 = 0.00451587 loss)
I0526 04:21:29.868521  5200 sgd_solver.cpp:112] Iteration 13000, lr = 0.0025
I0526 04:21:46.068845  5200 solver.cpp:239] Iteration 13026 (1.60494 iter/s, 16.2s/26 iters), loss = 0.00701742
I0526 04:21:46.068985  5200 solver.cpp:258]     Train net output #0: loss = 0.00230706 (* 1 = 0.00230706 loss)
I0526 04:21:46.069003  5200 sgd_solver.cpp:112] Iteration 13026, lr = 0.0025
I0526 04:22:01.791684  5200 solver.cpp:239] Iteration 13052 (1.65373 iter/s, 15.722s/26 iters), loss = 0.00906996
I0526 04:22:01.791735  5200 solver.cpp:258]     Train net output #0: loss = 0.0108902 (* 1 = 0.0108902 loss)
I0526 04:22:01.791743  5200 sgd_solver.cpp:112] Iteration 13052, lr = 0.0025
I0526 04:22:17.463232  5200 solver.cpp:239] Iteration 13078 (1.65912 iter/s, 15.671s/26 iters), loss = 0.00763027
I0526 04:22:17.463382  5200 solver.cpp:258]     Train net output #0: loss = 0.000738677 (* 1 = 0.000738677 loss)
I0526 04:22:17.463390  5200 sgd_solver.cpp:112] Iteration 13078, lr = 0.0025
I0526 04:22:24.085374  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_13090.caffemodel
I0526 04:22:24.086042  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_13090.solverstate
I0526 04:22:24.086360  5200 solver.cpp:347] Iteration 13090, Testing net (#0)
I0526 04:22:35.199808  5200 solver.cpp:414]     Test net output #0: accuracy = 0.9992
I0526 04:22:35.199854  5200 solver.cpp:414]     Test net output #1: loss = 0.00440611 (* 1 = 0.00440611 loss)
I0526 04:22:35.199859  5200 solver.cpp:347] Iteration 13090, Testing net (#1)
I0526 04:22:56.916339  5200 solver.cpp:414]     Test net output #0: accuracy = 0.797021
I0526 04:22:56.916564  5200 solver.cpp:414]     Test net output #1: loss = 0.6923 (* 1 = 0.6923 loss)
I0526 04:22:56.916571  5200 solver.cpp:347] Iteration 13090, Testing net (#2)
I0526 04:23:47.714238  5200 solver.cpp:414]     Test net output #0: accuracy = 0.986036
I0526 04:23:47.714423  5200 solver.cpp:414]     Test net output #1: loss = 0.0423548 (* 1 = 0.0423548 loss)
I0526 04:23:56.858433  5200 solver.cpp:239] Iteration 13104 (0.261583 iter/s, 99.395s/26 iters), loss = 0.00580552
I0526 04:23:56.858490  5200 solver.cpp:258]     Train net output #0: loss = 0.000725661 (* 1 = 0.000725661 loss)
I0526 04:23:56.858497  5200 sgd_solver.cpp:112] Iteration 13104, lr = 0.0025
I0526 04:24:12.704700  5200 solver.cpp:239] Iteration 13130 (1.64079 iter/s, 15.846s/26 iters), loss = 0.00484688
I0526 04:24:12.704756  5200 solver.cpp:258]     Train net output #0: loss = 0.000994617 (* 1 = 0.000994617 loss)
I0526 04:24:12.704763  5200 sgd_solver.cpp:112] Iteration 13130, lr = 0.0025
I0526 04:24:28.565585  5200 solver.cpp:239] Iteration 13156 (1.63934 iter/s, 15.86s/26 iters), loss = 0.00697954
I0526 04:24:28.565762  5200 solver.cpp:258]     Train net output #0: loss = 0.000546273 (* 1 = 0.000546273 loss)
I0526 04:24:28.565769  5200 sgd_solver.cpp:112] Iteration 13156, lr = 0.0025
I0526 04:24:44.403862  5200 solver.cpp:239] Iteration 13182 (1.64162 iter/s, 15.838s/26 iters), loss = 0.00361941
I0526 04:24:44.403908  5200 solver.cpp:258]     Train net output #0: loss = 0.0050655 (* 1 = 0.0050655 loss)
I0526 04:24:44.403915  5200 sgd_solver.cpp:112] Iteration 13182, lr = 0.0025
I0526 04:25:00.228284  5200 solver.cpp:239] Iteration 13208 (1.64307 iter/s, 15.824s/26 iters), loss = 0.0111944
I0526 04:25:00.228435  5200 solver.cpp:258]     Train net output #0: loss = 0.00455596 (* 1 = 0.00455596 loss)
I0526 04:25:00.228443  5200 sgd_solver.cpp:112] Iteration 13208, lr = 0.0025
I0526 04:25:16.059713  5200 solver.cpp:239] Iteration 13234 (1.64235 iter/s, 15.831s/26 iters), loss = 0.00883377
I0526 04:25:16.059753  5200 solver.cpp:258]     Train net output #0: loss = 0.000520455 (* 1 = 0.000520455 loss)
I0526 04:25:16.059762  5200 sgd_solver.cpp:112] Iteration 13234, lr = 0.0025
I0526 04:25:31.852268  5200 solver.cpp:239] Iteration 13260 (1.6464 iter/s, 15.792s/26 iters), loss = 0.00895588
I0526 04:25:31.852430  5200 solver.cpp:258]     Train net output #0: loss = 0.012422 (* 1 = 0.012422 loss)
I0526 04:25:31.852448  5200 sgd_solver.cpp:112] Iteration 13260, lr = 0.0025
I0526 04:25:47.686050  5200 solver.cpp:239] Iteration 13286 (1.64214 iter/s, 15.833s/26 iters), loss = 0.00454311
I0526 04:25:47.686107  5200 solver.cpp:258]     Train net output #0: loss = 0.000984578 (* 1 = 0.000984578 loss)
I0526 04:25:47.686116  5200 sgd_solver.cpp:112] Iteration 13286, lr = 0.0025
I0526 04:26:03.527245  5200 solver.cpp:239] Iteration 13312 (1.64131 iter/s, 15.841s/26 iters), loss = 0.00967679
I0526 04:26:03.527376  5200 solver.cpp:258]     Train net output #0: loss = 0.0744036 (* 1 = 0.0744036 loss)
I0526 04:26:03.527395  5200 sgd_solver.cpp:112] Iteration 13312, lr = 0.0025
I0526 04:26:19.378080  5200 solver.cpp:239] Iteration 13338 (1.64038 iter/s, 15.85s/26 iters), loss = 0.0192437
I0526 04:26:19.378136  5200 solver.cpp:258]     Train net output #0: loss = 0.00204286 (* 1 = 0.00204286 loss)
I0526 04:26:19.378144  5200 sgd_solver.cpp:112] Iteration 13338, lr = 0.0025
I0526 04:26:35.224884  5200 solver.cpp:239] Iteration 13364 (1.64079 iter/s, 15.846s/26 iters), loss = 0.00455404
I0526 04:26:35.225003  5200 solver.cpp:258]     Train net output #0: loss = 0.000958849 (* 1 = 0.000958849 loss)
I0526 04:26:35.225011  5200 sgd_solver.cpp:112] Iteration 13364, lr = 0.0025
I0526 04:26:51.098579  5200 solver.cpp:239] Iteration 13390 (1.638 iter/s, 15.873s/26 iters), loss = 0.00608391
I0526 04:26:51.098637  5200 solver.cpp:258]     Train net output #0: loss = 0.000816949 (* 1 = 0.000816949 loss)
I0526 04:26:51.098645  5200 sgd_solver.cpp:112] Iteration 13390, lr = 0.0025
I0526 04:27:06.933022  5200 solver.cpp:239] Iteration 13416 (1.64204 iter/s, 15.834s/26 iters), loss = 0.00885934
I0526 04:27:06.933200  5200 solver.cpp:258]     Train net output #0: loss = 0.00143901 (* 1 = 0.00143901 loss)
I0526 04:27:06.933218  5200 sgd_solver.cpp:112] Iteration 13416, lr = 0.0025
I0526 04:27:22.747800  5200 solver.cpp:239] Iteration 13442 (1.64411 iter/s, 15.814s/26 iters), loss = 0.00430073
I0526 04:27:22.747857  5200 solver.cpp:258]     Train net output #0: loss = 0.0418722 (* 1 = 0.0418722 loss)
I0526 04:27:22.747866  5200 sgd_solver.cpp:112] Iteration 13442, lr = 0.0025
I0526 04:27:38.572826  5200 solver.cpp:239] Iteration 13468 (1.64307 iter/s, 15.824s/26 iters), loss = 0.00507449
I0526 04:27:38.572962  5200 solver.cpp:258]     Train net output #0: loss = 0.0019159 (* 1 = 0.0019159 loss)
I0526 04:27:38.572978  5200 sgd_solver.cpp:112] Iteration 13468, lr = 0.0025
I0526 04:27:42.221282  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_13475.caffemodel
I0526 04:27:42.221959  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_13475.solverstate
I0526 04:27:42.222275  5200 solver.cpp:347] Iteration 13475, Testing net (#0)
I0526 04:27:53.531514  5200 solver.cpp:414]     Test net output #0: accuracy = 0.998
I0526 04:27:53.531566  5200 solver.cpp:414]     Test net output #1: loss = 0.00458445 (* 1 = 0.00458445 loss)
I0526 04:27:53.531571  5200 solver.cpp:347] Iteration 13475, Testing net (#1)
I0526 04:28:15.334717  5200 solver.cpp:414]     Test net output #0: accuracy = 0.650851
I0526 04:28:15.334903  5200 solver.cpp:414]     Test net output #1: loss = 1.21878 (* 1 = 1.21878 loss)
I0526 04:28:15.334920  5200 solver.cpp:347] Iteration 13475, Testing net (#2)
I0526 04:29:06.147830  5200 solver.cpp:414]     Test net output #0: accuracy = 0.966847
I0526 04:29:06.147994  5200 solver.cpp:414]     Test net output #1: loss = 0.105506 (* 1 = 0.105506 loss)
I0526 04:29:18.339457  5200 solver.cpp:239] Iteration 13494 (0.26061 iter/s, 99.766s/26 iters), loss = 0.00639458
I0526 04:29:18.339512  5200 solver.cpp:258]     Train net output #0: loss = 0.000570817 (* 1 = 0.000570817 loss)
I0526 04:29:18.339520  5200 sgd_solver.cpp:112] Iteration 13494, lr = 0.0025
I0526 04:29:34.199344  5200 solver.cpp:239] Iteration 13520 (1.63945 iter/s, 15.859s/26 iters), loss = 0.00322175
I0526 04:29:34.199396  5200 solver.cpp:258]     Train net output #0: loss = 0.0044151 (* 1 = 0.0044151 loss)
I0526 04:29:34.199405  5200 sgd_solver.cpp:112] Iteration 13520, lr = 0.0025
I0526 04:29:50.112939  5200 solver.cpp:239] Iteration 13546 (1.63388 iter/s, 15.913s/26 iters), loss = 0.00521468
I0526 04:29:50.113093  5200 solver.cpp:258]     Train net output #0: loss = 0.00853915 (* 1 = 0.00853915 loss)
I0526 04:29:50.113111  5200 sgd_solver.cpp:112] Iteration 13546, lr = 0.0025
I0526 04:30:06.018496  5200 solver.cpp:239] Iteration 13572 (1.63471 iter/s, 15.905s/26 iters), loss = 0.007584
I0526 04:30:06.018548  5200 solver.cpp:258]     Train net output #0: loss = 0.000524096 (* 1 = 0.000524096 loss)
I0526 04:30:06.018555  5200 sgd_solver.cpp:112] Iteration 13572, lr = 0.0025
I0526 04:30:21.899899  5200 solver.cpp:239] Iteration 13598 (1.63718 iter/s, 15.881s/26 iters), loss = 0.005689
I0526 04:30:21.900058  5200 solver.cpp:258]     Train net output #0: loss = 0.0153456 (* 1 = 0.0153456 loss)
I0526 04:30:21.900076  5200 sgd_solver.cpp:112] Iteration 13598, lr = 0.0025
I0526 04:30:37.710124  5200 solver.cpp:239] Iteration 13624 (1.64453 iter/s, 15.81s/26 iters), loss = 0.0119875
I0526 04:30:37.710181  5200 solver.cpp:258]     Train net output #0: loss = 0.00221546 (* 1 = 0.00221546 loss)
I0526 04:30:37.710188  5200 sgd_solver.cpp:112] Iteration 13624, lr = 0.0025
I0526 04:30:53.538206  5200 solver.cpp:239] Iteration 13650 (1.64266 iter/s, 15.828s/26 iters), loss = 0.00373928
I0526 04:30:53.538457  5200 solver.cpp:258]     Train net output #0: loss = 0.00131904 (* 1 = 0.00131904 loss)
I0526 04:30:53.538465  5200 sgd_solver.cpp:112] Iteration 13650, lr = 0.0025
I0526 04:31:09.433454  5200 solver.cpp:239] Iteration 13676 (1.63584 iter/s, 15.894s/26 iters), loss = 0.00710167
I0526 04:31:09.433511  5200 solver.cpp:258]     Train net output #0: loss = 0.00018978 (* 1 = 0.00018978 loss)
I0526 04:31:09.433518  5200 sgd_solver.cpp:112] Iteration 13676, lr = 0.0025
I0526 04:31:25.285542  5200 solver.cpp:239] Iteration 13702 (1.64017 iter/s, 15.852s/26 iters), loss = 0.00754269
I0526 04:31:25.285737  5200 solver.cpp:258]     Train net output #0: loss = 0.000481848 (* 1 = 0.000481848 loss)
I0526 04:31:25.285745  5200 sgd_solver.cpp:112] Iteration 13702, lr = 0.0025
I0526 04:31:41.200601  5200 solver.cpp:239] Iteration 13728 (1.63378 iter/s, 15.914s/26 iters), loss = 0.005833
I0526 04:31:41.200645  5200 solver.cpp:258]     Train net output #0: loss = 0.00339607 (* 1 = 0.00339607 loss)
I0526 04:31:41.200654  5200 sgd_solver.cpp:112] Iteration 13728, lr = 0.0025
I0526 04:31:57.063910  5200 solver.cpp:239] Iteration 13754 (1.63903 iter/s, 15.863s/26 iters), loss = 0.00559835
I0526 04:31:57.064096  5200 solver.cpp:258]     Train net output #0: loss = 0.0236657 (* 1 = 0.0236657 loss)
I0526 04:31:57.064105  5200 sgd_solver.cpp:112] Iteration 13754, lr = 0.0025
I0526 04:32:12.936514  5200 solver.cpp:239] Iteration 13780 (1.6381 iter/s, 15.872s/26 iters), loss = 0.00721695
I0526 04:32:12.936565  5200 solver.cpp:258]     Train net output #0: loss = 0.000378643 (* 1 = 0.000378643 loss)
I0526 04:32:12.936573  5200 sgd_solver.cpp:112] Iteration 13780, lr = 0.0025
I0526 04:32:28.791328  5200 solver.cpp:239] Iteration 13806 (1.63996 iter/s, 15.854s/26 iters), loss = 0.00583532
I0526 04:32:28.791472  5200 solver.cpp:258]     Train net output #0: loss = 0.00778779 (* 1 = 0.00778779 loss)
I0526 04:32:28.791491  5200 sgd_solver.cpp:112] Iteration 13806, lr = 0.0025
I0526 04:32:41.004840  5200 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_13827.caffemodel
I0526 04:32:41.005512  5200 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_13827.solverstate
I0526 04:32:41.005825  5200 solver.cpp:332] Optimization Done.
I0526 04:32:41.005831  5200 caffe.cpp:250] Optimization Done.
