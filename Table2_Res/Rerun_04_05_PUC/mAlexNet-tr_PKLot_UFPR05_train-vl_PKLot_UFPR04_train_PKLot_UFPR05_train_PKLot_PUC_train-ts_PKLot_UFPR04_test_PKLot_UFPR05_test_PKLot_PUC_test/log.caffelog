I0526 10:55:29.234237 10701 upgrade_proto.cpp:1084] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': solver.prototxt
I0526 10:55:29.234436 10701 upgrade_proto.cpp:1091] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0526 10:55:29.234441 10701 upgrade_proto.cpp:1093] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0526 10:55:29.234529 10701 caffe.cpp:197] Use CPU.
I0526 10:55:29.234608 10701 solver.cpp:45] Initializing solver from parameters: 
train_net: "train.prototxt"
test_net: "val-PKLot_UFPR04_train.prototxt"
test_net: "val-PKLot_UFPR05_train.prototxt"
test_net: "val-PKLot_PUC_train.prototxt"
test_iter: 25
test_iter: 47
test_iter: 111
test_interval: 735
base_lr: 0.01
display: 49
max_iter: 26425
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 8809
snapshot: 735
snapshot_prefix: "snapshots/snapshot"
solver_mode: CPU
random_seed: 23
train_state {
  level: 0
  stage: ""
}
test_initialization: true
average_loss: 49
type: "SGD"
I0526 10:55:29.234707 10701 solver.cpp:92] Creating training net from train_net file: train.prototxt
I0526 10:55:29.234992 10701 net.cpp:53] Initializing net from parameters: 
name: "mAlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 224
  }
  image_data_param {
    source: "/home/hao/deep-parking/splits/PKLot/UFPR05_train.txt"
    batch_size: 64
    rand_skip: 64
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "/home/hao/Documents/CV/PKLot/PKLotSegmented/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
I0526 10:55:29.235069 10701 layer_factory.hpp:77] Creating layer data
I0526 10:55:29.235100 10701 net.cpp:86] Creating Layer data
I0526 10:55:29.235110 10701 net.cpp:382] data -> data
I0526 10:55:29.235136 10701 net.cpp:382] data -> label
I0526 10:55:29.235155 10701 image_data_layer.cpp:38] Opening file /home/hao/deep-parking/splits/PKLot/UFPR05_train.txt
I0526 10:55:29.263258 10701 image_data_layer.cpp:53] Shuffling data
I0526 10:55:29.290556 10701 image_data_layer.cpp:63] A total of 93955 images.
I0526 10:55:29.290587 10701 image_data_layer.cpp:70] Skipping first 40 data points.
I0526 10:55:29.291445 10701 image_data_layer.cpp:90] output data size: 64,3,224,224
I0526 10:55:29.291554 10701 net.cpp:124] Setting up data
I0526 10:55:29.291574 10701 net.cpp:131] Top shape: 64 3 224 224 (9633792)
I0526 10:55:29.291582 10701 net.cpp:131] Top shape: 64 (64)
I0526 10:55:29.291589 10701 net.cpp:139] Memory required for data: 38535424
I0526 10:55:29.291600 10701 layer_factory.hpp:77] Creating layer conv1
I0526 10:55:29.291630 10701 net.cpp:86] Creating Layer conv1
I0526 10:55:29.291640 10701 net.cpp:408] conv1 <- data
I0526 10:55:29.291657 10701 net.cpp:382] conv1 -> conv1
I0526 10:55:29.291736 10701 net.cpp:124] Setting up conv1
I0526 10:55:29.291748 10701 net.cpp:131] Top shape: 64 16 54 54 (2985984)
I0526 10:55:29.291752 10701 net.cpp:139] Memory required for data: 50479360
I0526 10:55:29.291771 10701 layer_factory.hpp:77] Creating layer relu1
I0526 10:55:29.291782 10701 net.cpp:86] Creating Layer relu1
I0526 10:55:29.291790 10701 net.cpp:408] relu1 <- conv1
I0526 10:55:29.291800 10701 net.cpp:369] relu1 -> conv1 (in-place)
I0526 10:55:29.291810 10701 net.cpp:124] Setting up relu1
I0526 10:55:29.291818 10701 net.cpp:131] Top shape: 64 16 54 54 (2985984)
I0526 10:55:29.291824 10701 net.cpp:139] Memory required for data: 62423296
I0526 10:55:29.291832 10701 layer_factory.hpp:77] Creating layer pool1
I0526 10:55:29.291841 10701 net.cpp:86] Creating Layer pool1
I0526 10:55:29.291846 10701 net.cpp:408] pool1 <- conv1
I0526 10:55:29.291858 10701 net.cpp:382] pool1 -> pool1
I0526 10:55:29.291884 10701 net.cpp:124] Setting up pool1
I0526 10:55:29.291893 10701 net.cpp:131] Top shape: 64 16 27 27 (746496)
I0526 10:55:29.291899 10701 net.cpp:139] Memory required for data: 65409280
I0526 10:55:29.291908 10701 layer_factory.hpp:77] Creating layer conv2
I0526 10:55:29.291921 10701 net.cpp:86] Creating Layer conv2
I0526 10:55:29.291929 10701 net.cpp:408] conv2 <- pool1
I0526 10:55:29.291939 10701 net.cpp:382] conv2 -> conv2
I0526 10:55:29.292016 10701 net.cpp:124] Setting up conv2
I0526 10:55:29.292026 10701 net.cpp:131] Top shape: 64 20 23 23 (677120)
I0526 10:55:29.292034 10701 net.cpp:139] Memory required for data: 68117760
I0526 10:55:29.292047 10701 layer_factory.hpp:77] Creating layer relu2
I0526 10:55:29.292055 10701 net.cpp:86] Creating Layer relu2
I0526 10:55:29.292062 10701 net.cpp:408] relu2 <- conv2
I0526 10:55:29.292071 10701 net.cpp:369] relu2 -> conv2 (in-place)
I0526 10:55:29.292079 10701 net.cpp:124] Setting up relu2
I0526 10:55:29.292088 10701 net.cpp:131] Top shape: 64 20 23 23 (677120)
I0526 10:55:29.292094 10701 net.cpp:139] Memory required for data: 70826240
I0526 10:55:29.292100 10701 layer_factory.hpp:77] Creating layer pool2
I0526 10:55:29.292109 10701 net.cpp:86] Creating Layer pool2
I0526 10:55:29.292115 10701 net.cpp:408] pool2 <- conv2
I0526 10:55:29.292125 10701 net.cpp:382] pool2 -> pool2
I0526 10:55:29.292137 10701 net.cpp:124] Setting up pool2
I0526 10:55:29.292145 10701 net.cpp:131] Top shape: 64 20 11 11 (154880)
I0526 10:55:29.292151 10701 net.cpp:139] Memory required for data: 71445760
I0526 10:55:29.292160 10701 layer_factory.hpp:77] Creating layer conv3
I0526 10:55:29.292173 10701 net.cpp:86] Creating Layer conv3
I0526 10:55:29.292179 10701 net.cpp:408] conv3 <- pool2
I0526 10:55:29.292191 10701 net.cpp:382] conv3 -> conv3
I0526 10:55:29.292254 10701 net.cpp:124] Setting up conv3
I0526 10:55:29.292264 10701 net.cpp:131] Top shape: 64 30 9 9 (155520)
I0526 10:55:29.292289 10701 net.cpp:139] Memory required for data: 72067840
I0526 10:55:29.292302 10701 layer_factory.hpp:77] Creating layer relu3
I0526 10:55:29.292312 10701 net.cpp:86] Creating Layer relu3
I0526 10:55:29.292318 10701 net.cpp:408] relu3 <- conv3
I0526 10:55:29.292327 10701 net.cpp:369] relu3 -> conv3 (in-place)
I0526 10:55:29.292336 10701 net.cpp:124] Setting up relu3
I0526 10:55:29.292345 10701 net.cpp:131] Top shape: 64 30 9 9 (155520)
I0526 10:55:29.292351 10701 net.cpp:139] Memory required for data: 72689920
I0526 10:55:29.292358 10701 layer_factory.hpp:77] Creating layer pool3
I0526 10:55:29.292368 10701 net.cpp:86] Creating Layer pool3
I0526 10:55:29.292376 10701 net.cpp:408] pool3 <- conv3
I0526 10:55:29.292387 10701 net.cpp:382] pool3 -> pool3
I0526 10:55:29.292398 10701 net.cpp:124] Setting up pool3
I0526 10:55:29.292407 10701 net.cpp:131] Top shape: 64 30 4 4 (30720)
I0526 10:55:29.292412 10701 net.cpp:139] Memory required for data: 72812800
I0526 10:55:29.292420 10701 layer_factory.hpp:77] Creating layer fc4
I0526 10:55:29.292433 10701 net.cpp:86] Creating Layer fc4
I0526 10:55:29.292438 10701 net.cpp:408] fc4 <- pool3
I0526 10:55:29.292450 10701 net.cpp:382] fc4 -> fc4
I0526 10:55:29.292584 10701 net.cpp:124] Setting up fc4
I0526 10:55:29.292593 10701 net.cpp:131] Top shape: 64 48 (3072)
I0526 10:55:29.292598 10701 net.cpp:139] Memory required for data: 72825088
I0526 10:55:29.292606 10701 layer_factory.hpp:77] Creating layer relu4
I0526 10:55:29.292616 10701 net.cpp:86] Creating Layer relu4
I0526 10:55:29.292623 10701 net.cpp:408] relu4 <- fc4
I0526 10:55:29.292634 10701 net.cpp:369] relu4 -> fc4 (in-place)
I0526 10:55:29.292642 10701 net.cpp:124] Setting up relu4
I0526 10:55:29.292650 10701 net.cpp:131] Top shape: 64 48 (3072)
I0526 10:55:29.292657 10701 net.cpp:139] Memory required for data: 72837376
I0526 10:55:29.292662 10701 layer_factory.hpp:77] Creating layer fc5
I0526 10:55:29.292673 10701 net.cpp:86] Creating Layer fc5
I0526 10:55:29.292680 10701 net.cpp:408] fc5 <- fc4
I0526 10:55:29.292688 10701 net.cpp:382] fc5 -> fc5
I0526 10:55:29.292709 10701 net.cpp:124] Setting up fc5
I0526 10:55:29.292716 10701 net.cpp:131] Top shape: 64 2 (128)
I0526 10:55:29.292722 10701 net.cpp:139] Memory required for data: 72837888
I0526 10:55:29.292732 10701 layer_factory.hpp:77] Creating layer loss
I0526 10:55:29.292742 10701 net.cpp:86] Creating Layer loss
I0526 10:55:29.292757 10701 net.cpp:408] loss <- fc5
I0526 10:55:29.292766 10701 net.cpp:408] loss <- label
I0526 10:55:29.292775 10701 net.cpp:382] loss -> loss
I0526 10:55:29.292791 10701 layer_factory.hpp:77] Creating layer loss
I0526 10:55:29.292812 10701 net.cpp:124] Setting up loss
I0526 10:55:29.292819 10701 net.cpp:131] Top shape: (1)
I0526 10:55:29.292824 10701 net.cpp:134]     with loss weight 1
I0526 10:55:29.292842 10701 net.cpp:139] Memory required for data: 72837892
I0526 10:55:29.292846 10701 net.cpp:200] loss needs backward computation.
I0526 10:55:29.292853 10701 net.cpp:200] fc5 needs backward computation.
I0526 10:55:29.292860 10701 net.cpp:200] relu4 needs backward computation.
I0526 10:55:29.292862 10701 net.cpp:200] fc4 needs backward computation.
I0526 10:55:29.292865 10701 net.cpp:200] pool3 needs backward computation.
I0526 10:55:29.292870 10701 net.cpp:200] relu3 needs backward computation.
I0526 10:55:29.292872 10701 net.cpp:200] conv3 needs backward computation.
I0526 10:55:29.292876 10701 net.cpp:200] pool2 needs backward computation.
I0526 10:55:29.292881 10701 net.cpp:200] relu2 needs backward computation.
I0526 10:55:29.292884 10701 net.cpp:200] conv2 needs backward computation.
I0526 10:55:29.292888 10701 net.cpp:200] pool1 needs backward computation.
I0526 10:55:29.292892 10701 net.cpp:200] relu1 needs backward computation.
I0526 10:55:29.292896 10701 net.cpp:200] conv1 needs backward computation.
I0526 10:55:29.292898 10701 net.cpp:202] data does not need backward computation.
I0526 10:55:29.292902 10701 net.cpp:244] This network produces output loss
I0526 10:55:29.292912 10701 net.cpp:257] Network initialization done.
I0526 10:55:29.293375 10701 solver.cpp:190] Creating test net (#0) specified by test_net file: val-PKLot_UFPR04_train.prototxt
I0526 10:55:29.293529 10701 net.cpp:53] Initializing net from parameters: 
name: "mAlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 224
  }
  image_data_param {
    source: "/home/hao/deep-parking/splits/PKLot/UFPR04_train.txt"
    batch_size: 100
    rand_skip: 100
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "/home/hao/Documents/CV/PKLot/PKLotSegmented/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0526 10:55:29.293632 10701 layer_factory.hpp:77] Creating layer data
I0526 10:55:29.293646 10701 net.cpp:86] Creating Layer data
I0526 10:55:29.293653 10701 net.cpp:382] data -> data
I0526 10:55:29.293663 10701 net.cpp:382] data -> label
I0526 10:55:29.293673 10701 image_data_layer.cpp:38] Opening file /home/hao/deep-parking/splits/PKLot/UFPR04_train.txt
I0526 10:55:29.325537 10701 image_data_layer.cpp:53] Shuffling data
I0526 10:55:29.342813 10701 image_data_layer.cpp:63] A total of 49160 images.
I0526 10:55:29.342844 10701 image_data_layer.cpp:70] Skipping first 21 data points.
I0526 10:55:29.343248 10701 image_data_layer.cpp:90] output data size: 100,3,224,224
I0526 10:55:29.343379 10701 net.cpp:124] Setting up data
I0526 10:55:29.343398 10701 net.cpp:131] Top shape: 100 3 224 224 (15052800)
I0526 10:55:29.343412 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.343420 10701 net.cpp:139] Memory required for data: 60211600
I0526 10:55:29.343427 10701 layer_factory.hpp:77] Creating layer label_data_1_split
I0526 10:55:29.343449 10701 net.cpp:86] Creating Layer label_data_1_split
I0526 10:55:29.343463 10701 net.cpp:408] label_data_1_split <- label
I0526 10:55:29.343475 10701 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0526 10:55:29.343487 10701 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0526 10:55:29.343498 10701 net.cpp:124] Setting up label_data_1_split
I0526 10:55:29.343504 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.343508 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.343511 10701 net.cpp:139] Memory required for data: 60212400
I0526 10:55:29.343515 10701 layer_factory.hpp:77] Creating layer conv1
I0526 10:55:29.343528 10701 net.cpp:86] Creating Layer conv1
I0526 10:55:29.343533 10701 net.cpp:408] conv1 <- data
I0526 10:55:29.343540 10701 net.cpp:382] conv1 -> conv1
I0526 10:55:29.343600 10701 net.cpp:124] Setting up conv1
I0526 10:55:29.343607 10701 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 10:55:29.343611 10701 net.cpp:139] Memory required for data: 78874800
I0526 10:55:29.343621 10701 layer_factory.hpp:77] Creating layer relu1
I0526 10:55:29.343627 10701 net.cpp:86] Creating Layer relu1
I0526 10:55:29.343636 10701 net.cpp:408] relu1 <- conv1
I0526 10:55:29.343649 10701 net.cpp:369] relu1 -> conv1 (in-place)
I0526 10:55:29.343662 10701 net.cpp:124] Setting up relu1
I0526 10:55:29.343672 10701 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 10:55:29.343679 10701 net.cpp:139] Memory required for data: 97537200
I0526 10:55:29.343688 10701 layer_factory.hpp:77] Creating layer pool1
I0526 10:55:29.343703 10701 net.cpp:86] Creating Layer pool1
I0526 10:55:29.343708 10701 net.cpp:408] pool1 <- conv1
I0526 10:55:29.343716 10701 net.cpp:382] pool1 -> pool1
I0526 10:55:29.343731 10701 net.cpp:124] Setting up pool1
I0526 10:55:29.343740 10701 net.cpp:131] Top shape: 100 16 27 27 (1166400)
I0526 10:55:29.343749 10701 net.cpp:139] Memory required for data: 102202800
I0526 10:55:29.343755 10701 layer_factory.hpp:77] Creating layer conv2
I0526 10:55:29.343770 10701 net.cpp:86] Creating Layer conv2
I0526 10:55:29.343776 10701 net.cpp:408] conv2 <- pool1
I0526 10:55:29.343787 10701 net.cpp:382] conv2 -> conv2
I0526 10:55:29.343856 10701 net.cpp:124] Setting up conv2
I0526 10:55:29.343865 10701 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 10:55:29.343870 10701 net.cpp:139] Memory required for data: 106434800
I0526 10:55:29.343883 10701 layer_factory.hpp:77] Creating layer relu2
I0526 10:55:29.343894 10701 net.cpp:86] Creating Layer relu2
I0526 10:55:29.343900 10701 net.cpp:408] relu2 <- conv2
I0526 10:55:29.343907 10701 net.cpp:369] relu2 -> conv2 (in-place)
I0526 10:55:29.343916 10701 net.cpp:124] Setting up relu2
I0526 10:55:29.343924 10701 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 10:55:29.343930 10701 net.cpp:139] Memory required for data: 110666800
I0526 10:55:29.343938 10701 layer_factory.hpp:77] Creating layer pool2
I0526 10:55:29.343950 10701 net.cpp:86] Creating Layer pool2
I0526 10:55:29.343955 10701 net.cpp:408] pool2 <- conv2
I0526 10:55:29.343963 10701 net.cpp:382] pool2 -> pool2
I0526 10:55:29.343976 10701 net.cpp:124] Setting up pool2
I0526 10:55:29.343991 10701 net.cpp:131] Top shape: 100 20 11 11 (242000)
I0526 10:55:29.343997 10701 net.cpp:139] Memory required for data: 111634800
I0526 10:55:29.344002 10701 layer_factory.hpp:77] Creating layer conv3
I0526 10:55:29.344020 10701 net.cpp:86] Creating Layer conv3
I0526 10:55:29.344025 10701 net.cpp:408] conv3 <- pool2
I0526 10:55:29.344033 10701 net.cpp:382] conv3 -> conv3
I0526 10:55:29.344084 10701 net.cpp:124] Setting up conv3
I0526 10:55:29.344091 10701 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 10:55:29.344094 10701 net.cpp:139] Memory required for data: 112606800
I0526 10:55:29.344115 10701 layer_factory.hpp:77] Creating layer relu3
I0526 10:55:29.344121 10701 net.cpp:86] Creating Layer relu3
I0526 10:55:29.344126 10701 net.cpp:408] relu3 <- conv3
I0526 10:55:29.344131 10701 net.cpp:369] relu3 -> conv3 (in-place)
I0526 10:55:29.344136 10701 net.cpp:124] Setting up relu3
I0526 10:55:29.344143 10701 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 10:55:29.344146 10701 net.cpp:139] Memory required for data: 113578800
I0526 10:55:29.344149 10701 layer_factory.hpp:77] Creating layer pool3
I0526 10:55:29.344154 10701 net.cpp:86] Creating Layer pool3
I0526 10:55:29.344159 10701 net.cpp:408] pool3 <- conv3
I0526 10:55:29.344164 10701 net.cpp:382] pool3 -> pool3
I0526 10:55:29.344172 10701 net.cpp:124] Setting up pool3
I0526 10:55:29.344177 10701 net.cpp:131] Top shape: 100 30 4 4 (48000)
I0526 10:55:29.344180 10701 net.cpp:139] Memory required for data: 113770800
I0526 10:55:29.344184 10701 layer_factory.hpp:77] Creating layer fc4
I0526 10:55:29.344192 10701 net.cpp:86] Creating Layer fc4
I0526 10:55:29.344197 10701 net.cpp:408] fc4 <- pool3
I0526 10:55:29.344202 10701 net.cpp:382] fc4 -> fc4
I0526 10:55:29.344388 10701 net.cpp:124] Setting up fc4
I0526 10:55:29.344398 10701 net.cpp:131] Top shape: 100 48 (4800)
I0526 10:55:29.344400 10701 net.cpp:139] Memory required for data: 113790000
I0526 10:55:29.344406 10701 layer_factory.hpp:77] Creating layer relu4
I0526 10:55:29.344413 10701 net.cpp:86] Creating Layer relu4
I0526 10:55:29.344417 10701 net.cpp:408] relu4 <- fc4
I0526 10:55:29.344422 10701 net.cpp:369] relu4 -> fc4 (in-place)
I0526 10:55:29.344429 10701 net.cpp:124] Setting up relu4
I0526 10:55:29.344432 10701 net.cpp:131] Top shape: 100 48 (4800)
I0526 10:55:29.344435 10701 net.cpp:139] Memory required for data: 113809200
I0526 10:55:29.344439 10701 layer_factory.hpp:77] Creating layer fc5
I0526 10:55:29.344444 10701 net.cpp:86] Creating Layer fc5
I0526 10:55:29.344447 10701 net.cpp:408] fc5 <- fc4
I0526 10:55:29.344453 10701 net.cpp:382] fc5 -> fc5
I0526 10:55:29.344481 10701 net.cpp:124] Setting up fc5
I0526 10:55:29.344501 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.344506 10701 net.cpp:139] Memory required for data: 113810000
I0526 10:55:29.344517 10701 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0526 10:55:29.344527 10701 net.cpp:86] Creating Layer fc5_fc5_0_split
I0526 10:55:29.344532 10701 net.cpp:408] fc5_fc5_0_split <- fc5
I0526 10:55:29.344537 10701 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0526 10:55:29.344544 10701 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0526 10:55:29.344552 10701 net.cpp:124] Setting up fc5_fc5_0_split
I0526 10:55:29.344557 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.344560 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.344563 10701 net.cpp:139] Memory required for data: 113811600
I0526 10:55:29.344566 10701 layer_factory.hpp:77] Creating layer loss
I0526 10:55:29.344571 10701 net.cpp:86] Creating Layer loss
I0526 10:55:29.344574 10701 net.cpp:408] loss <- fc5_fc5_0_split_0
I0526 10:55:29.344578 10701 net.cpp:408] loss <- label_data_1_split_0
I0526 10:55:29.344583 10701 net.cpp:382] loss -> loss
I0526 10:55:29.344591 10701 layer_factory.hpp:77] Creating layer loss
I0526 10:55:29.344604 10701 net.cpp:124] Setting up loss
I0526 10:55:29.344607 10701 net.cpp:131] Top shape: (1)
I0526 10:55:29.344610 10701 net.cpp:134]     with loss weight 1
I0526 10:55:29.344619 10701 net.cpp:139] Memory required for data: 113811604
I0526 10:55:29.344622 10701 layer_factory.hpp:77] Creating layer accuracy
I0526 10:55:29.344630 10701 net.cpp:86] Creating Layer accuracy
I0526 10:55:29.344632 10701 net.cpp:408] accuracy <- fc5_fc5_0_split_1
I0526 10:55:29.344636 10701 net.cpp:408] accuracy <- label_data_1_split_1
I0526 10:55:29.344641 10701 net.cpp:382] accuracy -> accuracy
I0526 10:55:29.344647 10701 net.cpp:124] Setting up accuracy
I0526 10:55:29.344650 10701 net.cpp:131] Top shape: (1)
I0526 10:55:29.344653 10701 net.cpp:139] Memory required for data: 113811608
I0526 10:55:29.344668 10701 net.cpp:202] accuracy does not need backward computation.
I0526 10:55:29.344672 10701 net.cpp:200] loss needs backward computation.
I0526 10:55:29.344676 10701 net.cpp:200] fc5_fc5_0_split needs backward computation.
I0526 10:55:29.344681 10701 net.cpp:200] fc5 needs backward computation.
I0526 10:55:29.344683 10701 net.cpp:200] relu4 needs backward computation.
I0526 10:55:29.344686 10701 net.cpp:200] fc4 needs backward computation.
I0526 10:55:29.344691 10701 net.cpp:200] pool3 needs backward computation.
I0526 10:55:29.344696 10701 net.cpp:200] relu3 needs backward computation.
I0526 10:55:29.344702 10701 net.cpp:200] conv3 needs backward computation.
I0526 10:55:29.344707 10701 net.cpp:200] pool2 needs backward computation.
I0526 10:55:29.344712 10701 net.cpp:200] relu2 needs backward computation.
I0526 10:55:29.344715 10701 net.cpp:200] conv2 needs backward computation.
I0526 10:55:29.344720 10701 net.cpp:200] pool1 needs backward computation.
I0526 10:55:29.344727 10701 net.cpp:200] relu1 needs backward computation.
I0526 10:55:29.344732 10701 net.cpp:200] conv1 needs backward computation.
I0526 10:55:29.344738 10701 net.cpp:202] label_data_1_split does not need backward computation.
I0526 10:55:29.344743 10701 net.cpp:202] data does not need backward computation.
I0526 10:55:29.344748 10701 net.cpp:244] This network produces output accuracy
I0526 10:55:29.344753 10701 net.cpp:244] This network produces output loss
I0526 10:55:29.344769 10701 net.cpp:257] Network initialization done.
I0526 10:55:29.344846 10701 solver.cpp:190] Creating test net (#1) specified by test_net file: val-PKLot_UFPR05_train.prototxt
I0526 10:55:29.344987 10701 net.cpp:53] Initializing net from parameters: 
name: "mAlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 224
  }
  image_data_param {
    source: "/home/hao/deep-parking/splits/PKLot/UFPR05_train.txt"
    batch_size: 100
    rand_skip: 100
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "/home/hao/Documents/CV/PKLot/PKLotSegmented/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0526 10:55:29.345070 10701 layer_factory.hpp:77] Creating layer data
I0526 10:55:29.345082 10701 net.cpp:86] Creating Layer data
I0526 10:55:29.345088 10701 net.cpp:382] data -> data
I0526 10:55:29.345094 10701 net.cpp:382] data -> label
I0526 10:55:29.345103 10701 image_data_layer.cpp:38] Opening file /home/hao/deep-parking/splits/PKLot/UFPR05_train.txt
I0526 10:55:29.402115 10701 image_data_layer.cpp:53] Shuffling data
I0526 10:55:29.437114 10701 image_data_layer.cpp:63] A total of 93955 images.
I0526 10:55:29.437136 10701 image_data_layer.cpp:70] Skipping first 38 data points.
I0526 10:55:29.437649 10701 image_data_layer.cpp:90] output data size: 100,3,224,224
I0526 10:55:29.437752 10701 net.cpp:124] Setting up data
I0526 10:55:29.437765 10701 net.cpp:131] Top shape: 100 3 224 224 (15052800)
I0526 10:55:29.437770 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.437773 10701 net.cpp:139] Memory required for data: 60211600
I0526 10:55:29.437779 10701 layer_factory.hpp:77] Creating layer label_data_1_split
I0526 10:55:29.437793 10701 net.cpp:86] Creating Layer label_data_1_split
I0526 10:55:29.437800 10701 net.cpp:408] label_data_1_split <- label
I0526 10:55:29.437809 10701 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0526 10:55:29.437821 10701 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0526 10:55:29.437831 10701 net.cpp:124] Setting up label_data_1_split
I0526 10:55:29.437839 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.437844 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.437849 10701 net.cpp:139] Memory required for data: 60212400
I0526 10:55:29.437857 10701 layer_factory.hpp:77] Creating layer conv1
I0526 10:55:29.437875 10701 net.cpp:86] Creating Layer conv1
I0526 10:55:29.437885 10701 net.cpp:408] conv1 <- data
I0526 10:55:29.437901 10701 net.cpp:382] conv1 -> conv1
I0526 10:55:29.437974 10701 net.cpp:124] Setting up conv1
I0526 10:55:29.437988 10701 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 10:55:29.437999 10701 net.cpp:139] Memory required for data: 78874800
I0526 10:55:29.438016 10701 layer_factory.hpp:77] Creating layer relu1
I0526 10:55:29.438028 10701 net.cpp:86] Creating Layer relu1
I0526 10:55:29.438036 10701 net.cpp:408] relu1 <- conv1
I0526 10:55:29.438047 10701 net.cpp:369] relu1 -> conv1 (in-place)
I0526 10:55:29.438055 10701 net.cpp:124] Setting up relu1
I0526 10:55:29.438061 10701 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 10:55:29.438064 10701 net.cpp:139] Memory required for data: 97537200
I0526 10:55:29.438067 10701 layer_factory.hpp:77] Creating layer pool1
I0526 10:55:29.438076 10701 net.cpp:86] Creating Layer pool1
I0526 10:55:29.438081 10701 net.cpp:408] pool1 <- conv1
I0526 10:55:29.438086 10701 net.cpp:382] pool1 -> pool1
I0526 10:55:29.438100 10701 net.cpp:124] Setting up pool1
I0526 10:55:29.438110 10701 net.cpp:131] Top shape: 100 16 27 27 (1166400)
I0526 10:55:29.438117 10701 net.cpp:139] Memory required for data: 102202800
I0526 10:55:29.438125 10701 layer_factory.hpp:77] Creating layer conv2
I0526 10:55:29.438134 10701 net.cpp:86] Creating Layer conv2
I0526 10:55:29.438138 10701 net.cpp:408] conv2 <- pool1
I0526 10:55:29.438145 10701 net.cpp:382] conv2 -> conv2
I0526 10:55:29.438248 10701 net.cpp:124] Setting up conv2
I0526 10:55:29.438282 10701 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 10:55:29.438287 10701 net.cpp:139] Memory required for data: 106434800
I0526 10:55:29.438298 10701 layer_factory.hpp:77] Creating layer relu2
I0526 10:55:29.438309 10701 net.cpp:86] Creating Layer relu2
I0526 10:55:29.438316 10701 net.cpp:408] relu2 <- conv2
I0526 10:55:29.438328 10701 net.cpp:369] relu2 -> conv2 (in-place)
I0526 10:55:29.438336 10701 net.cpp:124] Setting up relu2
I0526 10:55:29.438344 10701 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 10:55:29.438351 10701 net.cpp:139] Memory required for data: 110666800
I0526 10:55:29.438359 10701 layer_factory.hpp:77] Creating layer pool2
I0526 10:55:29.438369 10701 net.cpp:86] Creating Layer pool2
I0526 10:55:29.438376 10701 net.cpp:408] pool2 <- conv2
I0526 10:55:29.438387 10701 net.cpp:382] pool2 -> pool2
I0526 10:55:29.438400 10701 net.cpp:124] Setting up pool2
I0526 10:55:29.438408 10701 net.cpp:131] Top shape: 100 20 11 11 (242000)
I0526 10:55:29.438414 10701 net.cpp:139] Memory required for data: 111634800
I0526 10:55:29.438422 10701 layer_factory.hpp:77] Creating layer conv3
I0526 10:55:29.438437 10701 net.cpp:86] Creating Layer conv3
I0526 10:55:29.438443 10701 net.cpp:408] conv3 <- pool2
I0526 10:55:29.438453 10701 net.cpp:382] conv3 -> conv3
I0526 10:55:29.438526 10701 net.cpp:124] Setting up conv3
I0526 10:55:29.438542 10701 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 10:55:29.438549 10701 net.cpp:139] Memory required for data: 112606800
I0526 10:55:29.438560 10701 layer_factory.hpp:77] Creating layer relu3
I0526 10:55:29.438567 10701 net.cpp:86] Creating Layer relu3
I0526 10:55:29.438572 10701 net.cpp:408] relu3 <- conv3
I0526 10:55:29.438577 10701 net.cpp:369] relu3 -> conv3 (in-place)
I0526 10:55:29.438582 10701 net.cpp:124] Setting up relu3
I0526 10:55:29.438588 10701 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 10:55:29.438591 10701 net.cpp:139] Memory required for data: 113578800
I0526 10:55:29.438594 10701 layer_factory.hpp:77] Creating layer pool3
I0526 10:55:29.438599 10701 net.cpp:86] Creating Layer pool3
I0526 10:55:29.438603 10701 net.cpp:408] pool3 <- conv3
I0526 10:55:29.438611 10701 net.cpp:382] pool3 -> pool3
I0526 10:55:29.438625 10701 net.cpp:124] Setting up pool3
I0526 10:55:29.438637 10701 net.cpp:131] Top shape: 100 30 4 4 (48000)
I0526 10:55:29.438639 10701 net.cpp:139] Memory required for data: 113770800
I0526 10:55:29.438643 10701 layer_factory.hpp:77] Creating layer fc4
I0526 10:55:29.438652 10701 net.cpp:86] Creating Layer fc4
I0526 10:55:29.438661 10701 net.cpp:408] fc4 <- pool3
I0526 10:55:29.438675 10701 net.cpp:382] fc4 -> fc4
I0526 10:55:29.438819 10701 net.cpp:124] Setting up fc4
I0526 10:55:29.438827 10701 net.cpp:131] Top shape: 100 48 (4800)
I0526 10:55:29.438832 10701 net.cpp:139] Memory required for data: 113790000
I0526 10:55:29.438836 10701 layer_factory.hpp:77] Creating layer relu4
I0526 10:55:29.438843 10701 net.cpp:86] Creating Layer relu4
I0526 10:55:29.438846 10701 net.cpp:408] relu4 <- fc4
I0526 10:55:29.438853 10701 net.cpp:369] relu4 -> fc4 (in-place)
I0526 10:55:29.438858 10701 net.cpp:124] Setting up relu4
I0526 10:55:29.438861 10701 net.cpp:131] Top shape: 100 48 (4800)
I0526 10:55:29.438864 10701 net.cpp:139] Memory required for data: 113809200
I0526 10:55:29.438868 10701 layer_factory.hpp:77] Creating layer fc5
I0526 10:55:29.438874 10701 net.cpp:86] Creating Layer fc5
I0526 10:55:29.438877 10701 net.cpp:408] fc5 <- fc4
I0526 10:55:29.438884 10701 net.cpp:382] fc5 -> fc5
I0526 10:55:29.438915 10701 net.cpp:124] Setting up fc5
I0526 10:55:29.438941 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.438948 10701 net.cpp:139] Memory required for data: 113810000
I0526 10:55:29.438961 10701 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0526 10:55:29.438971 10701 net.cpp:86] Creating Layer fc5_fc5_0_split
I0526 10:55:29.438977 10701 net.cpp:408] fc5_fc5_0_split <- fc5
I0526 10:55:29.438988 10701 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0526 10:55:29.438998 10701 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0526 10:55:29.439024 10701 net.cpp:124] Setting up fc5_fc5_0_split
I0526 10:55:29.439031 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.439060 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.439070 10701 net.cpp:139] Memory required for data: 113811600
I0526 10:55:29.439075 10701 layer_factory.hpp:77] Creating layer loss
I0526 10:55:29.439085 10701 net.cpp:86] Creating Layer loss
I0526 10:55:29.439093 10701 net.cpp:408] loss <- fc5_fc5_0_split_0
I0526 10:55:29.439098 10701 net.cpp:408] loss <- label_data_1_split_0
I0526 10:55:29.439105 10701 net.cpp:382] loss -> loss
I0526 10:55:29.439113 10701 layer_factory.hpp:77] Creating layer loss
I0526 10:55:29.439128 10701 net.cpp:124] Setting up loss
I0526 10:55:29.439134 10701 net.cpp:131] Top shape: (1)
I0526 10:55:29.439142 10701 net.cpp:134]     with loss weight 1
I0526 10:55:29.439157 10701 net.cpp:139] Memory required for data: 113811604
I0526 10:55:29.439163 10701 layer_factory.hpp:77] Creating layer accuracy
I0526 10:55:29.439172 10701 net.cpp:86] Creating Layer accuracy
I0526 10:55:29.439178 10701 net.cpp:408] accuracy <- fc5_fc5_0_split_1
I0526 10:55:29.439182 10701 net.cpp:408] accuracy <- label_data_1_split_1
I0526 10:55:29.439189 10701 net.cpp:382] accuracy -> accuracy
I0526 10:55:29.439203 10701 net.cpp:124] Setting up accuracy
I0526 10:55:29.439213 10701 net.cpp:131] Top shape: (1)
I0526 10:55:29.439218 10701 net.cpp:139] Memory required for data: 113811608
I0526 10:55:29.439221 10701 net.cpp:202] accuracy does not need backward computation.
I0526 10:55:29.439226 10701 net.cpp:200] loss needs backward computation.
I0526 10:55:29.439230 10701 net.cpp:200] fc5_fc5_0_split needs backward computation.
I0526 10:55:29.439234 10701 net.cpp:200] fc5 needs backward computation.
I0526 10:55:29.439236 10701 net.cpp:200] relu4 needs backward computation.
I0526 10:55:29.439239 10701 net.cpp:200] fc4 needs backward computation.
I0526 10:55:29.439244 10701 net.cpp:200] pool3 needs backward computation.
I0526 10:55:29.439246 10701 net.cpp:200] relu3 needs backward computation.
I0526 10:55:29.439249 10701 net.cpp:200] conv3 needs backward computation.
I0526 10:55:29.439254 10701 net.cpp:200] pool2 needs backward computation.
I0526 10:55:29.439257 10701 net.cpp:200] relu2 needs backward computation.
I0526 10:55:29.439260 10701 net.cpp:200] conv2 needs backward computation.
I0526 10:55:29.439263 10701 net.cpp:200] pool1 needs backward computation.
I0526 10:55:29.439266 10701 net.cpp:200] relu1 needs backward computation.
I0526 10:55:29.439270 10701 net.cpp:200] conv1 needs backward computation.
I0526 10:55:29.439273 10701 net.cpp:202] label_data_1_split does not need backward computation.
I0526 10:55:29.439280 10701 net.cpp:202] data does not need backward computation.
I0526 10:55:29.439291 10701 net.cpp:244] This network produces output accuracy
I0526 10:55:29.439299 10701 net.cpp:244] This network produces output loss
I0526 10:55:29.439319 10701 net.cpp:257] Network initialization done.
I0526 10:55:29.439401 10701 solver.cpp:190] Creating test net (#2) specified by test_net file: val-PKLot_PUC_train.prototxt
I0526 10:55:29.439545 10701 net.cpp:53] Initializing net from parameters: 
name: "mAlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 224
  }
  image_data_param {
    source: "/home/hao/deep-parking/splits/PKLot/PUC_train.txt"
    batch_size: 100
    rand_skip: 100
    shuffle: true
    new_height: 256
    new_width: 256
    root_folder: "/home/hao/Documents/CV/PKLot/PKLotSegmented/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc5"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0526 10:55:29.439648 10701 layer_factory.hpp:77] Creating layer data
I0526 10:55:29.439669 10701 net.cpp:86] Creating Layer data
I0526 10:55:29.439680 10701 net.cpp:382] data -> data
I0526 10:55:29.439693 10701 net.cpp:382] data -> label
I0526 10:55:29.439707 10701 image_data_layer.cpp:38] Opening file /home/hao/deep-parking/splits/PKLot/PUC_train.txt
I0526 10:55:29.586602 10701 image_data_layer.cpp:53] Shuffling data
I0526 10:55:29.751650 10701 image_data_layer.cpp:63] A total of 220713 images.
I0526 10:55:29.751672 10701 image_data_layer.cpp:70] Skipping first 90 data points.
I0526 10:55:29.752049 10701 image_data_layer.cpp:90] output data size: 100,3,224,224
I0526 10:55:29.752147 10701 net.cpp:124] Setting up data
I0526 10:55:29.752167 10701 net.cpp:131] Top shape: 100 3 224 224 (15052800)
I0526 10:55:29.752177 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.752182 10701 net.cpp:139] Memory required for data: 60211600
I0526 10:55:29.752190 10701 layer_factory.hpp:77] Creating layer label_data_1_split
I0526 10:55:29.752211 10701 net.cpp:86] Creating Layer label_data_1_split
I0526 10:55:29.752221 10701 net.cpp:408] label_data_1_split <- label
I0526 10:55:29.752239 10701 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0526 10:55:29.752259 10701 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0526 10:55:29.752271 10701 net.cpp:124] Setting up label_data_1_split
I0526 10:55:29.752281 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.752288 10701 net.cpp:131] Top shape: 100 (100)
I0526 10:55:29.752295 10701 net.cpp:139] Memory required for data: 60212400
I0526 10:55:29.752300 10701 layer_factory.hpp:77] Creating layer conv1
I0526 10:55:29.752323 10701 net.cpp:86] Creating Layer conv1
I0526 10:55:29.752331 10701 net.cpp:408] conv1 <- data
I0526 10:55:29.752373 10701 net.cpp:382] conv1 -> conv1
I0526 10:55:29.752480 10701 net.cpp:124] Setting up conv1
I0526 10:55:29.752493 10701 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 10:55:29.752501 10701 net.cpp:139] Memory required for data: 78874800
I0526 10:55:29.752516 10701 layer_factory.hpp:77] Creating layer relu1
I0526 10:55:29.752526 10701 net.cpp:86] Creating Layer relu1
I0526 10:55:29.752533 10701 net.cpp:408] relu1 <- conv1
I0526 10:55:29.752542 10701 net.cpp:369] relu1 -> conv1 (in-place)
I0526 10:55:29.752552 10701 net.cpp:124] Setting up relu1
I0526 10:55:29.752560 10701 net.cpp:131] Top shape: 100 16 54 54 (4665600)
I0526 10:55:29.752570 10701 net.cpp:139] Memory required for data: 97537200
I0526 10:55:29.752579 10701 layer_factory.hpp:77] Creating layer pool1
I0526 10:55:29.752595 10701 net.cpp:86] Creating Layer pool1
I0526 10:55:29.752602 10701 net.cpp:408] pool1 <- conv1
I0526 10:55:29.752611 10701 net.cpp:382] pool1 -> pool1
I0526 10:55:29.752629 10701 net.cpp:124] Setting up pool1
I0526 10:55:29.752636 10701 net.cpp:131] Top shape: 100 16 27 27 (1166400)
I0526 10:55:29.752641 10701 net.cpp:139] Memory required for data: 102202800
I0526 10:55:29.752646 10701 layer_factory.hpp:77] Creating layer conv2
I0526 10:55:29.752660 10701 net.cpp:86] Creating Layer conv2
I0526 10:55:29.752667 10701 net.cpp:408] conv2 <- pool1
I0526 10:55:29.752677 10701 net.cpp:382] conv2 -> conv2
I0526 10:55:29.752789 10701 net.cpp:124] Setting up conv2
I0526 10:55:29.752801 10701 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 10:55:29.752806 10701 net.cpp:139] Memory required for data: 106434800
I0526 10:55:29.752822 10701 layer_factory.hpp:77] Creating layer relu2
I0526 10:55:29.752835 10701 net.cpp:86] Creating Layer relu2
I0526 10:55:29.752843 10701 net.cpp:408] relu2 <- conv2
I0526 10:55:29.752852 10701 net.cpp:369] relu2 -> conv2 (in-place)
I0526 10:55:29.752861 10701 net.cpp:124] Setting up relu2
I0526 10:55:29.752871 10701 net.cpp:131] Top shape: 100 20 23 23 (1058000)
I0526 10:55:29.752876 10701 net.cpp:139] Memory required for data: 110666800
I0526 10:55:29.752882 10701 layer_factory.hpp:77] Creating layer pool2
I0526 10:55:29.752892 10701 net.cpp:86] Creating Layer pool2
I0526 10:55:29.752898 10701 net.cpp:408] pool2 <- conv2
I0526 10:55:29.752907 10701 net.cpp:382] pool2 -> pool2
I0526 10:55:29.752920 10701 net.cpp:124] Setting up pool2
I0526 10:55:29.752929 10701 net.cpp:131] Top shape: 100 20 11 11 (242000)
I0526 10:55:29.752935 10701 net.cpp:139] Memory required for data: 111634800
I0526 10:55:29.752943 10701 layer_factory.hpp:77] Creating layer conv3
I0526 10:55:29.752964 10701 net.cpp:86] Creating Layer conv3
I0526 10:55:29.752971 10701 net.cpp:408] conv3 <- pool2
I0526 10:55:29.752981 10701 net.cpp:382] conv3 -> conv3
I0526 10:55:29.753068 10701 net.cpp:124] Setting up conv3
I0526 10:55:29.753078 10701 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 10:55:29.753083 10701 net.cpp:139] Memory required for data: 112606800
I0526 10:55:29.753094 10701 layer_factory.hpp:77] Creating layer relu3
I0526 10:55:29.753103 10701 net.cpp:86] Creating Layer relu3
I0526 10:55:29.753111 10701 net.cpp:408] relu3 <- conv3
I0526 10:55:29.753118 10701 net.cpp:369] relu3 -> conv3 (in-place)
I0526 10:55:29.753127 10701 net.cpp:124] Setting up relu3
I0526 10:55:29.753135 10701 net.cpp:131] Top shape: 100 30 9 9 (243000)
I0526 10:55:29.753142 10701 net.cpp:139] Memory required for data: 113578800
I0526 10:55:29.753146 10701 layer_factory.hpp:77] Creating layer pool3
I0526 10:55:29.753156 10701 net.cpp:86] Creating Layer pool3
I0526 10:55:29.753163 10701 net.cpp:408] pool3 <- conv3
I0526 10:55:29.753172 10701 net.cpp:382] pool3 -> pool3
I0526 10:55:29.753185 10701 net.cpp:124] Setting up pool3
I0526 10:55:29.753194 10701 net.cpp:131] Top shape: 100 30 4 4 (48000)
I0526 10:55:29.753201 10701 net.cpp:139] Memory required for data: 113770800
I0526 10:55:29.753206 10701 layer_factory.hpp:77] Creating layer fc4
I0526 10:55:29.753216 10701 net.cpp:86] Creating Layer fc4
I0526 10:55:29.753224 10701 net.cpp:408] fc4 <- pool3
I0526 10:55:29.753253 10701 net.cpp:382] fc4 -> fc4
I0526 10:55:29.753496 10701 net.cpp:124] Setting up fc4
I0526 10:55:29.753506 10701 net.cpp:131] Top shape: 100 48 (4800)
I0526 10:55:29.753511 10701 net.cpp:139] Memory required for data: 113790000
I0526 10:55:29.753520 10701 layer_factory.hpp:77] Creating layer relu4
I0526 10:55:29.753532 10701 net.cpp:86] Creating Layer relu4
I0526 10:55:29.753540 10701 net.cpp:408] relu4 <- fc4
I0526 10:55:29.753548 10701 net.cpp:369] relu4 -> fc4 (in-place)
I0526 10:55:29.753558 10701 net.cpp:124] Setting up relu4
I0526 10:55:29.753567 10701 net.cpp:131] Top shape: 100 48 (4800)
I0526 10:55:29.753572 10701 net.cpp:139] Memory required for data: 113809200
I0526 10:55:29.753579 10701 layer_factory.hpp:77] Creating layer fc5
I0526 10:55:29.753593 10701 net.cpp:86] Creating Layer fc5
I0526 10:55:29.753599 10701 net.cpp:408] fc5 <- fc4
I0526 10:55:29.753610 10701 net.cpp:382] fc5 -> fc5
I0526 10:55:29.753631 10701 net.cpp:124] Setting up fc5
I0526 10:55:29.753639 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.753646 10701 net.cpp:139] Memory required for data: 113810000
I0526 10:55:29.753655 10701 layer_factory.hpp:77] Creating layer fc5_fc5_0_split
I0526 10:55:29.753667 10701 net.cpp:86] Creating Layer fc5_fc5_0_split
I0526 10:55:29.753675 10701 net.cpp:408] fc5_fc5_0_split <- fc5
I0526 10:55:29.753686 10701 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_0
I0526 10:55:29.753697 10701 net.cpp:382] fc5_fc5_0_split -> fc5_fc5_0_split_1
I0526 10:55:29.753713 10701 net.cpp:124] Setting up fc5_fc5_0_split
I0526 10:55:29.753722 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.753731 10701 net.cpp:131] Top shape: 100 2 (200)
I0526 10:55:29.753736 10701 net.cpp:139] Memory required for data: 113811600
I0526 10:55:29.753746 10701 layer_factory.hpp:77] Creating layer loss
I0526 10:55:29.753753 10701 net.cpp:86] Creating Layer loss
I0526 10:55:29.753762 10701 net.cpp:408] loss <- fc5_fc5_0_split_0
I0526 10:55:29.753767 10701 net.cpp:408] loss <- label_data_1_split_0
I0526 10:55:29.753778 10701 net.cpp:382] loss -> loss
I0526 10:55:29.753791 10701 layer_factory.hpp:77] Creating layer loss
I0526 10:55:29.753811 10701 net.cpp:124] Setting up loss
I0526 10:55:29.753820 10701 net.cpp:131] Top shape: (1)
I0526 10:55:29.753824 10701 net.cpp:134]     with loss weight 1
I0526 10:55:29.753839 10701 net.cpp:139] Memory required for data: 113811604
I0526 10:55:29.753844 10701 layer_factory.hpp:77] Creating layer accuracy
I0526 10:55:29.753857 10701 net.cpp:86] Creating Layer accuracy
I0526 10:55:29.753865 10701 net.cpp:408] accuracy <- fc5_fc5_0_split_1
I0526 10:55:29.753871 10701 net.cpp:408] accuracy <- label_data_1_split_1
I0526 10:55:29.753880 10701 net.cpp:382] accuracy -> accuracy
I0526 10:55:29.753890 10701 net.cpp:124] Setting up accuracy
I0526 10:55:29.753898 10701 net.cpp:131] Top shape: (1)
I0526 10:55:29.753906 10701 net.cpp:139] Memory required for data: 113811608
I0526 10:55:29.753911 10701 net.cpp:202] accuracy does not need backward computation.
I0526 10:55:29.753919 10701 net.cpp:200] loss needs backward computation.
I0526 10:55:29.753927 10701 net.cpp:200] fc5_fc5_0_split needs backward computation.
I0526 10:55:29.753935 10701 net.cpp:200] fc5 needs backward computation.
I0526 10:55:29.753942 10701 net.cpp:200] relu4 needs backward computation.
I0526 10:55:29.753950 10701 net.cpp:200] fc4 needs backward computation.
I0526 10:55:29.753958 10701 net.cpp:200] pool3 needs backward computation.
I0526 10:55:29.753965 10701 net.cpp:200] relu3 needs backward computation.
I0526 10:55:29.753973 10701 net.cpp:200] conv3 needs backward computation.
I0526 10:55:29.753981 10701 net.cpp:200] pool2 needs backward computation.
I0526 10:55:29.753988 10701 net.cpp:200] relu2 needs backward computation.
I0526 10:55:29.753996 10701 net.cpp:200] conv2 needs backward computation.
I0526 10:55:29.754004 10701 net.cpp:200] pool1 needs backward computation.
I0526 10:55:29.754012 10701 net.cpp:200] relu1 needs backward computation.
I0526 10:55:29.754017 10701 net.cpp:200] conv1 needs backward computation.
I0526 10:55:29.754042 10701 net.cpp:202] label_data_1_split does not need backward computation.
I0526 10:55:29.754051 10701 net.cpp:202] data does not need backward computation.
I0526 10:55:29.754060 10701 net.cpp:244] This network produces output accuracy
I0526 10:55:29.754065 10701 net.cpp:244] This network produces output loss
I0526 10:55:29.754086 10701 net.cpp:257] Network initialization done.
I0526 10:55:29.754384 10701 solver.cpp:57] Solver scaffolding done.
I0526 10:55:29.754459 10701 caffe.cpp:239] Starting Optimization
I0526 10:55:29.754468 10701 solver.cpp:289] Solving mAlexNet
I0526 10:55:29.754473 10701 solver.cpp:290] Learning Rate Policy: step
I0526 10:55:29.754623 10701 solver.cpp:347] Iteration 0, Testing net (#0)
I0526 10:55:45.473116 10701 solver.cpp:414]     Test net output #0: accuracy = 0.52
I0526 10:55:45.473151 10701 solver.cpp:414]     Test net output #1: loss = 1.46103 (* 1 = 1.46103 loss)
I0526 10:55:45.473157 10701 solver.cpp:347] Iteration 0, Testing net (#1)
I0526 10:56:15.012867 10701 solver.cpp:414]     Test net output #0: accuracy = 0.483404
I0526 10:56:15.012976 10701 solver.cpp:414]     Test net output #1: loss = 1.65894 (* 1 = 1.65894 loss)
I0526 10:56:15.012984 10701 solver.cpp:347] Iteration 0, Testing net (#2)
I0526 10:57:22.339893 10701 solver.cpp:414]     Test net output #0: accuracy = 0.514144
I0526 10:57:22.340011 10701 solver.cpp:414]     Test net output #1: loss = 1.49652 (* 1 = 1.49652 loss)
I0526 10:57:23.272370 10701 solver.cpp:239] Iteration 0 (0 iter/s, 113.517s/49 iters), loss = 1.61963
I0526 10:57:23.272410 10701 solver.cpp:258]     Train net output #0: loss = 1.61963 (* 1 = 1.61963 loss)
I0526 10:57:23.272425 10701 sgd_solver.cpp:112] Iteration 0, lr = 0.01
I0526 10:58:10.505753 10701 solver.cpp:239] Iteration 49 (1.03741 iter/s, 47.233s/49 iters), loss = 0.606221
I0526 10:58:10.505893 10701 solver.cpp:258]     Train net output #0: loss = 0.0444426 (* 1 = 0.0444426 loss)
I0526 10:58:10.505909 10701 sgd_solver.cpp:112] Iteration 49, lr = 0.01
I0526 10:58:59.516538 10701 solver.cpp:239] Iteration 98 (0.999796 iter/s, 49.01s/49 iters), loss = 0.315656
I0526 10:58:59.516741 10701 solver.cpp:258]     Train net output #0: loss = 0.153415 (* 1 = 0.153415 loss)
I0526 10:58:59.516762 10701 sgd_solver.cpp:112] Iteration 98, lr = 0.01
I0526 10:59:48.772584 10701 solver.cpp:239] Iteration 147 (0.994823 iter/s, 49.255s/49 iters), loss = 0.144862
I0526 10:59:48.772698 10701 solver.cpp:258]     Train net output #0: loss = 0.1542 (* 1 = 0.1542 loss)
I0526 10:59:48.772707 10701 sgd_solver.cpp:112] Iteration 147, lr = 0.01
I0526 11:00:46.584918 10701 solver.cpp:239] Iteration 196 (0.847575 iter/s, 57.812s/49 iters), loss = 0.130157
I0526 11:00:46.585078 10701 solver.cpp:258]     Train net output #0: loss = 0.100315 (* 1 = 0.100315 loss)
I0526 11:00:46.585099 10701 sgd_solver.cpp:112] Iteration 196, lr = 0.01
I0526 11:01:44.968852 10701 solver.cpp:239] Iteration 245 (0.839285 iter/s, 58.383s/49 iters), loss = 0.11367
I0526 11:01:44.968982 10701 solver.cpp:258]     Train net output #0: loss = 0.0744689 (* 1 = 0.0744689 loss)
I0526 11:01:44.968999 10701 sgd_solver.cpp:112] Iteration 245, lr = 0.01
I0526 11:02:42.864243 10701 solver.cpp:239] Iteration 294 (0.84636 iter/s, 57.895s/49 iters), loss = 0.0849526
I0526 11:02:42.864385 10701 solver.cpp:258]     Train net output #0: loss = 0.0311043 (* 1 = 0.0311043 loss)
I0526 11:02:42.864396 10701 sgd_solver.cpp:112] Iteration 294, lr = 0.01
I0526 11:03:46.587296 10701 solver.cpp:239] Iteration 343 (0.768965 iter/s, 63.722s/49 iters), loss = 0.0843955
I0526 11:03:46.587430 10701 solver.cpp:258]     Train net output #0: loss = 0.0173109 (* 1 = 0.0173109 loss)
I0526 11:03:46.587446 10701 sgd_solver.cpp:112] Iteration 343, lr = 0.01
I0526 11:04:52.715449 10701 solver.cpp:239] Iteration 392 (0.740987 iter/s, 66.128s/49 iters), loss = 0.0966263
I0526 11:04:52.715739 10701 solver.cpp:258]     Train net output #0: loss = 0.0176004 (* 1 = 0.0176004 loss)
I0526 11:04:52.715772 10701 sgd_solver.cpp:112] Iteration 392, lr = 0.01
I0526 11:06:01.095286 10701 solver.cpp:239] Iteration 441 (0.716594 iter/s, 68.379s/49 iters), loss = 0.0753277
I0526 11:06:01.095537 10701 solver.cpp:258]     Train net output #0: loss = 0.0398318 (* 1 = 0.0398318 loss)
I0526 11:06:01.095551 10701 sgd_solver.cpp:112] Iteration 441, lr = 0.01
I0526 11:07:02.517408 10701 solver.cpp:239] Iteration 490 (0.797773 iter/s, 61.421s/49 iters), loss = 0.0598195
I0526 11:07:02.517575 10701 solver.cpp:258]     Train net output #0: loss = 0.0728459 (* 1 = 0.0728459 loss)
I0526 11:07:02.517593 10701 sgd_solver.cpp:112] Iteration 490, lr = 0.01
I0526 11:08:04.524109 10701 solver.cpp:239] Iteration 539 (0.790246 iter/s, 62.006s/49 iters), loss = 0.0682693
I0526 11:08:04.524288 10701 solver.cpp:258]     Train net output #0: loss = 0.197928 (* 1 = 0.197928 loss)
I0526 11:08:04.524312 10701 sgd_solver.cpp:112] Iteration 539, lr = 0.01
I0526 11:09:08.532133 10701 solver.cpp:239] Iteration 588 (0.765541 iter/s, 64.007s/49 iters), loss = 0.0821493
I0526 11:09:08.532280 10701 solver.cpp:258]     Train net output #0: loss = 0.0158334 (* 1 = 0.0158334 loss)
I0526 11:09:08.532299 10701 sgd_solver.cpp:112] Iteration 588, lr = 0.01
I0526 11:10:07.558394 10701 solver.cpp:239] Iteration 637 (0.830143 iter/s, 59.026s/49 iters), loss = 0.0570861
I0526 11:10:07.558704 10701 solver.cpp:258]     Train net output #0: loss = 0.055584 (* 1 = 0.055584 loss)
I0526 11:10:07.558746 10701 sgd_solver.cpp:112] Iteration 637, lr = 0.01
I0526 11:11:06.894138 10701 solver.cpp:239] Iteration 686 (0.825819 iter/s, 59.335s/49 iters), loss = 0.0454676
I0526 11:11:06.894275 10701 solver.cpp:258]     Train net output #0: loss = 0.0454679 (* 1 = 0.0454679 loss)
I0526 11:11:06.894286 10701 sgd_solver.cpp:112] Iteration 686, lr = 0.01
I0526 11:12:02.164239 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_735.caffemodel
I0526 11:12:02.165549 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_735.solverstate
I0526 11:12:02.166175 10701 solver.cpp:347] Iteration 735, Testing net (#0)
I0526 11:12:24.904819 10701 solver.cpp:414]     Test net output #0: accuracy = 0.6168
I0526 11:12:24.904861 10701 solver.cpp:414]     Test net output #1: loss = 1.63414 (* 1 = 1.63414 loss)
I0526 11:12:24.904871 10701 solver.cpp:347] Iteration 735, Testing net (#1)
I0526 11:13:08.577013 10701 solver.cpp:414]     Test net output #0: accuracy = 0.988511
I0526 11:13:08.577165 10701 solver.cpp:414]     Test net output #1: loss = 0.034485 (* 1 = 0.034485 loss)
I0526 11:13:08.577184 10701 solver.cpp:347] Iteration 735, Testing net (#2)
I0526 11:14:48.570658 10701 solver.cpp:414]     Test net output #0: accuracy = 0.71009
I0526 11:14:48.570785 10701 solver.cpp:414]     Test net output #1: loss = 1.18141 (* 1 = 1.18141 loss)
I0526 11:14:49.646543 10701 solver.cpp:239] Iteration 735 (0.219976 iter/s, 222.752s/49 iters), loss = 0.0415022
I0526 11:14:49.646600 10701 solver.cpp:258]     Train net output #0: loss = 0.0218338 (* 1 = 0.0218338 loss)
I0526 11:14:49.646613 10701 sgd_solver.cpp:112] Iteration 735, lr = 0.01
I0526 11:15:52.327296 10701 solver.cpp:239] Iteration 784 (0.781749 iter/s, 62.68s/49 iters), loss = 0.0422039
I0526 11:15:52.327441 10701 solver.cpp:258]     Train net output #0: loss = 0.0150546 (* 1 = 0.0150546 loss)
I0526 11:15:52.327452 10701 sgd_solver.cpp:112] Iteration 784, lr = 0.01
I0526 11:16:47.366641 10701 solver.cpp:239] Iteration 833 (0.890278 iter/s, 55.039s/49 iters), loss = 0.0351902
I0526 11:16:47.366799 10701 solver.cpp:258]     Train net output #0: loss = 0.0441518 (* 1 = 0.0441518 loss)
I0526 11:16:47.366820 10701 sgd_solver.cpp:112] Iteration 833, lr = 0.01
I0526 11:17:47.633280 10701 solver.cpp:239] Iteration 882 (0.813062 iter/s, 60.266s/49 iters), loss = 0.049313
I0526 11:17:47.633492 10701 solver.cpp:258]     Train net output #0: loss = 0.157123 (* 1 = 0.157123 loss)
I0526 11:17:47.633520 10701 sgd_solver.cpp:112] Iteration 882, lr = 0.01
I0526 11:18:48.991863 10701 solver.cpp:239] Iteration 931 (0.798592 iter/s, 61.358s/49 iters), loss = 0.0414738
I0526 11:18:48.992017 10701 solver.cpp:258]     Train net output #0: loss = 0.0344701 (* 1 = 0.0344701 loss)
I0526 11:18:48.992033 10701 sgd_solver.cpp:112] Iteration 931, lr = 0.01
I0526 11:19:56.755381 10701 solver.cpp:239] Iteration 980 (0.723108 iter/s, 67.763s/49 iters), loss = 0.0353901
I0526 11:19:56.755599 10701 solver.cpp:258]     Train net output #0: loss = 0.0575462 (* 1 = 0.0575462 loss)
I0526 11:19:56.755648 10701 sgd_solver.cpp:112] Iteration 980, lr = 0.01
I0526 11:21:07.830240 10701 solver.cpp:239] Iteration 1029 (0.689422 iter/s, 71.074s/49 iters), loss = 0.0522385
I0526 11:21:07.830785 10701 solver.cpp:258]     Train net output #0: loss = 0.0458306 (* 1 = 0.0458306 loss)
I0526 11:21:07.830850 10701 sgd_solver.cpp:112] Iteration 1029, lr = 0.01
I0526 11:22:19.640647 10701 solver.cpp:239] Iteration 1078 (0.682366 iter/s, 71.809s/49 iters), loss = 0.029063
I0526 11:22:19.641132 10701 solver.cpp:258]     Train net output #0: loss = 0.0185452 (* 1 = 0.0185452 loss)
I0526 11:22:19.641162 10701 sgd_solver.cpp:112] Iteration 1078, lr = 0.01
I0526 11:23:22.649381 10701 solver.cpp:239] Iteration 1127 (0.777679 iter/s, 63.008s/49 iters), loss = 0.0374536
I0526 11:23:22.649559 10701 solver.cpp:258]     Train net output #0: loss = 0.0083162 (* 1 = 0.0083162 loss)
I0526 11:23:22.649576 10701 sgd_solver.cpp:112] Iteration 1127, lr = 0.01
I0526 11:24:21.022722 10701 solver.cpp:239] Iteration 1176 (0.839429 iter/s, 58.373s/49 iters), loss = 0.0368731
I0526 11:24:21.022877 10701 solver.cpp:258]     Train net output #0: loss = 0.0230235 (* 1 = 0.0230235 loss)
I0526 11:24:21.022913 10701 sgd_solver.cpp:112] Iteration 1176, lr = 0.01
I0526 11:25:19.760838 10701 solver.cpp:239] Iteration 1225 (0.834227 iter/s, 58.737s/49 iters), loss = 0.0309188
I0526 11:25:19.761031 10701 solver.cpp:258]     Train net output #0: loss = 0.0880338 (* 1 = 0.0880338 loss)
I0526 11:25:19.761075 10701 sgd_solver.cpp:112] Iteration 1225, lr = 0.01
I0526 11:26:23.181246 10701 solver.cpp:239] Iteration 1274 (0.772627 iter/s, 63.42s/49 iters), loss = 0.043623
I0526 11:26:23.181413 10701 solver.cpp:258]     Train net output #0: loss = 0.00464755 (* 1 = 0.00464755 loss)
I0526 11:26:23.181427 10701 sgd_solver.cpp:112] Iteration 1274, lr = 0.01
I0526 11:27:30.874650 10701 solver.cpp:239] Iteration 1323 (0.723856 iter/s, 67.693s/49 iters), loss = 0.0288375
I0526 11:27:30.876242 10701 solver.cpp:258]     Train net output #0: loss = 0.0834066 (* 1 = 0.0834066 loss)
I0526 11:27:30.876312 10701 sgd_solver.cpp:112] Iteration 1323, lr = 0.01
I0526 11:28:40.972730 10701 solver.cpp:239] Iteration 1372 (0.699041 iter/s, 70.096s/49 iters), loss = 0.043481
I0526 11:28:40.973034 10701 solver.cpp:258]     Train net output #0: loss = 0.00563258 (* 1 = 0.00563258 loss)
I0526 11:28:40.973049 10701 sgd_solver.cpp:112] Iteration 1372, lr = 0.01
I0526 11:29:56.181218 10701 solver.cpp:239] Iteration 1421 (0.651526 iter/s, 75.208s/49 iters), loss = 0.0357524
I0526 11:29:56.181854 10701 solver.cpp:258]     Train net output #0: loss = 0.0527205 (* 1 = 0.0527205 loss)
I0526 11:29:56.181931 10701 sgd_solver.cpp:112] Iteration 1421, lr = 0.01
I0526 11:31:05.454463 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_1470.caffemodel
I0526 11:31:05.455781 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_1470.solverstate
I0526 11:31:05.456379 10701 solver.cpp:347] Iteration 1470, Testing net (#0)
I0526 11:31:30.783732 10701 solver.cpp:414]     Test net output #0: accuracy = 0.6896
I0526 11:31:30.783776 10701 solver.cpp:414]     Test net output #1: loss = 0.69672 (* 1 = 0.69672 loss)
I0526 11:31:30.783783 10701 solver.cpp:347] Iteration 1470, Testing net (#1)
I0526 11:32:20.774777 10701 solver.cpp:414]     Test net output #0: accuracy = 0.995319
I0526 11:32:20.774935 10701 solver.cpp:414]     Test net output #1: loss = 0.0187619 (* 1 = 0.0187619 loss)
I0526 11:32:20.774947 10701 solver.cpp:347] Iteration 1470, Testing net (#2)
I0526 11:34:12.389482 10701 solver.cpp:414]     Test net output #0: accuracy = 0.806847
I0526 11:34:12.389622 10701 solver.cpp:414]     Test net output #1: loss = 0.506263 (* 1 = 0.506263 loss)
I0526 11:34:13.685423 10701 solver.cpp:239] Iteration 1470 (0.190289 iter/s, 257.503s/49 iters), loss = 0.0267867
I0526 11:34:13.685479 10701 solver.cpp:258]     Train net output #0: loss = 0.0060792 (* 1 = 0.0060792 loss)
I0526 11:34:13.685490 10701 sgd_solver.cpp:112] Iteration 1470, lr = 0.01
I0526 11:35:22.470129 10701 solver.cpp:239] Iteration 1519 (0.712375 iter/s, 68.784s/49 iters), loss = 0.0409928
I0526 11:35:22.470304 10701 solver.cpp:258]     Train net output #0: loss = 0.051102 (* 1 = 0.051102 loss)
I0526 11:35:22.470319 10701 sgd_solver.cpp:112] Iteration 1519, lr = 0.01
I0526 11:36:46.830649 10701 solver.cpp:239] Iteration 1568 (0.580844 iter/s, 84.36s/49 iters), loss = 0.0511928
I0526 11:36:46.830839 10701 solver.cpp:258]     Train net output #0: loss = 0.0130686 (* 1 = 0.0130686 loss)
I0526 11:36:46.830857 10701 sgd_solver.cpp:112] Iteration 1568, lr = 0.01
I0526 11:37:55.093144 10701 solver.cpp:239] Iteration 1617 (0.717822 iter/s, 68.262s/49 iters), loss = 0.0257687
I0526 11:37:55.093297 10701 solver.cpp:258]     Train net output #0: loss = 0.0438027 (* 1 = 0.0438027 loss)
I0526 11:37:55.093348 10701 sgd_solver.cpp:112] Iteration 1617, lr = 0.01
I0526 11:39:10.918125 10701 solver.cpp:239] Iteration 1666 (0.646233 iter/s, 75.824s/49 iters), loss = 0.0340705
I0526 11:39:10.918285 10701 solver.cpp:258]     Train net output #0: loss = 0.0652199 (* 1 = 0.0652199 loss)
I0526 11:39:10.918299 10701 sgd_solver.cpp:112] Iteration 1666, lr = 0.01
I0526 11:40:18.548250 10701 solver.cpp:239] Iteration 1715 (0.724541 iter/s, 67.629s/49 iters), loss = 0.0221316
I0526 11:40:18.548516 10701 solver.cpp:258]     Train net output #0: loss = 0.0053273 (* 1 = 0.0053273 loss)
I0526 11:40:18.548583 10701 sgd_solver.cpp:112] Iteration 1715, lr = 0.01
I0526 11:41:40.504729 10701 solver.cpp:239] Iteration 1764 (0.597882 iter/s, 81.956s/49 iters), loss = 0.0266445
I0526 11:41:40.504917 10701 solver.cpp:258]     Train net output #0: loss = 0.0383305 (* 1 = 0.0383305 loss)
I0526 11:41:40.504940 10701 sgd_solver.cpp:112] Iteration 1764, lr = 0.01
I0526 11:42:49.097374 10701 solver.cpp:239] Iteration 1813 (0.714369 iter/s, 68.592s/49 iters), loss = 0.0218633
I0526 11:42:49.097522 10701 solver.cpp:258]     Train net output #0: loss = 0.019185 (* 1 = 0.019185 loss)
I0526 11:42:49.097530 10701 sgd_solver.cpp:112] Iteration 1813, lr = 0.01
I0526 11:44:05.000494 10701 solver.cpp:239] Iteration 1862 (0.645569 iter/s, 75.902s/49 iters), loss = 0.0252421
I0526 11:44:05.000681 10701 solver.cpp:258]     Train net output #0: loss = 0.00611435 (* 1 = 0.00611435 loss)
I0526 11:44:05.000701 10701 sgd_solver.cpp:112] Iteration 1862, lr = 0.01
I0526 11:45:10.941336 10701 solver.cpp:239] Iteration 1911 (0.7431 iter/s, 65.94s/49 iters), loss = 0.0286134
I0526 11:45:10.941480 10701 solver.cpp:258]     Train net output #0: loss = 0.00472409 (* 1 = 0.00472409 loss)
I0526 11:45:10.941491 10701 sgd_solver.cpp:112] Iteration 1911, lr = 0.01
I0526 11:46:09.035987 10701 solver.cpp:239] Iteration 1960 (0.843461 iter/s, 58.094s/49 iters), loss = 0.0298243
I0526 11:46:09.036167 10701 solver.cpp:258]     Train net output #0: loss = 0.00192499 (* 1 = 0.00192499 loss)
I0526 11:46:09.036221 10701 sgd_solver.cpp:112] Iteration 1960, lr = 0.01
I0526 11:47:08.861245 10701 solver.cpp:239] Iteration 2009 (0.819056 iter/s, 59.825s/49 iters), loss = 0.0171696
I0526 11:47:08.861393 10701 solver.cpp:258]     Train net output #0: loss = 0.00732991 (* 1 = 0.00732991 loss)
I0526 11:47:08.861411 10701 sgd_solver.cpp:112] Iteration 2009, lr = 0.01
I0526 11:48:06.676484 10701 solver.cpp:239] Iteration 2058 (0.847531 iter/s, 57.815s/49 iters), loss = 0.0343562
I0526 11:48:06.676654 10701 solver.cpp:258]     Train net output #0: loss = 0.102379 (* 1 = 0.102379 loss)
I0526 11:48:06.676666 10701 sgd_solver.cpp:112] Iteration 2058, lr = 0.01
I0526 11:49:04.412034 10701 solver.cpp:239] Iteration 2107 (0.848705 iter/s, 57.735s/49 iters), loss = 0.0212167
I0526 11:49:04.412215 10701 solver.cpp:258]     Train net output #0: loss = 0.0202618 (* 1 = 0.0202618 loss)
I0526 11:49:04.412235 10701 sgd_solver.cpp:112] Iteration 2107, lr = 0.01
I0526 11:50:02.958328 10701 solver.cpp:239] Iteration 2156 (0.836949 iter/s, 58.546s/49 iters), loss = 0.0175053
I0526 11:50:02.958492 10701 solver.cpp:258]     Train net output #0: loss = 0.003024 (* 1 = 0.003024 loss)
I0526 11:50:02.958518 10701 sgd_solver.cpp:112] Iteration 2156, lr = 0.01
I0526 11:51:03.417663 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_2205.caffemodel
I0526 11:51:03.418854 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_2205.solverstate
I0526 11:51:03.419324 10701 solver.cpp:347] Iteration 2205, Testing net (#0)
I0526 11:51:26.026495 10701 solver.cpp:414]     Test net output #0: accuracy = 0.5608
I0526 11:51:26.026549 10701 solver.cpp:414]     Test net output #1: loss = 0.790067 (* 1 = 0.790067 loss)
I0526 11:51:26.026562 10701 solver.cpp:347] Iteration 2205, Testing net (#1)
I0526 11:52:07.565028 10701 solver.cpp:414]     Test net output #0: accuracy = 0.992979
I0526 11:52:07.565176 10701 solver.cpp:414]     Test net output #1: loss = 0.0270953 (* 1 = 0.0270953 loss)
I0526 11:52:07.565193 10701 solver.cpp:347] Iteration 2205, Testing net (#2)
I0526 11:53:43.692065 10701 solver.cpp:414]     Test net output #0: accuracy = 0.804054
I0526 11:53:43.692217 10701 solver.cpp:414]     Test net output #1: loss = 0.41472 (* 1 = 0.41472 loss)
I0526 11:53:44.845181 10701 solver.cpp:239] Iteration 2205 (0.220834 iter/s, 221.886s/49 iters), loss = 0.0317369
I0526 11:53:44.845232 10701 solver.cpp:258]     Train net output #0: loss = 0.0108699 (* 1 = 0.0108699 loss)
I0526 11:53:44.845247 10701 sgd_solver.cpp:112] Iteration 2205, lr = 0.01
I0526 11:54:44.201125 10701 solver.cpp:239] Iteration 2254 (0.825541 iter/s, 59.355s/49 iters), loss = 0.0330153
I0526 11:54:44.201292 10701 solver.cpp:258]     Train net output #0: loss = 0.104977 (* 1 = 0.104977 loss)
I0526 11:54:44.201306 10701 sgd_solver.cpp:112] Iteration 2254, lr = 0.01
I0526 11:55:44.244881 10701 solver.cpp:239] Iteration 2303 (0.816082 iter/s, 60.043s/49 iters), loss = 0.058443
I0526 11:55:44.245034 10701 solver.cpp:258]     Train net output #0: loss = 0.0665045 (* 1 = 0.0665045 loss)
I0526 11:55:44.245045 10701 sgd_solver.cpp:112] Iteration 2303, lr = 0.01
I0526 11:56:43.448880 10701 solver.cpp:239] Iteration 2352 (0.827661 iter/s, 59.203s/49 iters), loss = 0.0396534
I0526 11:56:43.449059 10701 solver.cpp:258]     Train net output #0: loss = 0.0203445 (* 1 = 0.0203445 loss)
I0526 11:56:43.449090 10701 sgd_solver.cpp:112] Iteration 2352, lr = 0.01
I0526 11:57:49.050742 10701 solver.cpp:239] Iteration 2401 (0.74694 iter/s, 65.601s/49 iters), loss = 0.0327347
I0526 11:57:49.050945 10701 solver.cpp:258]     Train net output #0: loss = 0.0291853 (* 1 = 0.0291853 loss)
I0526 11:57:49.050987 10701 sgd_solver.cpp:112] Iteration 2401, lr = 0.01
I0526 11:58:57.811247 10701 solver.cpp:239] Iteration 2450 (0.712624 iter/s, 68.76s/49 iters), loss = 0.0198619
I0526 11:58:57.811764 10701 solver.cpp:258]     Train net output #0: loss = 0.00121065 (* 1 = 0.00121065 loss)
I0526 11:58:57.811870 10701 sgd_solver.cpp:112] Iteration 2450, lr = 0.01
I0526 12:00:10.485081 10701 solver.cpp:239] Iteration 2499 (0.674253 iter/s, 72.673s/49 iters), loss = 0.0237913
I0526 12:00:10.485193 10701 solver.cpp:258]     Train net output #0: loss = 0.0106108 (* 1 = 0.0106108 loss)
I0526 12:00:10.485203 10701 sgd_solver.cpp:112] Iteration 2499, lr = 0.01
I0526 12:01:15.209180 10701 solver.cpp:239] Iteration 2548 (0.757072 iter/s, 64.723s/49 iters), loss = 0.0227461
I0526 12:01:15.209316 10701 solver.cpp:258]     Train net output #0: loss = 0.00112968 (* 1 = 0.00112968 loss)
I0526 12:01:15.209332 10701 sgd_solver.cpp:112] Iteration 2548, lr = 0.01
I0526 12:02:29.700917 10701 solver.cpp:239] Iteration 2597 (0.657798 iter/s, 74.491s/49 iters), loss = 0.0199046
I0526 12:02:29.701150 10701 solver.cpp:258]     Train net output #0: loss = 0.0207011 (* 1 = 0.0207011 loss)
I0526 12:02:29.701174 10701 sgd_solver.cpp:112] Iteration 2597, lr = 0.01
I0526 12:03:41.922976 10701 solver.cpp:239] Iteration 2646 (0.678473 iter/s, 72.221s/49 iters), loss = 0.0295198
I0526 12:03:41.923171 10701 solver.cpp:258]     Train net output #0: loss = 0.066051 (* 1 = 0.066051 loss)
I0526 12:03:41.923195 10701 sgd_solver.cpp:112] Iteration 2646, lr = 0.01
I0526 12:04:58.623178 10701 solver.cpp:239] Iteration 2695 (0.638853 iter/s, 76.7s/49 iters), loss = 0.0182976
I0526 12:04:58.623335 10701 solver.cpp:258]     Train net output #0: loss = 0.0139797 (* 1 = 0.0139797 loss)
I0526 12:04:58.623356 10701 sgd_solver.cpp:112] Iteration 2695, lr = 0.01
I0526 12:06:07.404137 10701 solver.cpp:239] Iteration 2744 (0.712416 iter/s, 68.78s/49 iters), loss = 0.0370087
I0526 12:06:07.404444 10701 solver.cpp:258]     Train net output #0: loss = 0.0443193 (* 1 = 0.0443193 loss)
I0526 12:06:07.404485 10701 sgd_solver.cpp:112] Iteration 2744, lr = 0.01
I0526 12:07:23.115200 10701 solver.cpp:239] Iteration 2793 (0.647206 iter/s, 75.71s/49 iters), loss = 0.0245849
I0526 12:07:23.115447 10701 solver.cpp:258]     Train net output #0: loss = 0.00425697 (* 1 = 0.00425697 loss)
I0526 12:07:23.115461 10701 sgd_solver.cpp:112] Iteration 2793, lr = 0.01
I0526 12:08:31.986042 10701 solver.cpp:239] Iteration 2842 (0.711485 iter/s, 68.87s/49 iters), loss = 0.0231233
I0526 12:08:31.986482 10701 solver.cpp:258]     Train net output #0: loss = 0.0058631 (* 1 = 0.0058631 loss)
I0526 12:08:31.986507 10701 sgd_solver.cpp:112] Iteration 2842, lr = 0.01
I0526 12:09:44.200233 10701 solver.cpp:239] Iteration 2891 (0.678548 iter/s, 72.213s/49 iters), loss = 0.0185996
I0526 12:09:44.200408 10701 solver.cpp:258]     Train net output #0: loss = 0.0197279 (* 1 = 0.0197279 loss)
I0526 12:09:44.200428 10701 sgd_solver.cpp:112] Iteration 2891, lr = 0.01
I0526 12:10:56.975109 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_2940.caffemodel
I0526 12:10:56.976972 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_2940.solverstate
I0526 12:10:56.977725 10701 solver.cpp:347] Iteration 2940, Testing net (#0)
I0526 12:11:25.531008 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8036
I0526 12:11:25.531145 10701 solver.cpp:414]     Test net output #1: loss = 0.512639 (* 1 = 0.512639 loss)
I0526 12:11:25.531195 10701 solver.cpp:347] Iteration 2940, Testing net (#1)
I0526 12:12:18.319454 10701 solver.cpp:414]     Test net output #0: accuracy = 0.99617
I0526 12:12:18.320397 10701 solver.cpp:414]     Test net output #1: loss = 0.0110108 (* 1 = 0.0110108 loss)
I0526 12:12:18.320430 10701 solver.cpp:347] Iteration 2940, Testing net (#2)
I0526 12:14:17.995402 10701 solver.cpp:414]     Test net output #0: accuracy = 0.831441
I0526 12:14:17.996214 10701 solver.cpp:414]     Test net output #1: loss = 0.382313 (* 1 = 0.382313 loss)
I0526 12:14:19.311084 10701 solver.cpp:239] Iteration 2940 (0.178111 iter/s, 275.11s/49 iters), loss = 0.0184973
I0526 12:14:19.311228 10701 solver.cpp:258]     Train net output #0: loss = 0.00202428 (* 1 = 0.00202428 loss)
I0526 12:14:19.311254 10701 sgd_solver.cpp:112] Iteration 2940, lr = 0.01
I0526 12:15:37.884878 10701 solver.cpp:239] Iteration 2989 (0.623624 iter/s, 78.573s/49 iters), loss = 0.0182231
I0526 12:15:37.885066 10701 solver.cpp:258]     Train net output #0: loss = 0.0744132 (* 1 = 0.0744132 loss)
I0526 12:15:37.885093 10701 sgd_solver.cpp:112] Iteration 2989, lr = 0.01
I0526 12:16:36.862335 10701 solver.cpp:239] Iteration 3038 (0.830832 iter/s, 58.977s/49 iters), loss = 0.0196607
I0526 12:16:36.862530 10701 solver.cpp:258]     Train net output #0: loss = 0.0110155 (* 1 = 0.0110155 loss)
I0526 12:16:36.862552 10701 sgd_solver.cpp:112] Iteration 3038, lr = 0.01
I0526 12:17:35.614482 10701 solver.cpp:239] Iteration 3087 (0.834028 iter/s, 58.751s/49 iters), loss = 0.0249344
I0526 12:17:35.614646 10701 solver.cpp:258]     Train net output #0: loss = 0.00526528 (* 1 = 0.00526528 loss)
I0526 12:17:35.614668 10701 sgd_solver.cpp:112] Iteration 3087, lr = 0.01
I0526 12:18:33.959136 10701 solver.cpp:239] Iteration 3136 (0.839846 iter/s, 58.344s/49 iters), loss = 0.0195572
I0526 12:18:33.959316 10701 solver.cpp:258]     Train net output #0: loss = 0.00295856 (* 1 = 0.00295856 loss)
I0526 12:18:33.959328 10701 sgd_solver.cpp:112] Iteration 3136, lr = 0.01
I0526 12:19:32.966508 10701 solver.cpp:239] Iteration 3185 (0.83041 iter/s, 59.007s/49 iters), loss = 0.022272
I0526 12:19:32.966647 10701 solver.cpp:258]     Train net output #0: loss = 0.0117901 (* 1 = 0.0117901 loss)
I0526 12:19:32.966666 10701 sgd_solver.cpp:112] Iteration 3185, lr = 0.01
I0526 12:20:31.097925 10701 solver.cpp:239] Iteration 3234 (0.842924 iter/s, 58.131s/49 iters), loss = 0.0173658
I0526 12:20:31.098098 10701 solver.cpp:258]     Train net output #0: loss = 0.00104891 (* 1 = 0.00104891 loss)
I0526 12:20:31.098114 10701 sgd_solver.cpp:112] Iteration 3234, lr = 0.01
I0526 12:21:35.084168 10701 solver.cpp:239] Iteration 3283 (0.765792 iter/s, 63.986s/49 iters), loss = 0.0267001
I0526 12:21:35.084412 10701 solver.cpp:258]     Train net output #0: loss = 0.00704315 (* 1 = 0.00704315 loss)
I0526 12:21:35.084426 10701 sgd_solver.cpp:112] Iteration 3283, lr = 0.01
I0526 12:22:34.869170 10701 solver.cpp:239] Iteration 3332 (0.819617 iter/s, 59.784s/49 iters), loss = 0.0106634
I0526 12:22:34.869357 10701 solver.cpp:258]     Train net output #0: loss = 0.00928201 (* 1 = 0.00928201 loss)
I0526 12:22:34.869381 10701 sgd_solver.cpp:112] Iteration 3332, lr = 0.01
I0526 12:23:33.741578 10701 solver.cpp:239] Iteration 3381 (0.832314 iter/s, 58.872s/49 iters), loss = 0.0282877
I0526 12:23:33.741780 10701 solver.cpp:258]     Train net output #0: loss = 0.00774838 (* 1 = 0.00774838 loss)
I0526 12:23:33.741817 10701 sgd_solver.cpp:112] Iteration 3381, lr = 0.01
I0526 12:24:34.601486 10701 solver.cpp:239] Iteration 3430 (0.80514 iter/s, 60.859s/49 iters), loss = 0.0117757
I0526 12:24:34.601670 10701 solver.cpp:258]     Train net output #0: loss = 0.00698562 (* 1 = 0.00698562 loss)
I0526 12:24:34.601696 10701 sgd_solver.cpp:112] Iteration 3430, lr = 0.01
I0526 12:25:32.826226 10701 solver.cpp:239] Iteration 3479 (0.841577 iter/s, 58.224s/49 iters), loss = 0.0191244
I0526 12:25:32.826452 10701 solver.cpp:258]     Train net output #0: loss = 0.00811405 (* 1 = 0.00811405 loss)
I0526 12:25:32.826472 10701 sgd_solver.cpp:112] Iteration 3479, lr = 0.01
I0526 12:26:31.819026 10701 solver.cpp:239] Iteration 3528 (0.830621 iter/s, 58.992s/49 iters), loss = 0.0173795
I0526 12:26:31.819175 10701 solver.cpp:258]     Train net output #0: loss = 0.00534648 (* 1 = 0.00534648 loss)
I0526 12:26:31.819186 10701 sgd_solver.cpp:112] Iteration 3528, lr = 0.01
I0526 12:27:31.997900 10701 solver.cpp:239] Iteration 3577 (0.814251 iter/s, 60.178s/49 iters), loss = 0.0100659
I0526 12:27:31.998083 10701 solver.cpp:258]     Train net output #0: loss = 0.00794393 (* 1 = 0.00794393 loss)
I0526 12:27:31.998136 10701 sgd_solver.cpp:112] Iteration 3577, lr = 0.01
I0526 12:28:32.598938 10701 solver.cpp:239] Iteration 3626 (0.808581 iter/s, 60.6s/49 iters), loss = 0.0211962
I0526 12:28:32.599092 10701 solver.cpp:258]     Train net output #0: loss = 0.00137676 (* 1 = 0.00137676 loss)
I0526 12:28:32.599110 10701 sgd_solver.cpp:112] Iteration 3626, lr = 0.01
I0526 12:29:33.773056 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_3675.caffemodel
I0526 12:29:33.774205 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_3675.solverstate
I0526 12:29:33.774737 10701 solver.cpp:347] Iteration 3675, Testing net (#0)
I0526 12:30:13.234535 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8708
I0526 12:30:13.234915 10701 solver.cpp:414]     Test net output #1: loss = 0.384752 (* 1 = 0.384752 loss)
I0526 12:30:13.234946 10701 solver.cpp:347] Iteration 3675, Testing net (#1)
I0526 12:31:07.766911 10701 solver.cpp:414]     Test net output #0: accuracy = 0.995106
I0526 12:31:07.767200 10701 solver.cpp:414]     Test net output #1: loss = 0.0168645 (* 1 = 0.0168645 loss)
I0526 12:31:07.767216 10701 solver.cpp:347] Iteration 3675, Testing net (#2)
I0526 12:32:56.923106 10701 solver.cpp:414]     Test net output #0: accuracy = 0.886847
I0526 12:32:56.923344 10701 solver.cpp:414]     Test net output #1: loss = 0.284139 (* 1 = 0.284139 loss)
I0526 12:32:58.888443 10701 solver.cpp:239] Iteration 3675 (0.184011 iter/s, 266.289s/49 iters), loss = 0.0155728
I0526 12:32:58.888543 10701 solver.cpp:258]     Train net output #0: loss = 0.00308568 (* 1 = 0.00308568 loss)
I0526 12:32:58.888571 10701 sgd_solver.cpp:112] Iteration 3675, lr = 0.01
I0526 12:34:02.846516 10701 solver.cpp:239] Iteration 3724 (0.76614 iter/s, 63.957s/49 iters), loss = 0.021603
I0526 12:34:02.846701 10701 solver.cpp:258]     Train net output #0: loss = 0.00313467 (* 1 = 0.00313467 loss)
I0526 12:34:02.846721 10701 sgd_solver.cpp:112] Iteration 3724, lr = 0.01
I0526 12:35:02.024282 10701 solver.cpp:239] Iteration 3773 (0.828024 iter/s, 59.177s/49 iters), loss = 0.0173662
I0526 12:35:02.024466 10701 solver.cpp:258]     Train net output #0: loss = 0.0565917 (* 1 = 0.0565917 loss)
I0526 12:35:02.024482 10701 sgd_solver.cpp:112] Iteration 3773, lr = 0.01
I0526 12:35:59.970376 10701 solver.cpp:239] Iteration 3822 (0.845629 iter/s, 57.945s/49 iters), loss = 0.0179773
I0526 12:35:59.970546 10701 solver.cpp:258]     Train net output #0: loss = 0.00085806 (* 1 = 0.00085806 loss)
I0526 12:35:59.970563 10701 sgd_solver.cpp:112] Iteration 3822, lr = 0.01
I0526 12:37:00.371949 10701 solver.cpp:239] Iteration 3871 (0.811245 iter/s, 60.401s/49 iters), loss = 0.0166253
I0526 12:37:00.372123 10701 solver.cpp:258]     Train net output #0: loss = 0.0637269 (* 1 = 0.0637269 loss)
I0526 12:37:00.372167 10701 sgd_solver.cpp:112] Iteration 3871, lr = 0.01
I0526 12:38:00.952085 10701 solver.cpp:239] Iteration 3920 (0.808861 iter/s, 60.579s/49 iters), loss = 0.0273005
I0526 12:38:00.952232 10701 solver.cpp:258]     Train net output #0: loss = 0.0523841 (* 1 = 0.0523841 loss)
I0526 12:38:00.952253 10701 sgd_solver.cpp:112] Iteration 3920, lr = 0.01
I0526 12:39:01.611169 10701 solver.cpp:239] Iteration 3969 (0.807808 iter/s, 60.658s/49 iters), loss = 0.0216537
I0526 12:39:01.611371 10701 solver.cpp:258]     Train net output #0: loss = 0.00276811 (* 1 = 0.00276811 loss)
I0526 12:39:01.611389 10701 sgd_solver.cpp:112] Iteration 3969, lr = 0.01
I0526 12:40:01.953469 10701 solver.cpp:239] Iteration 4018 (0.812038 iter/s, 60.342s/49 iters), loss = 0.0197164
I0526 12:40:01.953632 10701 solver.cpp:258]     Train net output #0: loss = 0.00385672 (* 1 = 0.00385672 loss)
I0526 12:40:01.953655 10701 sgd_solver.cpp:112] Iteration 4018, lr = 0.01
I0526 12:41:00.926805 10701 solver.cpp:239] Iteration 4067 (0.830889 iter/s, 58.973s/49 iters), loss = 0.0248334
I0526 12:41:00.926980 10701 solver.cpp:258]     Train net output #0: loss = 0.00458389 (* 1 = 0.00458389 loss)
I0526 12:41:00.927000 10701 sgd_solver.cpp:112] Iteration 4067, lr = 0.01
I0526 12:42:00.552702 10701 solver.cpp:239] Iteration 4116 (0.821803 iter/s, 59.625s/49 iters), loss = 0.0196815
I0526 12:42:00.552888 10701 solver.cpp:258]     Train net output #0: loss = 0.0020964 (* 1 = 0.0020964 loss)
I0526 12:42:00.552911 10701 sgd_solver.cpp:112] Iteration 4116, lr = 0.01
I0526 12:42:59.557596 10701 solver.cpp:239] Iteration 4165 (0.830452 iter/s, 59.004s/49 iters), loss = 0.00926208
I0526 12:42:59.560596 10701 solver.cpp:258]     Train net output #0: loss = 0.000540522 (* 1 = 0.000540522 loss)
I0526 12:42:59.560652 10701 sgd_solver.cpp:112] Iteration 4165, lr = 0.01
I0526 12:43:57.848515 10701 solver.cpp:239] Iteration 4214 (0.840668 iter/s, 58.287s/49 iters), loss = 0.0186194
I0526 12:43:57.848671 10701 solver.cpp:258]     Train net output #0: loss = 0.0572059 (* 1 = 0.0572059 loss)
I0526 12:43:57.848695 10701 sgd_solver.cpp:112] Iteration 4214, lr = 0.01
I0526 12:44:56.650552 10701 solver.cpp:239] Iteration 4263 (0.833319 iter/s, 58.801s/49 iters), loss = 0.0161192
I0526 12:44:56.651108 10701 solver.cpp:258]     Train net output #0: loss = 0.0152252 (* 1 = 0.0152252 loss)
I0526 12:44:56.651126 10701 sgd_solver.cpp:112] Iteration 4263, lr = 0.01
I0526 12:45:56.318512 10701 solver.cpp:239] Iteration 4312 (0.821224 iter/s, 59.667s/49 iters), loss = 0.0165616
I0526 12:45:56.318704 10701 solver.cpp:258]     Train net output #0: loss = 0.00266261 (* 1 = 0.00266261 loss)
I0526 12:45:56.318725 10701 sgd_solver.cpp:112] Iteration 4312, lr = 0.01
I0526 12:46:54.083441 10701 solver.cpp:239] Iteration 4361 (0.848279 iter/s, 57.764s/49 iters), loss = 0.0159497
I0526 12:46:54.083590 10701 solver.cpp:258]     Train net output #0: loss = 0.00286501 (* 1 = 0.00286501 loss)
I0526 12:46:54.083636 10701 sgd_solver.cpp:112] Iteration 4361, lr = 0.01
I0526 12:47:50.594158 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_4410.caffemodel
I0526 12:47:50.595607 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_4410.solverstate
I0526 12:47:50.596238 10701 solver.cpp:347] Iteration 4410, Testing net (#0)
I0526 12:48:12.886831 10701 solver.cpp:414]     Test net output #0: accuracy = 0.9092
I0526 12:48:12.886943 10701 solver.cpp:414]     Test net output #1: loss = 0.273887 (* 1 = 0.273887 loss)
I0526 12:48:12.886962 10701 solver.cpp:347] Iteration 4410, Testing net (#1)
I0526 12:48:54.203235 10701 solver.cpp:414]     Test net output #0: accuracy = 0.996383
I0526 12:48:54.203402 10701 solver.cpp:414]     Test net output #1: loss = 0.011721 (* 1 = 0.011721 loss)
I0526 12:48:54.203421 10701 solver.cpp:347] Iteration 4410, Testing net (#2)
I0526 12:50:26.755301 10701 solver.cpp:414]     Test net output #0: accuracy = 0.92
I0526 12:50:26.755491 10701 solver.cpp:414]     Test net output #1: loss = 0.250468 (* 1 = 0.250468 loss)
I0526 12:50:28.082964 10701 solver.cpp:239] Iteration 4410 (0.228973 iter/s, 213.999s/49 iters), loss = 0.0119408
I0526 12:50:28.083015 10701 solver.cpp:258]     Train net output #0: loss = 0.00261552 (* 1 = 0.00261552 loss)
I0526 12:50:28.083025 10701 sgd_solver.cpp:112] Iteration 4410, lr = 0.01
I0526 12:51:28.623117 10701 solver.cpp:239] Iteration 4459 (0.809382 iter/s, 60.54s/49 iters), loss = 0.0213496
I0526 12:51:28.623275 10701 solver.cpp:258]     Train net output #0: loss = 0.104125 (* 1 = 0.104125 loss)
I0526 12:51:28.623296 10701 sgd_solver.cpp:112] Iteration 4459, lr = 0.01
I0526 12:52:29.748893 10701 solver.cpp:239] Iteration 4508 (0.801636 iter/s, 61.125s/49 iters), loss = 0.020322
I0526 12:52:29.749017 10701 solver.cpp:258]     Train net output #0: loss = 0.0193035 (* 1 = 0.0193035 loss)
I0526 12:52:29.749027 10701 sgd_solver.cpp:112] Iteration 4508, lr = 0.01
I0526 12:53:29.686832 10701 solver.cpp:239] Iteration 4557 (0.817525 iter/s, 59.937s/49 iters), loss = 0.0207875
I0526 12:53:29.686995 10701 solver.cpp:258]     Train net output #0: loss = 0.00505784 (* 1 = 0.00505784 loss)
I0526 12:53:29.687014 10701 sgd_solver.cpp:112] Iteration 4557, lr = 0.01
I0526 12:54:28.152634 10701 solver.cpp:239] Iteration 4606 (0.838108 iter/s, 58.465s/49 iters), loss = 0.00944697
I0526 12:54:28.152798 10701 solver.cpp:258]     Train net output #0: loss = 0.00256413 (* 1 = 0.00256413 loss)
I0526 12:54:28.152818 10701 sgd_solver.cpp:112] Iteration 4606, lr = 0.01
I0526 12:55:25.590241 10701 solver.cpp:239] Iteration 4655 (0.853109 iter/s, 57.437s/49 iters), loss = 0.0141855
I0526 12:55:25.590428 10701 solver.cpp:258]     Train net output #0: loss = 0.00174821 (* 1 = 0.00174821 loss)
I0526 12:55:25.590454 10701 sgd_solver.cpp:112] Iteration 4655, lr = 0.01
I0526 12:56:26.156297 10701 solver.cpp:239] Iteration 4704 (0.809048 iter/s, 60.565s/49 iters), loss = 0.0107397
I0526 12:56:26.156500 10701 solver.cpp:258]     Train net output #0: loss = 0.00560179 (* 1 = 0.00560179 loss)
I0526 12:56:26.156543 10701 sgd_solver.cpp:112] Iteration 4704, lr = 0.01
I0526 12:57:24.307991 10701 solver.cpp:239] Iteration 4753 (0.842634 iter/s, 58.151s/49 iters), loss = 0.0147687
I0526 12:57:24.308187 10701 solver.cpp:258]     Train net output #0: loss = 0.00447066 (* 1 = 0.00447066 loss)
I0526 12:57:24.308209 10701 sgd_solver.cpp:112] Iteration 4753, lr = 0.01
I0526 12:58:29.082270 10701 solver.cpp:239] Iteration 4802 (0.756476 iter/s, 64.774s/49 iters), loss = 0.0136023
I0526 12:58:29.082460 10701 solver.cpp:258]     Train net output #0: loss = 0.00181408 (* 1 = 0.00181408 loss)
I0526 12:58:29.082515 10701 sgd_solver.cpp:112] Iteration 4802, lr = 0.01
I0526 12:59:35.482168 10701 solver.cpp:239] Iteration 4851 (0.737963 iter/s, 66.399s/49 iters), loss = 0.0167549
I0526 12:59:35.482287 10701 solver.cpp:258]     Train net output #0: loss = 0.00737218 (* 1 = 0.00737218 loss)
I0526 12:59:35.482301 10701 sgd_solver.cpp:112] Iteration 4851, lr = 0.01
I0526 13:00:41.129007 10701 solver.cpp:239] Iteration 4900 (0.746428 iter/s, 65.646s/49 iters), loss = 0.0119806
I0526 13:00:41.129362 10701 solver.cpp:258]     Train net output #0: loss = 0.00148589 (* 1 = 0.00148589 loss)
I0526 13:00:41.129390 10701 sgd_solver.cpp:112] Iteration 4900, lr = 0.01
I0526 13:01:46.134796 10701 solver.cpp:239] Iteration 4949 (0.753788 iter/s, 65.005s/49 iters), loss = 0.0110386
I0526 13:01:46.135126 10701 solver.cpp:258]     Train net output #0: loss = 0.00297375 (* 1 = 0.00297375 loss)
I0526 13:01:46.135146 10701 sgd_solver.cpp:112] Iteration 4949, lr = 0.01
I0526 13:02:51.390429 10701 solver.cpp:239] Iteration 4998 (0.7509 iter/s, 65.255s/49 iters), loss = 0.014567
I0526 13:02:51.390589 10701 solver.cpp:258]     Train net output #0: loss = 0.00137178 (* 1 = 0.00137178 loss)
I0526 13:02:51.390625 10701 sgd_solver.cpp:112] Iteration 4998, lr = 0.01
I0526 13:03:56.845391 10701 solver.cpp:239] Iteration 5047 (0.748617 iter/s, 65.454s/49 iters), loss = 0.022749
I0526 13:03:56.845587 10701 solver.cpp:258]     Train net output #0: loss = 0.0455575 (* 1 = 0.0455575 loss)
I0526 13:03:56.845631 10701 sgd_solver.cpp:112] Iteration 5047, lr = 0.01
I0526 13:05:03.264251 10701 solver.cpp:239] Iteration 5096 (0.737752 iter/s, 66.418s/49 iters), loss = 0.0143083
I0526 13:05:03.264443 10701 solver.cpp:258]     Train net output #0: loss = 0.000546271 (* 1 = 0.000546271 loss)
I0526 13:05:03.264465 10701 sgd_solver.cpp:112] Iteration 5096, lr = 0.01
I0526 13:06:10.972486 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_5145.caffemodel
I0526 13:06:10.973794 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_5145.solverstate
I0526 13:06:10.974362 10701 solver.cpp:347] Iteration 5145, Testing net (#0)
I0526 13:06:34.983889 10701 solver.cpp:414]     Test net output #0: accuracy = 0.7764
I0526 13:06:34.983952 10701 solver.cpp:414]     Test net output #1: loss = 0.609538 (* 1 = 0.609538 loss)
I0526 13:06:34.983965 10701 solver.cpp:347] Iteration 5145, Testing net (#1)
I0526 13:07:26.080505 10701 solver.cpp:414]     Test net output #0: accuracy = 0.99766
I0526 13:07:26.080996 10701 solver.cpp:414]     Test net output #1: loss = 0.0113413 (* 1 = 0.0113413 loss)
I0526 13:07:26.081060 10701 solver.cpp:347] Iteration 5145, Testing net (#2)
I0526 13:09:14.779146 10701 solver.cpp:414]     Test net output #0: accuracy = 0.849369
I0526 13:09:14.779352 10701 solver.cpp:414]     Test net output #1: loss = 0.381037 (* 1 = 0.381037 loss)
I0526 13:09:16.210083 10701 solver.cpp:239] Iteration 5145 (0.193718 iter/s, 252.945s/49 iters), loss = 0.0135237
I0526 13:09:16.210196 10701 solver.cpp:258]     Train net output #0: loss = 0.00376339 (* 1 = 0.00376339 loss)
I0526 13:09:16.210239 10701 sgd_solver.cpp:112] Iteration 5145, lr = 0.01
I0526 13:10:23.487421 10701 solver.cpp:239] Iteration 5194 (0.728332 iter/s, 67.277s/49 iters), loss = 0.00890549
I0526 13:10:23.487777 10701 solver.cpp:258]     Train net output #0: loss = 0.024946 (* 1 = 0.024946 loss)
I0526 13:10:23.487797 10701 sgd_solver.cpp:112] Iteration 5194, lr = 0.01
I0526 13:11:40.322779 10701 solver.cpp:239] Iteration 5243 (0.63773 iter/s, 76.835s/49 iters), loss = 0.0226411
I0526 13:11:40.323004 10701 solver.cpp:258]     Train net output #0: loss = 0.00615759 (* 1 = 0.00615759 loss)
I0526 13:11:40.323022 10701 sgd_solver.cpp:112] Iteration 5243, lr = 0.01
I0526 13:12:54.044919 10701 solver.cpp:239] Iteration 5292 (0.664668 iter/s, 73.721s/49 iters), loss = 0.0188862
I0526 13:12:54.045151 10701 solver.cpp:258]     Train net output #0: loss = 0.0245711 (* 1 = 0.0245711 loss)
I0526 13:12:54.045207 10701 sgd_solver.cpp:112] Iteration 5292, lr = 0.01
I0526 13:14:06.600831 10701 solver.cpp:239] Iteration 5341 (0.67535 iter/s, 72.555s/49 iters), loss = 0.0357847
I0526 13:14:06.601002 10701 solver.cpp:258]     Train net output #0: loss = 0.0214093 (* 1 = 0.0214093 loss)
I0526 13:14:06.601018 10701 sgd_solver.cpp:112] Iteration 5341, lr = 0.01
I0526 13:15:15.702311 10701 solver.cpp:239] Iteration 5390 (0.709107 iter/s, 69.101s/49 iters), loss = 0.0171012
I0526 13:15:15.702474 10701 solver.cpp:258]     Train net output #0: loss = 0.00761871 (* 1 = 0.00761871 loss)
I0526 13:15:15.702497 10701 sgd_solver.cpp:112] Iteration 5390, lr = 0.01
I0526 13:16:24.322005 10701 solver.cpp:239] Iteration 5439 (0.714088 iter/s, 68.619s/49 iters), loss = 0.0184643
I0526 13:16:24.322158 10701 solver.cpp:258]     Train net output #0: loss = 0.00182234 (* 1 = 0.00182234 loss)
I0526 13:16:24.322175 10701 sgd_solver.cpp:112] Iteration 5439, lr = 0.01
I0526 13:17:35.470196 10701 solver.cpp:239] Iteration 5488 (0.688705 iter/s, 71.148s/49 iters), loss = 0.0254895
I0526 13:17:35.470350 10701 solver.cpp:258]     Train net output #0: loss = 0.0075755 (* 1 = 0.0075755 loss)
I0526 13:17:35.470368 10701 sgd_solver.cpp:112] Iteration 5488, lr = 0.01
I0526 13:18:45.470564 10701 solver.cpp:239] Iteration 5537 (0.7 iter/s, 70s/49 iters), loss = 0.0142013
I0526 13:18:45.470702 10701 solver.cpp:258]     Train net output #0: loss = 0.00254719 (* 1 = 0.00254719 loss)
I0526 13:18:45.470716 10701 sgd_solver.cpp:112] Iteration 5537, lr = 0.01
I0526 13:19:57.432936 10701 solver.cpp:239] Iteration 5586 (0.680915 iter/s, 71.962s/49 iters), loss = 0.0143083
I0526 13:19:57.433116 10701 solver.cpp:258]     Train net output #0: loss = 0.00406073 (* 1 = 0.00406073 loss)
I0526 13:19:57.433140 10701 sgd_solver.cpp:112] Iteration 5586, lr = 0.01
I0526 13:20:56.233286 10701 solver.cpp:239] Iteration 5635 (0.833333 iter/s, 58.8s/49 iters), loss = 0.014408
I0526 13:20:56.233436 10701 solver.cpp:258]     Train net output #0: loss = 0.00178657 (* 1 = 0.00178657 loss)
I0526 13:20:56.233448 10701 sgd_solver.cpp:112] Iteration 5635, lr = 0.01
I0526 13:21:54.953385 10701 solver.cpp:239] Iteration 5684 (0.834483 iter/s, 58.719s/49 iters), loss = 0.0113031
I0526 13:21:54.953528 10701 solver.cpp:258]     Train net output #0: loss = 0.0035699 (* 1 = 0.0035699 loss)
I0526 13:21:54.953547 10701 sgd_solver.cpp:112] Iteration 5684, lr = 0.01
I0526 13:22:53.871404 10701 solver.cpp:239] Iteration 5733 (0.831678 iter/s, 58.917s/49 iters), loss = 0.0163518
I0526 13:22:53.871570 10701 solver.cpp:258]     Train net output #0: loss = 0.00542189 (* 1 = 0.00542189 loss)
I0526 13:22:53.871592 10701 sgd_solver.cpp:112] Iteration 5733, lr = 0.01
I0526 13:23:51.635593 10701 solver.cpp:239] Iteration 5782 (0.848279 iter/s, 57.764s/49 iters), loss = 0.0109508
I0526 13:23:51.635711 10701 solver.cpp:258]     Train net output #0: loss = 0.00477278 (* 1 = 0.00477278 loss)
I0526 13:23:51.635728 10701 sgd_solver.cpp:112] Iteration 5782, lr = 0.01
I0526 13:24:50.656523 10701 solver.cpp:239] Iteration 5831 (0.830227 iter/s, 59.02s/49 iters), loss = 0.0157632
I0526 13:24:50.656936 10701 solver.cpp:258]     Train net output #0: loss = 0.0489504 (* 1 = 0.0489504 loss)
I0526 13:24:50.656957 10701 sgd_solver.cpp:112] Iteration 5831, lr = 0.01
I0526 13:25:47.362866 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_5880.caffemodel
I0526 13:25:47.364095 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_5880.solverstate
I0526 13:25:47.364656 10701 solver.cpp:347] Iteration 5880, Testing net (#0)
I0526 13:26:09.498126 10701 solver.cpp:414]     Test net output #0: accuracy = 0.81
I0526 13:26:09.498179 10701 solver.cpp:414]     Test net output #1: loss = 0.475073 (* 1 = 0.475073 loss)
I0526 13:26:09.498190 10701 solver.cpp:347] Iteration 5880, Testing net (#1)
I0526 13:26:50.667389 10701 solver.cpp:414]     Test net output #0: accuracy = 0.997447
I0526 13:26:50.667601 10701 solver.cpp:414]     Test net output #1: loss = 0.0120976 (* 1 = 0.0120976 loss)
I0526 13:26:50.667618 10701 solver.cpp:347] Iteration 5880, Testing net (#2)
I0526 13:28:24.909941 10701 solver.cpp:414]     Test net output #0: accuracy = 0.872973
I0526 13:28:24.910089 10701 solver.cpp:414]     Test net output #1: loss = 0.304251 (* 1 = 0.304251 loss)
I0526 13:28:26.003192 10701 solver.cpp:239] Iteration 5880 (0.227541 iter/s, 215.346s/49 iters), loss = 0.0201921
I0526 13:28:26.003293 10701 solver.cpp:258]     Train net output #0: loss = 0.000872731 (* 1 = 0.000872731 loss)
I0526 13:28:26.003329 10701 sgd_solver.cpp:112] Iteration 5880, lr = 0.01
I0526 13:29:25.298286 10701 solver.cpp:239] Iteration 5929 (0.826391 iter/s, 59.294s/49 iters), loss = 0.0283622
I0526 13:29:25.298486 10701 solver.cpp:258]     Train net output #0: loss = 0.00269104 (* 1 = 0.00269104 loss)
I0526 13:29:25.298528 10701 sgd_solver.cpp:112] Iteration 5929, lr = 0.01
I0526 13:30:24.196640 10701 solver.cpp:239] Iteration 5978 (0.831947 iter/s, 58.898s/49 iters), loss = 0.0106585
I0526 13:30:24.196784 10701 solver.cpp:258]     Train net output #0: loss = 0.00439428 (* 1 = 0.00439428 loss)
I0526 13:30:24.196801 10701 sgd_solver.cpp:112] Iteration 5978, lr = 0.01
I0526 13:31:21.893158 10701 solver.cpp:239] Iteration 6027 (0.849279 iter/s, 57.696s/49 iters), loss = 0.0122199
I0526 13:31:21.893290 10701 solver.cpp:258]     Train net output #0: loss = 0.00615336 (* 1 = 0.00615336 loss)
I0526 13:31:21.893301 10701 sgd_solver.cpp:112] Iteration 6027, lr = 0.01
I0526 13:32:20.389008 10701 solver.cpp:239] Iteration 6076 (0.837678 iter/s, 58.495s/49 iters), loss = 0.0111438
I0526 13:32:20.389140 10701 solver.cpp:258]     Train net output #0: loss = 0.00405076 (* 1 = 0.00405076 loss)
I0526 13:32:20.389150 10701 sgd_solver.cpp:112] Iteration 6076, lr = 0.01
I0526 13:33:19.000062 10701 solver.cpp:239] Iteration 6125 (0.836035 iter/s, 58.61s/49 iters), loss = 0.0157499
I0526 13:33:19.000245 10701 solver.cpp:258]     Train net output #0: loss = 0.0441736 (* 1 = 0.0441736 loss)
I0526 13:33:19.000295 10701 sgd_solver.cpp:112] Iteration 6125, lr = 0.01
I0526 13:34:17.926753 10701 solver.cpp:239] Iteration 6174 (0.831551 iter/s, 58.926s/49 iters), loss = 0.017484
I0526 13:34:17.926918 10701 solver.cpp:258]     Train net output #0: loss = 0.00883545 (* 1 = 0.00883545 loss)
I0526 13:34:17.926934 10701 sgd_solver.cpp:112] Iteration 6174, lr = 0.01
I0526 13:35:16.223958 10701 solver.cpp:239] Iteration 6223 (0.840524 iter/s, 58.297s/49 iters), loss = 0.00256952
I0526 13:35:16.224138 10701 solver.cpp:258]     Train net output #0: loss = 0.000190078 (* 1 = 0.000190078 loss)
I0526 13:35:16.224156 10701 sgd_solver.cpp:112] Iteration 6223, lr = 0.01
I0526 13:36:14.031323 10701 solver.cpp:239] Iteration 6272 (0.847648 iter/s, 57.807s/49 iters), loss = 0.0269559
I0526 13:36:14.031505 10701 solver.cpp:258]     Train net output #0: loss = 0.0555815 (* 1 = 0.0555815 loss)
I0526 13:36:14.031539 10701 sgd_solver.cpp:112] Iteration 6272, lr = 0.01
I0526 13:37:20.941695 10701 solver.cpp:239] Iteration 6321 (0.732327 iter/s, 66.91s/49 iters), loss = 0.0182134
I0526 13:37:20.942145 10701 solver.cpp:258]     Train net output #0: loss = 0.0221324 (* 1 = 0.0221324 loss)
I0526 13:37:20.942170 10701 sgd_solver.cpp:112] Iteration 6321, lr = 0.01
I0526 13:38:30.830745 10701 solver.cpp:239] Iteration 6370 (0.701122 iter/s, 69.888s/49 iters), loss = 0.00970131
I0526 13:38:30.831152 10701 solver.cpp:258]     Train net output #0: loss = 0.00338172 (* 1 = 0.00338172 loss)
I0526 13:38:30.831235 10701 sgd_solver.cpp:112] Iteration 6370, lr = 0.01
I0526 13:39:39.368774 10701 solver.cpp:239] Iteration 6419 (0.714942 iter/s, 68.537s/49 iters), loss = 0.00974386
I0526 13:39:39.368973 10701 solver.cpp:258]     Train net output #0: loss = 0.000640323 (* 1 = 0.000640323 loss)
I0526 13:39:39.368988 10701 sgd_solver.cpp:112] Iteration 6419, lr = 0.01
I0526 13:40:48.773686 10701 solver.cpp:239] Iteration 6468 (0.706011 iter/s, 69.404s/49 iters), loss = 0.00809184
I0526 13:40:48.773872 10701 solver.cpp:258]     Train net output #0: loss = 0.00223381 (* 1 = 0.00223381 loss)
I0526 13:40:48.773906 10701 sgd_solver.cpp:112] Iteration 6468, lr = 0.01
I0526 13:41:58.443295 10701 solver.cpp:239] Iteration 6517 (0.703326 iter/s, 69.669s/49 iters), loss = 0.00939738
I0526 13:41:58.443574 10701 solver.cpp:258]     Train net output #0: loss = 0.00163435 (* 1 = 0.00163435 loss)
I0526 13:41:58.443591 10701 sgd_solver.cpp:112] Iteration 6517, lr = 0.01
I0526 13:43:07.638759 10701 solver.cpp:239] Iteration 6566 (0.708144 iter/s, 69.195s/49 iters), loss = 0.00789707
I0526 13:43:07.638933 10701 solver.cpp:258]     Train net output #0: loss = 0.000656891 (* 1 = 0.000656891 loss)
I0526 13:43:07.638954 10701 sgd_solver.cpp:112] Iteration 6566, lr = 0.01
I0526 13:44:19.161489 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_6615.caffemodel
I0526 13:44:19.162802 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_6615.solverstate
I0526 13:44:19.163381 10701 solver.cpp:347] Iteration 6615, Testing net (#0)
I0526 13:44:46.138115 10701 solver.cpp:414]     Test net output #0: accuracy = 0.7892
I0526 13:44:46.138176 10701 solver.cpp:414]     Test net output #1: loss = 0.442726 (* 1 = 0.442726 loss)
I0526 13:44:46.138191 10701 solver.cpp:347] Iteration 6615, Testing net (#1)
I0526 13:45:38.376773 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998085
I0526 13:45:38.377167 10701 solver.cpp:414]     Test net output #1: loss = 0.0114614 (* 1 = 0.0114614 loss)
I0526 13:45:38.377223 10701 solver.cpp:347] Iteration 6615, Testing net (#2)
I0526 13:47:32.570031 10701 solver.cpp:414]     Test net output #0: accuracy = 0.880811
I0526 13:47:32.570304 10701 solver.cpp:414]     Test net output #1: loss = 0.345252 (* 1 = 0.345252 loss)
I0526 13:47:34.058295 10701 solver.cpp:239] Iteration 6615 (0.183921 iter/s, 266.419s/49 iters), loss = 0.00753951
I0526 13:47:34.058385 10701 solver.cpp:258]     Train net output #0: loss = 0.0196399 (* 1 = 0.0196399 loss)
I0526 13:47:34.058404 10701 sgd_solver.cpp:112] Iteration 6615, lr = 0.01
I0526 13:48:48.077893 10701 solver.cpp:239] Iteration 6664 (0.661992 iter/s, 74.019s/49 iters), loss = 0.0106567
I0526 13:48:48.078058 10701 solver.cpp:258]     Train net output #0: loss = 0.0325891 (* 1 = 0.0325891 loss)
I0526 13:48:48.078075 10701 sgd_solver.cpp:112] Iteration 6664, lr = 0.01
I0526 13:49:54.699476 10701 solver.cpp:239] Iteration 6713 (0.735504 iter/s, 66.621s/49 iters), loss = 0.0115524
I0526 13:49:54.699673 10701 solver.cpp:258]     Train net output #0: loss = 0.0194739 (* 1 = 0.0194739 loss)
I0526 13:49:54.699697 10701 sgd_solver.cpp:112] Iteration 6713, lr = 0.01
I0526 13:51:04.185951 10701 solver.cpp:239] Iteration 6762 (0.705178 iter/s, 69.486s/49 iters), loss = 0.0163968
I0526 13:51:04.186146 10701 solver.cpp:258]     Train net output #0: loss = 0.0764886 (* 1 = 0.0764886 loss)
I0526 13:51:04.186201 10701 sgd_solver.cpp:112] Iteration 6762, lr = 0.01
I0526 13:52:16.674448 10701 solver.cpp:239] Iteration 6811 (0.675974 iter/s, 72.488s/49 iters), loss = 0.0112893
I0526 13:52:16.674827 10701 solver.cpp:258]     Train net output #0: loss = 0.00627157 (* 1 = 0.00627157 loss)
I0526 13:52:16.674866 10701 sgd_solver.cpp:112] Iteration 6811, lr = 0.01
I0526 13:53:27.369563 10701 solver.cpp:239] Iteration 6860 (0.693128 iter/s, 70.694s/49 iters), loss = 0.0139202
I0526 13:53:27.369814 10701 solver.cpp:258]     Train net output #0: loss = 0.00441402 (* 1 = 0.00441402 loss)
I0526 13:53:27.369832 10701 sgd_solver.cpp:112] Iteration 6860, lr = 0.01
I0526 13:54:39.925253 10701 solver.cpp:239] Iteration 6909 (0.67535 iter/s, 72.555s/49 iters), loss = 0.00623174
I0526 13:54:39.925416 10701 solver.cpp:258]     Train net output #0: loss = 0.0244474 (* 1 = 0.0244474 loss)
I0526 13:54:39.925437 10701 sgd_solver.cpp:112] Iteration 6909, lr = 0.01
I0526 13:55:52.751632 10701 solver.cpp:239] Iteration 6958 (0.672837 iter/s, 72.826s/49 iters), loss = 0.0137236
I0526 13:55:52.751909 10701 solver.cpp:258]     Train net output #0: loss = 0.00317203 (* 1 = 0.00317203 loss)
I0526 13:55:52.751931 10701 sgd_solver.cpp:112] Iteration 6958, lr = 0.01
I0526 13:56:52.149389 10701 solver.cpp:239] Iteration 7007 (0.824957 iter/s, 59.397s/49 iters), loss = 0.0155435
I0526 13:56:52.149549 10701 solver.cpp:258]     Train net output #0: loss = 0.0113038 (* 1 = 0.0113038 loss)
I0526 13:56:52.149569 10701 sgd_solver.cpp:112] Iteration 7007, lr = 0.01
I0526 13:57:50.522332 10701 solver.cpp:239] Iteration 7056 (0.839444 iter/s, 58.372s/49 iters), loss = 0.0118697
I0526 13:57:50.522497 10701 solver.cpp:258]     Train net output #0: loss = 0.00109369 (* 1 = 0.00109369 loss)
I0526 13:57:50.522522 10701 sgd_solver.cpp:112] Iteration 7056, lr = 0.01
I0526 13:58:50.581578 10701 solver.cpp:239] Iteration 7105 (0.815864 iter/s, 60.059s/49 iters), loss = 0.0144802
I0526 13:58:50.581763 10701 solver.cpp:258]     Train net output #0: loss = 0.00100836 (* 1 = 0.00100836 loss)
I0526 13:58:50.581789 10701 sgd_solver.cpp:112] Iteration 7105, lr = 0.01
I0526 13:59:50.150585 10701 solver.cpp:239] Iteration 7154 (0.822589 iter/s, 59.568s/49 iters), loss = 0.011251
I0526 13:59:50.150728 10701 solver.cpp:258]     Train net output #0: loss = 0.0033221 (* 1 = 0.0033221 loss)
I0526 13:59:50.150740 10701 sgd_solver.cpp:112] Iteration 7154, lr = 0.01
I0526 14:00:51.106855 10701 solver.cpp:239] Iteration 7203 (0.803859 iter/s, 60.956s/49 iters), loss = 0.0181264
I0526 14:00:51.107017 10701 solver.cpp:258]     Train net output #0: loss = 0.00730958 (* 1 = 0.00730958 loss)
I0526 14:00:51.107036 10701 sgd_solver.cpp:112] Iteration 7203, lr = 0.01
I0526 14:01:49.723769 10701 solver.cpp:239] Iteration 7252 (0.835949 iter/s, 58.616s/49 iters), loss = 0.0083157
I0526 14:01:49.723920 10701 solver.cpp:258]     Train net output #0: loss = 0.0315885 (* 1 = 0.0315885 loss)
I0526 14:01:49.723939 10701 sgd_solver.cpp:112] Iteration 7252, lr = 0.01
I0526 14:02:48.636827 10701 solver.cpp:239] Iteration 7301 (0.831749 iter/s, 58.912s/49 iters), loss = 0.0136913
I0526 14:02:48.636988 10701 solver.cpp:258]     Train net output #0: loss = 0.00078445 (* 1 = 0.00078445 loss)
I0526 14:02:48.637009 10701 sgd_solver.cpp:112] Iteration 7301, lr = 0.01
I0526 14:03:48.184515 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_7350.caffemodel
I0526 14:03:48.186007 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_7350.solverstate
I0526 14:03:48.186707 10701 solver.cpp:347] Iteration 7350, Testing net (#0)
I0526 14:04:09.707790 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8796
I0526 14:04:09.707845 10701 solver.cpp:414]     Test net output #1: loss = 0.301063 (* 1 = 0.301063 loss)
I0526 14:04:09.707854 10701 solver.cpp:347] Iteration 7350, Testing net (#1)
I0526 14:04:50.985005 10701 solver.cpp:414]     Test net output #0: accuracy = 0.997021
I0526 14:04:50.985168 10701 solver.cpp:414]     Test net output #1: loss = 0.0127917 (* 1 = 0.0127917 loss)
I0526 14:04:50.985184 10701 solver.cpp:347] Iteration 7350, Testing net (#2)
I0526 14:06:40.083750 10701 solver.cpp:414]     Test net output #0: accuracy = 0.89964
I0526 14:06:40.083986 10701 solver.cpp:414]     Test net output #1: loss = 0.232742 (* 1 = 0.232742 loss)
I0526 14:06:41.845141 10701 solver.cpp:239] Iteration 7350 (0.210113 iter/s, 233.208s/49 iters), loss = 0.0141298
I0526 14:06:41.845203 10701 solver.cpp:258]     Train net output #0: loss = 0.00271652 (* 1 = 0.00271652 loss)
I0526 14:06:41.845221 10701 sgd_solver.cpp:112] Iteration 7350, lr = 0.01
I0526 14:07:56.992769 10701 solver.cpp:239] Iteration 7399 (0.652055 iter/s, 75.147s/49 iters), loss = 0.0111117
I0526 14:07:56.992931 10701 solver.cpp:258]     Train net output #0: loss = 0.00170766 (* 1 = 0.00170766 loss)
I0526 14:07:56.992950 10701 sgd_solver.cpp:112] Iteration 7399, lr = 0.01
I0526 14:09:05.003091 10701 solver.cpp:239] Iteration 7448 (0.720482 iter/s, 68.01s/49 iters), loss = 0.0128657
I0526 14:09:05.003288 10701 solver.cpp:258]     Train net output #0: loss = 0.00184937 (* 1 = 0.00184937 loss)
I0526 14:09:05.003299 10701 sgd_solver.cpp:112] Iteration 7448, lr = 0.01
I0526 14:10:12.056919 10701 solver.cpp:239] Iteration 7497 (0.730765 iter/s, 67.053s/49 iters), loss = 0.00692569
I0526 14:10:12.057078 10701 solver.cpp:258]     Train net output #0: loss = 0.000722628 (* 1 = 0.000722628 loss)
I0526 14:10:12.057094 10701 sgd_solver.cpp:112] Iteration 7497, lr = 0.01
I0526 14:11:22.162006 10701 solver.cpp:239] Iteration 7546 (0.698962 iter/s, 70.104s/49 iters), loss = 0.0165197
I0526 14:11:22.162189 10701 solver.cpp:258]     Train net output #0: loss = 0.000825218 (* 1 = 0.000825218 loss)
I0526 14:11:22.162205 10701 sgd_solver.cpp:112] Iteration 7546, lr = 0.01
I0526 14:12:35.407155 10701 solver.cpp:239] Iteration 7595 (0.668997 iter/s, 73.244s/49 iters), loss = 0.0136093
I0526 14:12:35.407328 10701 solver.cpp:258]     Train net output #0: loss = 0.00981368 (* 1 = 0.00981368 loss)
I0526 14:12:35.407346 10701 sgd_solver.cpp:112] Iteration 7595, lr = 0.01
I0526 14:13:39.880569 10701 solver.cpp:239] Iteration 7644 (0.760008 iter/s, 64.473s/49 iters), loss = 0.00926469
I0526 14:13:39.880722 10701 solver.cpp:258]     Train net output #0: loss = 0.00103581 (* 1 = 0.00103581 loss)
I0526 14:13:39.880734 10701 sgd_solver.cpp:112] Iteration 7644, lr = 0.01
I0526 14:14:46.372526 10701 solver.cpp:239] Iteration 7693 (0.736942 iter/s, 66.491s/49 iters), loss = 0.016313
I0526 14:14:46.372689 10701 solver.cpp:258]     Train net output #0: loss = 0.00466599 (* 1 = 0.00466599 loss)
I0526 14:14:46.372707 10701 sgd_solver.cpp:112] Iteration 7693, lr = 0.01
I0526 14:15:53.530413 10701 solver.cpp:239] Iteration 7742 (0.729634 iter/s, 67.157s/49 iters), loss = 0.0170212
I0526 14:15:53.530578 10701 solver.cpp:258]     Train net output #0: loss = 0.00885061 (* 1 = 0.00885061 loss)
I0526 14:15:53.530596 10701 sgd_solver.cpp:112] Iteration 7742, lr = 0.01
I0526 14:16:57.799996 10701 solver.cpp:239] Iteration 7791 (0.76242 iter/s, 64.269s/49 iters), loss = 0.0152369
I0526 14:16:57.800658 10701 solver.cpp:258]     Train net output #0: loss = 0.0017655 (* 1 = 0.0017655 loss)
I0526 14:16:57.800683 10701 sgd_solver.cpp:112] Iteration 7791, lr = 0.01
I0526 14:18:06.256345 10701 solver.cpp:239] Iteration 7840 (0.715799 iter/s, 68.455s/49 iters), loss = 0.0170364
I0526 14:18:06.256656 10701 solver.cpp:258]     Train net output #0: loss = 0.0010977 (* 1 = 0.0010977 loss)
I0526 14:18:06.256721 10701 sgd_solver.cpp:112] Iteration 7840, lr = 0.01
I0526 14:19:14.600162 10701 solver.cpp:239] Iteration 7889 (0.716972 iter/s, 68.343s/49 iters), loss = 0.0107715
I0526 14:19:14.600311 10701 solver.cpp:258]     Train net output #0: loss = 0.000515717 (* 1 = 0.000515717 loss)
I0526 14:19:14.600328 10701 sgd_solver.cpp:112] Iteration 7889, lr = 0.01
I0526 14:20:19.697540 10701 solver.cpp:239] Iteration 7938 (0.752723 iter/s, 65.097s/49 iters), loss = 0.0126241
I0526 14:20:19.697700 10701 solver.cpp:258]     Train net output #0: loss = 0.00116415 (* 1 = 0.00116415 loss)
I0526 14:20:19.697721 10701 sgd_solver.cpp:112] Iteration 7938, lr = 0.01
I0526 14:21:24.656051 10701 solver.cpp:239] Iteration 7987 (0.754334 iter/s, 64.958s/49 iters), loss = 0.0122699
I0526 14:21:24.656199 10701 solver.cpp:258]     Train net output #0: loss = 0.000221852 (* 1 = 0.000221852 loss)
I0526 14:21:24.656217 10701 sgd_solver.cpp:112] Iteration 7987, lr = 0.01
I0526 14:22:34.085173 10701 solver.cpp:239] Iteration 8036 (0.705767 iter/s, 69.428s/49 iters), loss = 0.0164803
I0526 14:22:34.085376 10701 solver.cpp:258]     Train net output #0: loss = 0.010477 (* 1 = 0.010477 loss)
I0526 14:22:34.085400 10701 sgd_solver.cpp:112] Iteration 8036, lr = 0.01
I0526 14:23:38.069599 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_8085.caffemodel
I0526 14:23:38.070770 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_8085.solverstate
I0526 14:23:38.071314 10701 solver.cpp:347] Iteration 8085, Testing net (#0)
I0526 14:24:00.633793 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8224
I0526 14:24:00.633846 10701 solver.cpp:414]     Test net output #1: loss = 0.430277 (* 1 = 0.430277 loss)
I0526 14:24:00.633858 10701 solver.cpp:347] Iteration 8085, Testing net (#1)
I0526 14:24:46.127286 10701 solver.cpp:414]     Test net output #0: accuracy = 0.996809
I0526 14:24:46.127493 10701 solver.cpp:414]     Test net output #1: loss = 0.0146389 (* 1 = 0.0146389 loss)
I0526 14:24:46.127518 10701 solver.cpp:347] Iteration 8085, Testing net (#2)
I0526 14:26:19.797488 10701 solver.cpp:414]     Test net output #0: accuracy = 0.871441
I0526 14:26:19.797642 10701 solver.cpp:414]     Test net output #1: loss = 0.314143 (* 1 = 0.314143 loss)
I0526 14:26:21.075920 10701 solver.cpp:239] Iteration 8085 (0.215869 iter/s, 226.99s/49 iters), loss = 0.0121099
I0526 14:26:21.075985 10701 solver.cpp:258]     Train net output #0: loss = 0.0035338 (* 1 = 0.0035338 loss)
I0526 14:26:21.076000 10701 sgd_solver.cpp:112] Iteration 8085, lr = 0.01
I0526 14:27:19.426496 10701 solver.cpp:239] Iteration 8134 (0.83976 iter/s, 58.35s/49 iters), loss = 0.0170762
I0526 14:27:19.426645 10701 solver.cpp:258]     Train net output #0: loss = 0.0311171 (* 1 = 0.0311171 loss)
I0526 14:27:19.426661 10701 sgd_solver.cpp:112] Iteration 8134, lr = 0.01
I0526 14:28:18.988683 10701 solver.cpp:239] Iteration 8183 (0.822672 iter/s, 59.562s/49 iters), loss = 0.00865139
I0526 14:28:18.988847 10701 solver.cpp:258]     Train net output #0: loss = 0.0245628 (* 1 = 0.0245628 loss)
I0526 14:28:18.988867 10701 sgd_solver.cpp:112] Iteration 8183, lr = 0.01
I0526 14:29:17.291195 10701 solver.cpp:239] Iteration 8232 (0.840451 iter/s, 58.302s/49 iters), loss = 0.00930915
I0526 14:29:17.291591 10701 solver.cpp:258]     Train net output #0: loss = 0.00292589 (* 1 = 0.00292589 loss)
I0526 14:29:17.291616 10701 sgd_solver.cpp:112] Iteration 8232, lr = 0.01
I0526 14:30:16.267381 10701 solver.cpp:239] Iteration 8281 (0.830861 iter/s, 58.975s/49 iters), loss = 0.00434228
I0526 14:30:16.267544 10701 solver.cpp:258]     Train net output #0: loss = 0.00029505 (* 1 = 0.00029505 loss)
I0526 14:30:16.267565 10701 sgd_solver.cpp:112] Iteration 8281, lr = 0.01
I0526 14:31:15.633378 10701 solver.cpp:239] Iteration 8330 (0.825402 iter/s, 59.365s/49 iters), loss = 0.00979084
I0526 14:31:15.633533 10701 solver.cpp:258]     Train net output #0: loss = 0.00179981 (* 1 = 0.00179981 loss)
I0526 14:31:15.633551 10701 sgd_solver.cpp:112] Iteration 8330, lr = 0.01
I0526 14:32:14.357048 10701 solver.cpp:239] Iteration 8379 (0.834426 iter/s, 58.723s/49 iters), loss = 0.0104903
I0526 14:32:14.357218 10701 solver.cpp:258]     Train net output #0: loss = 0.00302783 (* 1 = 0.00302783 loss)
I0526 14:32:14.357249 10701 sgd_solver.cpp:112] Iteration 8379, lr = 0.01
I0526 14:33:13.504942 10701 solver.cpp:239] Iteration 8428 (0.828444 iter/s, 59.147s/49 iters), loss = 0.00797686
I0526 14:33:13.505115 10701 solver.cpp:258]     Train net output #0: loss = 0.00280254 (* 1 = 0.00280254 loss)
I0526 14:33:13.505165 10701 sgd_solver.cpp:112] Iteration 8428, lr = 0.01
I0526 14:34:12.586076 10701 solver.cpp:239] Iteration 8477 (0.829384 iter/s, 59.08s/49 iters), loss = 0.019848
I0526 14:34:12.586266 10701 solver.cpp:258]     Train net output #0: loss = 0.00125192 (* 1 = 0.00125192 loss)
I0526 14:34:12.586320 10701 sgd_solver.cpp:112] Iteration 8477, lr = 0.01
I0526 14:35:12.506842 10701 solver.cpp:239] Iteration 8526 (0.817757 iter/s, 59.92s/49 iters), loss = 0.0117509
I0526 14:35:12.507000 10701 solver.cpp:258]     Train net output #0: loss = 0.0215711 (* 1 = 0.0215711 loss)
I0526 14:35:12.507016 10701 sgd_solver.cpp:112] Iteration 8526, lr = 0.01
I0526 14:36:10.483641 10701 solver.cpp:239] Iteration 8575 (0.845177 iter/s, 57.976s/49 iters), loss = 0.00448524
I0526 14:36:10.483814 10701 solver.cpp:258]     Train net output #0: loss = 0.000500546 (* 1 = 0.000500546 loss)
I0526 14:36:10.483831 10701 sgd_solver.cpp:112] Iteration 8575, lr = 0.01
I0526 14:37:10.343164 10701 solver.cpp:239] Iteration 8624 (0.81859 iter/s, 59.859s/49 iters), loss = 0.0133113
I0526 14:37:10.343380 10701 solver.cpp:258]     Train net output #0: loss = 0.000824726 (* 1 = 0.000824726 loss)
I0526 14:37:10.343402 10701 sgd_solver.cpp:112] Iteration 8624, lr = 0.01
I0526 14:38:09.125952 10701 solver.cpp:239] Iteration 8673 (0.833588 iter/s, 58.782s/49 iters), loss = 0.0123774
I0526 14:38:09.126123 10701 solver.cpp:258]     Train net output #0: loss = 0.000497559 (* 1 = 0.000497559 loss)
I0526 14:38:09.126142 10701 sgd_solver.cpp:112] Iteration 8673, lr = 0.01
I0526 14:39:13.330549 10701 solver.cpp:239] Iteration 8722 (0.763192 iter/s, 64.204s/49 iters), loss = 0.0196679
I0526 14:39:13.330706 10701 solver.cpp:258]     Train net output #0: loss = 0.00551004 (* 1 = 0.00551004 loss)
I0526 14:39:13.330725 10701 sgd_solver.cpp:112] Iteration 8722, lr = 0.01
I0526 14:40:21.400346 10701 solver.cpp:239] Iteration 8771 (0.719858 iter/s, 68.069s/49 iters), loss = 0.0185491
I0526 14:40:21.400517 10701 solver.cpp:258]     Train net output #0: loss = 0.0142707 (* 1 = 0.0142707 loss)
I0526 14:40:21.400532 10701 sgd_solver.cpp:112] Iteration 8771, lr = 0.01
I0526 14:41:26.230504 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_8820.caffemodel
I0526 14:41:26.232575 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_8820.solverstate
I0526 14:41:26.233263 10701 solver.cpp:347] Iteration 8820, Testing net (#0)
I0526 14:41:52.747634 10701 solver.cpp:414]     Test net output #0: accuracy = 0.7052
I0526 14:41:52.747674 10701 solver.cpp:414]     Test net output #1: loss = 1.12562 (* 1 = 1.12562 loss)
I0526 14:41:52.747682 10701 solver.cpp:347] Iteration 8820, Testing net (#1)
I0526 14:42:38.630553 10701 solver.cpp:414]     Test net output #0: accuracy = 0.99617
I0526 14:42:38.630746 10701 solver.cpp:414]     Test net output #1: loss = 0.0102173 (* 1 = 0.0102173 loss)
I0526 14:42:38.630769 10701 solver.cpp:347] Iteration 8820, Testing net (#2)
I0526 14:44:23.182929 10701 solver.cpp:414]     Test net output #0: accuracy = 0.787297
I0526 14:44:23.183316 10701 solver.cpp:414]     Test net output #1: loss = 0.800241 (* 1 = 0.800241 loss)
I0526 14:44:24.472930 10701 solver.cpp:239] Iteration 8820 (0.201586 iter/s, 243.072s/49 iters), loss = 0.0134795
I0526 14:44:24.472986 10701 solver.cpp:258]     Train net output #0: loss = 0.00118482 (* 1 = 0.00118482 loss)
I0526 14:44:24.472997 10701 sgd_solver.cpp:112] Iteration 8820, lr = 0.005
I0526 14:45:58.171538 10701 solver.cpp:239] Iteration 8869 (0.522957 iter/s, 93.698s/49 iters), loss = 0.0162877
I0526 14:45:58.171708 10701 solver.cpp:258]     Train net output #0: loss = 0.00726058 (* 1 = 0.00726058 loss)
I0526 14:45:58.171737 10701 sgd_solver.cpp:112] Iteration 8869, lr = 0.005
I0526 14:47:04.437805 10701 solver.cpp:239] Iteration 8918 (0.739444 iter/s, 66.266s/49 iters), loss = 0.0129214
I0526 14:47:04.437960 10701 solver.cpp:258]     Train net output #0: loss = 0.0103673 (* 1 = 0.0103673 loss)
I0526 14:47:04.437978 10701 sgd_solver.cpp:112] Iteration 8918, lr = 0.005
I0526 14:48:09.489775 10701 solver.cpp:239] Iteration 8967 (0.753255 iter/s, 65.051s/49 iters), loss = 0.00820592
I0526 14:48:09.490018 10701 solver.cpp:258]     Train net output #0: loss = 0.00271345 (* 1 = 0.00271345 loss)
I0526 14:48:09.490067 10701 sgd_solver.cpp:112] Iteration 8967, lr = 0.005
I0526 14:49:14.680291 10701 solver.cpp:239] Iteration 9016 (0.751649 iter/s, 65.19s/49 iters), loss = 0.0111358
I0526 14:49:14.680485 10701 solver.cpp:258]     Train net output #0: loss = 0.0254093 (* 1 = 0.0254093 loss)
I0526 14:49:14.680510 10701 sgd_solver.cpp:112] Iteration 9016, lr = 0.005
I0526 14:50:22.335835 10701 solver.cpp:239] Iteration 9065 (0.724263 iter/s, 67.655s/49 iters), loss = 0.0161031
I0526 14:50:22.335968 10701 solver.cpp:258]     Train net output #0: loss = 0.00377052 (* 1 = 0.00377052 loss)
I0526 14:50:22.335980 10701 sgd_solver.cpp:112] Iteration 9065, lr = 0.005
I0526 14:51:27.906343 10701 solver.cpp:239] Iteration 9114 (0.747293 iter/s, 65.57s/49 iters), loss = 0.00908647
I0526 14:51:27.906663 10701 solver.cpp:258]     Train net output #0: loss = 0.000820252 (* 1 = 0.000820252 loss)
I0526 14:51:27.906689 10701 sgd_solver.cpp:112] Iteration 9114, lr = 0.005
I0526 14:52:32.173779 10701 solver.cpp:239] Iteration 9163 (0.762444 iter/s, 64.267s/49 iters), loss = 0.00858097
I0526 14:52:32.173980 10701 solver.cpp:258]     Train net output #0: loss = 0.00272594 (* 1 = 0.00272594 loss)
I0526 14:52:32.174000 10701 sgd_solver.cpp:112] Iteration 9163, lr = 0.005
I0526 14:53:33.551118 10701 solver.cpp:239] Iteration 9212 (0.798345 iter/s, 61.377s/49 iters), loss = 0.00537635
I0526 14:53:33.551263 10701 solver.cpp:258]     Train net output #0: loss = 0.000457362 (* 1 = 0.000457362 loss)
I0526 14:53:33.551283 10701 sgd_solver.cpp:112] Iteration 9212, lr = 0.005
I0526 14:54:35.141789 10701 solver.cpp:239] Iteration 9261 (0.795584 iter/s, 61.59s/49 iters), loss = 0.0103905
I0526 14:54:35.142004 10701 solver.cpp:258]     Train net output #0: loss = 0.00126474 (* 1 = 0.00126474 loss)
I0526 14:54:35.142052 10701 sgd_solver.cpp:112] Iteration 9261, lr = 0.005
I0526 14:55:34.613834 10701 solver.cpp:239] Iteration 9310 (0.823931 iter/s, 59.471s/49 iters), loss = 0.0080203
I0526 14:55:34.614027 10701 solver.cpp:258]     Train net output #0: loss = 0.00300952 (* 1 = 0.00300952 loss)
I0526 14:55:34.614042 10701 sgd_solver.cpp:112] Iteration 9310, lr = 0.005
I0526 14:56:33.730365 10701 solver.cpp:239] Iteration 9359 (0.828879 iter/s, 59.116s/49 iters), loss = 0.00324069
I0526 14:56:33.730541 10701 solver.cpp:258]     Train net output #0: loss = 0.000284883 (* 1 = 0.000284883 loss)
I0526 14:56:33.730567 10701 sgd_solver.cpp:112] Iteration 9359, lr = 0.005
I0526 14:57:33.373646 10701 solver.cpp:239] Iteration 9408 (0.821555 iter/s, 59.643s/49 iters), loss = 0.00940208
I0526 14:57:33.373796 10701 solver.cpp:258]     Train net output #0: loss = 0.0065036 (* 1 = 0.0065036 loss)
I0526 14:57:33.373814 10701 sgd_solver.cpp:112] Iteration 9408, lr = 0.005
I0526 14:58:30.908464 10701 solver.cpp:239] Iteration 9457 (0.85167 iter/s, 57.534s/49 iters), loss = 0.0137773
I0526 14:58:30.908613 10701 solver.cpp:258]     Train net output #0: loss = 0.0492188 (* 1 = 0.0492188 loss)
I0526 14:58:30.908633 10701 sgd_solver.cpp:112] Iteration 9457, lr = 0.005
I0526 14:59:28.638599 10701 solver.cpp:239] Iteration 9506 (0.848794 iter/s, 57.729s/49 iters), loss = 0.013178
I0526 14:59:28.638767 10701 solver.cpp:258]     Train net output #0: loss = 0.0010124 (* 1 = 0.0010124 loss)
I0526 14:59:28.638779 10701 sgd_solver.cpp:112] Iteration 9506, lr = 0.005
I0526 15:00:26.525234 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_9555.caffemodel
I0526 15:00:26.526671 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_9555.solverstate
I0526 15:00:26.527402 10701 solver.cpp:347] Iteration 9555, Testing net (#0)
I0526 15:00:48.086930 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8744
I0526 15:00:48.086977 10701 solver.cpp:414]     Test net output #1: loss = 0.338734 (* 1 = 0.338734 loss)
I0526 15:00:48.086988 10701 solver.cpp:347] Iteration 9555, Testing net (#1)
I0526 15:01:28.911288 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998085
I0526 15:01:28.911468 10701 solver.cpp:414]     Test net output #1: loss = 0.00590051 (* 1 = 0.00590051 loss)
I0526 15:01:28.911497 10701 solver.cpp:347] Iteration 9555, Testing net (#2)
I0526 15:03:02.733543 10701 solver.cpp:414]     Test net output #0: accuracy = 0.918739
I0526 15:03:02.733729 10701 solver.cpp:414]     Test net output #1: loss = 0.200098 (* 1 = 0.200098 loss)
I0526 15:03:03.833586 10701 solver.cpp:239] Iteration 9555 (0.227702 iter/s, 215.194s/49 iters), loss = 0.010543
I0526 15:03:03.833631 10701 solver.cpp:258]     Train net output #0: loss = 0.0152739 (* 1 = 0.0152739 loss)
I0526 15:03:03.833640 10701 sgd_solver.cpp:112] Iteration 9555, lr = 0.005
I0526 15:04:02.342447 10701 solver.cpp:239] Iteration 9604 (0.837492 iter/s, 58.508s/49 iters), loss = 0.0105857
I0526 15:04:02.342636 10701 solver.cpp:258]     Train net output #0: loss = 0.00487784 (* 1 = 0.00487784 loss)
I0526 15:04:02.342654 10701 sgd_solver.cpp:112] Iteration 9604, lr = 0.005
I0526 15:05:01.172758 10701 solver.cpp:239] Iteration 9653 (0.832908 iter/s, 58.83s/49 iters), loss = 0.00680711
I0526 15:05:01.172924 10701 solver.cpp:258]     Train net output #0: loss = 0.00416581 (* 1 = 0.00416581 loss)
I0526 15:05:01.172943 10701 sgd_solver.cpp:112] Iteration 9653, lr = 0.005
I0526 15:05:59.885293 10701 solver.cpp:239] Iteration 9702 (0.834582 iter/s, 58.712s/49 iters), loss = 0.0115732
I0526 15:05:59.885438 10701 solver.cpp:258]     Train net output #0: loss = 0.00181437 (* 1 = 0.00181437 loss)
I0526 15:05:59.885457 10701 sgd_solver.cpp:112] Iteration 9702, lr = 0.005
I0526 15:06:59.302181 10701 solver.cpp:239] Iteration 9751 (0.824694 iter/s, 59.416s/49 iters), loss = 0.00431047
I0526 15:06:59.302345 10701 solver.cpp:258]     Train net output #0: loss = 0.000413543 (* 1 = 0.000413543 loss)
I0526 15:06:59.302361 10701 sgd_solver.cpp:112] Iteration 9751, lr = 0.005
I0526 15:07:57.897322 10701 solver.cpp:239] Iteration 9800 (0.836263 iter/s, 58.594s/49 iters), loss = 0.0145317
I0526 15:07:57.897650 10701 solver.cpp:258]     Train net output #0: loss = 0.0345408 (* 1 = 0.0345408 loss)
I0526 15:07:57.897667 10701 sgd_solver.cpp:112] Iteration 9800, lr = 0.005
I0526 15:08:56.116760 10701 solver.cpp:239] Iteration 9849 (0.84165 iter/s, 58.219s/49 iters), loss = 0.00418164
I0526 15:08:56.116892 10701 solver.cpp:258]     Train net output #0: loss = 0.00162549 (* 1 = 0.00162549 loss)
I0526 15:08:56.116911 10701 sgd_solver.cpp:112] Iteration 9849, lr = 0.005
I0526 15:09:55.687686 10701 solver.cpp:239] Iteration 9898 (0.822562 iter/s, 59.57s/49 iters), loss = 0.0107895
I0526 15:09:55.687888 10701 solver.cpp:258]     Train net output #0: loss = 0.000540689 (* 1 = 0.000540689 loss)
I0526 15:09:55.687911 10701 sgd_solver.cpp:112] Iteration 9898, lr = 0.005
I0526 15:10:54.659801 10701 solver.cpp:239] Iteration 9947 (0.830917 iter/s, 58.971s/49 iters), loss = 0.00418488
I0526 15:10:54.659981 10701 solver.cpp:258]     Train net output #0: loss = 0.00895921 (* 1 = 0.00895921 loss)
I0526 15:10:54.660018 10701 sgd_solver.cpp:112] Iteration 9947, lr = 0.005
I0526 15:11:53.957275 10701 solver.cpp:239] Iteration 9996 (0.826349 iter/s, 59.297s/49 iters), loss = 0.00890464
I0526 15:11:53.957461 10701 solver.cpp:258]     Train net output #0: loss = 0.0376474 (* 1 = 0.0376474 loss)
I0526 15:11:53.957513 10701 sgd_solver.cpp:112] Iteration 9996, lr = 0.005
I0526 15:12:53.439273 10701 solver.cpp:239] Iteration 10045 (0.823792 iter/s, 59.481s/49 iters), loss = 0.00920348
I0526 15:12:53.439427 10701 solver.cpp:258]     Train net output #0: loss = 0.00863738 (* 1 = 0.00863738 loss)
I0526 15:12:53.439445 10701 sgd_solver.cpp:112] Iteration 10045, lr = 0.005
I0526 15:13:51.707432 10701 solver.cpp:239] Iteration 10094 (0.840942 iter/s, 58.268s/49 iters), loss = 0.00891373
I0526 15:13:51.707595 10701 solver.cpp:258]     Train net output #0: loss = 0.0079906 (* 1 = 0.0079906 loss)
I0526 15:13:51.707650 10701 sgd_solver.cpp:112] Iteration 10094, lr = 0.005
I0526 15:14:55.065099 10701 solver.cpp:239] Iteration 10143 (0.773395 iter/s, 63.357s/49 iters), loss = 0.00755139
I0526 15:14:55.065268 10701 solver.cpp:258]     Train net output #0: loss = 0.0137786 (* 1 = 0.0137786 loss)
I0526 15:14:55.065286 10701 sgd_solver.cpp:112] Iteration 10143, lr = 0.005
I0526 15:15:55.091523 10701 solver.cpp:239] Iteration 10192 (0.816313 iter/s, 60.026s/49 iters), loss = 0.00733784
I0526 15:15:55.091805 10701 solver.cpp:258]     Train net output #0: loss = 0.035122 (* 1 = 0.035122 loss)
I0526 15:15:55.091831 10701 sgd_solver.cpp:112] Iteration 10192, lr = 0.005
I0526 15:16:54.124258 10701 solver.cpp:239] Iteration 10241 (0.830058 iter/s, 59.032s/49 iters), loss = 0.00427078
I0526 15:16:54.124456 10701 solver.cpp:258]     Train net output #0: loss = 0.00879812 (* 1 = 0.00879812 loss)
I0526 15:16:54.124493 10701 sgd_solver.cpp:112] Iteration 10241, lr = 0.005
I0526 15:17:52.436136 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_10290.caffemodel
I0526 15:17:52.437474 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_10290.solverstate
I0526 15:17:52.438076 10701 solver.cpp:347] Iteration 10290, Testing net (#0)
I0526 15:18:14.783252 10701 solver.cpp:414]     Test net output #0: accuracy = 0.9284
I0526 15:18:14.783298 10701 solver.cpp:414]     Test net output #1: loss = 0.220215 (* 1 = 0.220215 loss)
I0526 15:18:14.783308 10701 solver.cpp:347] Iteration 10290, Testing net (#1)
I0526 15:18:55.592278 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998723
I0526 15:18:55.592414 10701 solver.cpp:414]     Test net output #1: loss = 0.00507045 (* 1 = 0.00507045 loss)
I0526 15:18:55.592430 10701 solver.cpp:347] Iteration 10290, Testing net (#2)
I0526 15:20:30.786451 10701 solver.cpp:414]     Test net output #0: accuracy = 0.924144
I0526 15:20:30.786584 10701 solver.cpp:414]     Test net output #1: loss = 0.182876 (* 1 = 0.182876 loss)
I0526 15:20:31.960722 10701 solver.cpp:239] Iteration 10290 (0.22494 iter/s, 217.836s/49 iters), loss = 0.00779946
I0526 15:20:31.960767 10701 solver.cpp:258]     Train net output #0: loss = 0.00341001 (* 1 = 0.00341001 loss)
I0526 15:20:31.960775 10701 sgd_solver.cpp:112] Iteration 10290, lr = 0.005
I0526 15:21:32.019862 10701 solver.cpp:239] Iteration 10339 (0.815864 iter/s, 60.059s/49 iters), loss = 0.00366032
I0526 15:21:32.020066 10701 solver.cpp:258]     Train net output #0: loss = 0.000768598 (* 1 = 0.000768598 loss)
I0526 15:21:32.020088 10701 sgd_solver.cpp:112] Iteration 10339, lr = 0.005
I0526 15:22:31.577216 10701 solver.cpp:239] Iteration 10388 (0.822741 iter/s, 59.557s/49 iters), loss = 0.00720703
I0526 15:22:31.577387 10701 solver.cpp:258]     Train net output #0: loss = 0.00851648 (* 1 = 0.00851648 loss)
I0526 15:22:31.577423 10701 sgd_solver.cpp:112] Iteration 10388, lr = 0.005
I0526 15:23:30.484158 10701 solver.cpp:239] Iteration 10437 (0.831834 iter/s, 58.906s/49 iters), loss = 0.00805713
I0526 15:23:30.484395 10701 solver.cpp:258]     Train net output #0: loss = 0.000428936 (* 1 = 0.000428936 loss)
I0526 15:23:30.484419 10701 sgd_solver.cpp:112] Iteration 10437, lr = 0.005
I0526 15:24:28.444618 10701 solver.cpp:239] Iteration 10486 (0.845411 iter/s, 57.96s/49 iters), loss = 0.0109622
I0526 15:24:28.444772 10701 solver.cpp:258]     Train net output #0: loss = 0.00395003 (* 1 = 0.00395003 loss)
I0526 15:24:28.444792 10701 sgd_solver.cpp:112] Iteration 10486, lr = 0.005
I0526 15:25:26.605304 10701 solver.cpp:239] Iteration 10535 (0.842503 iter/s, 58.16s/49 iters), loss = 0.0075802
I0526 15:25:26.605453 10701 solver.cpp:258]     Train net output #0: loss = 0.000746588 (* 1 = 0.000746588 loss)
I0526 15:25:26.605470 10701 sgd_solver.cpp:112] Iteration 10535, lr = 0.005
I0526 15:26:24.363420 10701 solver.cpp:239] Iteration 10584 (0.848382 iter/s, 57.757s/49 iters), loss = 0.00554096
I0526 15:26:24.363585 10701 solver.cpp:258]     Train net output #0: loss = 0.000603435 (* 1 = 0.000603435 loss)
I0526 15:26:24.363606 10701 sgd_solver.cpp:112] Iteration 10584, lr = 0.005
I0526 15:27:24.160284 10701 solver.cpp:239] Iteration 10633 (0.819453 iter/s, 59.796s/49 iters), loss = 0.00886038
I0526 15:27:24.160486 10701 solver.cpp:258]     Train net output #0: loss = 0.00257779 (* 1 = 0.00257779 loss)
I0526 15:27:24.160526 10701 sgd_solver.cpp:112] Iteration 10633, lr = 0.005
I0526 15:28:19.279909 10701 solver.cpp:239] Iteration 10682 (0.888986 iter/s, 55.119s/49 iters), loss = 0.00516492
I0526 15:28:19.280092 10701 solver.cpp:258]     Train net output #0: loss = 0.00946751 (* 1 = 0.00946751 loss)
I0526 15:28:19.280103 10701 sgd_solver.cpp:112] Iteration 10682, lr = 0.005
I0526 15:28:53.752238 10701 solver.cpp:239] Iteration 10731 (1.42144 iter/s, 34.472s/49 iters), loss = 0.00428127
I0526 15:28:53.752408 10701 solver.cpp:258]     Train net output #0: loss = 0.00171843 (* 1 = 0.00171843 loss)
I0526 15:28:53.752420 10701 sgd_solver.cpp:112] Iteration 10731, lr = 0.005
I0526 15:29:32.122306 10701 solver.cpp:239] Iteration 10780 (1.27707 iter/s, 38.369s/49 iters), loss = 0.00752501
I0526 15:29:32.122584 10701 solver.cpp:258]     Train net output #0: loss = 0.00125645 (* 1 = 0.00125645 loss)
I0526 15:29:32.122596 10701 sgd_solver.cpp:112] Iteration 10780, lr = 0.005
I0526 15:30:04.636864 10701 solver.cpp:239] Iteration 10829 (1.50704 iter/s, 32.514s/49 iters), loss = 0.00576524
I0526 15:30:04.637019 10701 solver.cpp:258]     Train net output #0: loss = 0.0222768 (* 1 = 0.0222768 loss)
I0526 15:30:04.637032 10701 sgd_solver.cpp:112] Iteration 10829, lr = 0.005
I0526 15:30:36.933410 10701 solver.cpp:239] Iteration 10878 (1.51722 iter/s, 32.296s/49 iters), loss = 0.00525435
I0526 15:30:36.933552 10701 solver.cpp:258]     Train net output #0: loss = 0.000788397 (* 1 = 0.000788397 loss)
I0526 15:30:36.933562 10701 sgd_solver.cpp:112] Iteration 10878, lr = 0.005
I0526 15:31:09.619170 10701 solver.cpp:239] Iteration 10927 (1.49916 iter/s, 32.685s/49 iters), loss = 0.00528234
I0526 15:31:09.619323 10701 solver.cpp:258]     Train net output #0: loss = 0.00502526 (* 1 = 0.00502526 loss)
I0526 15:31:09.619333 10701 sgd_solver.cpp:112] Iteration 10927, lr = 0.005
I0526 15:31:42.155911 10701 solver.cpp:239] Iteration 10976 (1.50602 iter/s, 32.536s/49 iters), loss = 0.0071948
I0526 15:31:42.156109 10701 solver.cpp:258]     Train net output #0: loss = 0.00488471 (* 1 = 0.00488471 loss)
I0526 15:31:42.156119 10701 sgd_solver.cpp:112] Iteration 10976, lr = 0.005
I0526 15:32:13.431200 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_11025.caffemodel
I0526 15:32:13.432092 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_11025.solverstate
I0526 15:32:13.432428 10701 solver.cpp:347] Iteration 11025, Testing net (#0)
I0526 15:32:25.276762 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8692
I0526 15:32:25.276799 10701 solver.cpp:414]     Test net output #1: loss = 0.335214 (* 1 = 0.335214 loss)
I0526 15:32:25.276805 10701 solver.cpp:347] Iteration 11025, Testing net (#1)
I0526 15:32:47.224869 10701 solver.cpp:414]     Test net output #0: accuracy = 0.996809
I0526 15:32:47.225100 10701 solver.cpp:414]     Test net output #1: loss = 0.0104882 (* 1 = 0.0104882 loss)
I0526 15:32:47.225116 10701 solver.cpp:347] Iteration 11025, Testing net (#2)
I0526 15:33:37.640846 10701 solver.cpp:414]     Test net output #0: accuracy = 0.882883
I0526 15:33:37.641059 10701 solver.cpp:414]     Test net output #1: loss = 0.299113 (* 1 = 0.299113 loss)
I0526 15:33:38.282392 10701 solver.cpp:239] Iteration 11025 (0.421955 iter/s, 116.126s/49 iters), loss = 0.0101212
I0526 15:33:38.282443 10701 solver.cpp:258]     Train net output #0: loss = 0.00922885 (* 1 = 0.00922885 loss)
I0526 15:33:38.282454 10701 sgd_solver.cpp:112] Iteration 11025, lr = 0.005
I0526 15:34:09.366021 10701 solver.cpp:239] Iteration 11074 (1.57642 iter/s, 31.083s/49 iters), loss = 0.0100864
I0526 15:34:09.366250 10701 solver.cpp:258]     Train net output #0: loss = 0.00369284 (* 1 = 0.00369284 loss)
I0526 15:34:09.366266 10701 sgd_solver.cpp:112] Iteration 11074, lr = 0.005
I0526 15:34:40.437788 10701 solver.cpp:239] Iteration 11123 (1.57703 iter/s, 31.071s/49 iters), loss = 0.0158976
I0526 15:34:40.438000 10701 solver.cpp:258]     Train net output #0: loss = 0.00196687 (* 1 = 0.00196687 loss)
I0526 15:34:40.438016 10701 sgd_solver.cpp:112] Iteration 11123, lr = 0.005
I0526 15:35:11.513455 10701 solver.cpp:239] Iteration 11172 (1.57683 iter/s, 31.075s/49 iters), loss = 0.00979781
I0526 15:35:11.513614 10701 solver.cpp:258]     Train net output #0: loss = 0.000865423 (* 1 = 0.000865423 loss)
I0526 15:35:11.513628 10701 sgd_solver.cpp:112] Iteration 11172, lr = 0.005
I0526 15:35:42.581383 10701 solver.cpp:239] Iteration 11221 (1.57724 iter/s, 31.067s/49 iters), loss = 0.00510909
I0526 15:35:42.581621 10701 solver.cpp:258]     Train net output #0: loss = 0.00519096 (* 1 = 0.00519096 loss)
I0526 15:35:42.581640 10701 sgd_solver.cpp:112] Iteration 11221, lr = 0.005
I0526 15:36:13.652055 10701 solver.cpp:239] Iteration 11270 (1.57708 iter/s, 31.07s/49 iters), loss = 0.00527641
I0526 15:36:13.652235 10701 solver.cpp:258]     Train net output #0: loss = 0.000648754 (* 1 = 0.000648754 loss)
I0526 15:36:13.652253 10701 sgd_solver.cpp:112] Iteration 11270, lr = 0.005
I0526 15:36:44.841338 10701 solver.cpp:239] Iteration 11319 (1.57107 iter/s, 31.189s/49 iters), loss = 0.00644091
I0526 15:36:44.841521 10701 solver.cpp:258]     Train net output #0: loss = 0.000739384 (* 1 = 0.000739384 loss)
I0526 15:36:44.841539 10701 sgd_solver.cpp:112] Iteration 11319, lr = 0.005
I0526 15:37:15.920136 10701 solver.cpp:239] Iteration 11368 (1.57668 iter/s, 31.078s/49 iters), loss = 0.00786899
I0526 15:37:15.920313 10701 solver.cpp:258]     Train net output #0: loss = 0.00675245 (* 1 = 0.00675245 loss)
I0526 15:37:15.920328 10701 sgd_solver.cpp:112] Iteration 11368, lr = 0.005
I0526 15:37:46.995600 10701 solver.cpp:239] Iteration 11417 (1.57683 iter/s, 31.075s/49 iters), loss = 0.00955181
I0526 15:37:46.995782 10701 solver.cpp:258]     Train net output #0: loss = 0.0019546 (* 1 = 0.0019546 loss)
I0526 15:37:46.995797 10701 sgd_solver.cpp:112] Iteration 11417, lr = 0.005
I0526 15:38:18.046809 10701 solver.cpp:239] Iteration 11466 (1.57805 iter/s, 31.051s/49 iters), loss = 0.0170056
I0526 15:38:18.046990 10701 solver.cpp:258]     Train net output #0: loss = 0.0011723 (* 1 = 0.0011723 loss)
I0526 15:38:18.047004 10701 sgd_solver.cpp:112] Iteration 11466, lr = 0.005
I0526 15:38:49.115447 10701 solver.cpp:239] Iteration 11515 (1.57719 iter/s, 31.068s/49 iters), loss = 0.00847828
I0526 15:38:49.115626 10701 solver.cpp:258]     Train net output #0: loss = 0.00159853 (* 1 = 0.00159853 loss)
I0526 15:38:49.115641 10701 sgd_solver.cpp:112] Iteration 11515, lr = 0.005
I0526 15:39:20.175945 10701 solver.cpp:239] Iteration 11564 (1.57759 iter/s, 31.06s/49 iters), loss = 0.0105422
I0526 15:39:20.176126 10701 solver.cpp:258]     Train net output #0: loss = 0.0520198 (* 1 = 0.0520198 loss)
I0526 15:39:20.176142 10701 sgd_solver.cpp:112] Iteration 11564, lr = 0.005
I0526 15:39:51.252120 10701 solver.cpp:239] Iteration 11613 (1.57678 iter/s, 31.076s/49 iters), loss = 0.0118003
I0526 15:39:51.252296 10701 solver.cpp:258]     Train net output #0: loss = 0.00248179 (* 1 = 0.00248179 loss)
I0526 15:39:51.252311 10701 sgd_solver.cpp:112] Iteration 11613, lr = 0.005
I0526 15:40:22.312420 10701 solver.cpp:239] Iteration 11662 (1.57759 iter/s, 31.06s/49 iters), loss = 0.00851276
I0526 15:40:22.312592 10701 solver.cpp:258]     Train net output #0: loss = 0.00109592 (* 1 = 0.00109592 loss)
I0526 15:40:22.312608 10701 sgd_solver.cpp:112] Iteration 11662, lr = 0.005
I0526 15:40:53.351860 10701 solver.cpp:239] Iteration 11711 (1.57866 iter/s, 31.039s/49 iters), loss = 0.00761073
I0526 15:40:53.352031 10701 solver.cpp:258]     Train net output #0: loss = 0.00448292 (* 1 = 0.00448292 loss)
I0526 15:40:53.352047 10701 sgd_solver.cpp:112] Iteration 11711, lr = 0.005
I0526 15:41:23.778667 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_11760.caffemodel
I0526 15:41:23.779507 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_11760.solverstate
I0526 15:41:23.779824 10701 solver.cpp:347] Iteration 11760, Testing net (#0)
I0526 15:41:35.404105 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8424
I0526 15:41:35.404152 10701 solver.cpp:414]     Test net output #1: loss = 0.457405 (* 1 = 0.457405 loss)
I0526 15:41:35.404161 10701 solver.cpp:347] Iteration 11760, Testing net (#1)
I0526 15:41:57.397634 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998298
I0526 15:41:57.397846 10701 solver.cpp:414]     Test net output #1: loss = 0.00567963 (* 1 = 0.00567963 loss)
I0526 15:41:57.397862 10701 solver.cpp:347] Iteration 11760, Testing net (#2)
I0526 15:42:49.115550 10701 solver.cpp:414]     Test net output #0: accuracy = 0.892522
I0526 15:42:49.115700 10701 solver.cpp:414]     Test net output #1: loss = 0.273162 (* 1 = 0.273162 loss)
I0526 15:42:49.749334 10701 solver.cpp:239] Iteration 11760 (0.420973 iter/s, 116.397s/49 iters), loss = 0.00755784
I0526 15:42:49.749382 10701 solver.cpp:258]     Train net output #0: loss = 0.00155501 (* 1 = 0.00155501 loss)
I0526 15:42:49.749392 10701 sgd_solver.cpp:112] Iteration 11760, lr = 0.005
I0526 15:43:20.821055 10701 solver.cpp:239] Iteration 11809 (1.57703 iter/s, 31.071s/49 iters), loss = 0.00842685
I0526 15:43:20.821249 10701 solver.cpp:258]     Train net output #0: loss = 0.0013669 (* 1 = 0.0013669 loss)
I0526 15:43:20.821264 10701 sgd_solver.cpp:112] Iteration 11809, lr = 0.005
I0526 15:43:51.877622 10701 solver.cpp:239] Iteration 11858 (1.57779 iter/s, 31.056s/49 iters), loss = 0.00963372
I0526 15:43:51.877812 10701 solver.cpp:258]     Train net output #0: loss = 0.00466403 (* 1 = 0.00466403 loss)
I0526 15:43:51.877826 10701 sgd_solver.cpp:112] Iteration 11858, lr = 0.005
I0526 15:44:22.905388 10701 solver.cpp:239] Iteration 11907 (1.57927 iter/s, 31.027s/49 iters), loss = 0.00645892
I0526 15:44:22.905624 10701 solver.cpp:258]     Train net output #0: loss = 0.000318516 (* 1 = 0.000318516 loss)
I0526 15:44:22.905642 10701 sgd_solver.cpp:112] Iteration 11907, lr = 0.005
I0526 15:44:53.976658 10701 solver.cpp:239] Iteration 11956 (1.57703 iter/s, 31.071s/49 iters), loss = 0.00738193
I0526 15:44:53.976840 10701 solver.cpp:258]     Train net output #0: loss = 0.00185815 (* 1 = 0.00185815 loss)
I0526 15:44:53.976855 10701 sgd_solver.cpp:112] Iteration 11956, lr = 0.005
I0526 15:45:25.050511 10701 solver.cpp:239] Iteration 12005 (1.57693 iter/s, 31.073s/49 iters), loss = 0.00894551
I0526 15:45:25.050678 10701 solver.cpp:258]     Train net output #0: loss = 0.000744976 (* 1 = 0.000744976 loss)
I0526 15:45:25.050693 10701 sgd_solver.cpp:112] Iteration 12005, lr = 0.005
I0526 15:45:56.508556 10701 solver.cpp:239] Iteration 12054 (1.55768 iter/s, 31.457s/49 iters), loss = 0.00805275
I0526 15:45:56.508752 10701 solver.cpp:258]     Train net output #0: loss = 0.00068863 (* 1 = 0.00068863 loss)
I0526 15:45:56.508765 10701 sgd_solver.cpp:112] Iteration 12054, lr = 0.005
I0526 15:46:27.598017 10701 solver.cpp:239] Iteration 12103 (1.57612 iter/s, 31.089s/49 iters), loss = 0.00239797
I0526 15:46:27.598151 10701 solver.cpp:258]     Train net output #0: loss = 0.000767715 (* 1 = 0.000767715 loss)
I0526 15:46:27.598170 10701 sgd_solver.cpp:112] Iteration 12103, lr = 0.005
I0526 15:46:59.060905 10701 solver.cpp:239] Iteration 12152 (1.55743 iter/s, 31.462s/49 iters), loss = 0.0080448
I0526 15:46:59.061151 10701 solver.cpp:258]     Train net output #0: loss = 0.00102562 (* 1 = 0.00102562 loss)
I0526 15:46:59.061162 10701 sgd_solver.cpp:112] Iteration 12152, lr = 0.005
I0526 15:47:30.499153 10701 solver.cpp:239] Iteration 12201 (1.55862 iter/s, 31.438s/49 iters), loss = 0.0114122
I0526 15:47:30.499393 10701 solver.cpp:258]     Train net output #0: loss = 0.000660576 (* 1 = 0.000660576 loss)
I0526 15:47:30.499403 10701 sgd_solver.cpp:112] Iteration 12201, lr = 0.005
I0526 15:48:01.929008 10701 solver.cpp:239] Iteration 12250 (1.55907 iter/s, 31.429s/49 iters), loss = 0.00493173
I0526 15:48:01.929234 10701 solver.cpp:258]     Train net output #0: loss = 0.000573488 (* 1 = 0.000573488 loss)
I0526 15:48:01.929244 10701 sgd_solver.cpp:112] Iteration 12250, lr = 0.005
I0526 15:48:33.399439 10701 solver.cpp:239] Iteration 12299 (1.55704 iter/s, 31.47s/49 iters), loss = 0.00611057
I0526 15:48:33.399648 10701 solver.cpp:258]     Train net output #0: loss = 0.00087255 (* 1 = 0.00087255 loss)
I0526 15:48:33.399658 10701 sgd_solver.cpp:112] Iteration 12299, lr = 0.005
I0526 15:49:04.845896 10701 solver.cpp:239] Iteration 12348 (1.55823 iter/s, 31.446s/49 iters), loss = 0.00756682
I0526 15:49:04.846129 10701 solver.cpp:258]     Train net output #0: loss = 0.000757519 (* 1 = 0.000757519 loss)
I0526 15:49:04.846140 10701 sgd_solver.cpp:112] Iteration 12348, lr = 0.005
I0526 15:49:36.329548 10701 solver.cpp:239] Iteration 12397 (1.5564 iter/s, 31.483s/49 iters), loss = 0.00472919
I0526 15:49:36.329738 10701 solver.cpp:258]     Train net output #0: loss = 0.00338493 (* 1 = 0.00338493 loss)
I0526 15:49:36.329747 10701 sgd_solver.cpp:112] Iteration 12397, lr = 0.005
I0526 15:50:07.779384 10701 solver.cpp:239] Iteration 12446 (1.55808 iter/s, 31.449s/49 iters), loss = 0.00642141
I0526 15:50:07.779546 10701 solver.cpp:258]     Train net output #0: loss = 0.00237052 (* 1 = 0.00237052 loss)
I0526 15:50:07.779556 10701 sgd_solver.cpp:112] Iteration 12446, lr = 0.005
I0526 15:50:38.589334 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_12495.caffemodel
I0526 15:50:38.590154 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_12495.solverstate
I0526 15:50:38.590481 10701 solver.cpp:347] Iteration 12495, Testing net (#0)
I0526 15:50:50.163062 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8828
I0526 15:50:50.163113 10701 solver.cpp:414]     Test net output #1: loss = 0.286762 (* 1 = 0.286762 loss)
I0526 15:50:50.163118 10701 solver.cpp:347] Iteration 12495, Testing net (#1)
I0526 15:51:12.046826 10701 solver.cpp:414]     Test net output #0: accuracy = 0.997447
I0526 15:51:12.047000 10701 solver.cpp:414]     Test net output #1: loss = 0.00744286 (* 1 = 0.00744286 loss)
I0526 15:51:12.047019 10701 solver.cpp:347] Iteration 12495, Testing net (#2)
I0526 15:52:02.746392 10701 solver.cpp:414]     Test net output #0: accuracy = 0.925406
I0526 15:52:02.746553 10701 solver.cpp:414]     Test net output #1: loss = 0.182085 (* 1 = 0.182085 loss)
I0526 15:52:03.390684 10701 solver.cpp:239] Iteration 12495 (0.423835 iter/s, 115.611s/49 iters), loss = 0.00568225
I0526 15:52:03.390739 10701 solver.cpp:258]     Train net output #0: loss = 0.000271632 (* 1 = 0.000271632 loss)
I0526 15:52:03.390748 10701 sgd_solver.cpp:112] Iteration 12495, lr = 0.005
I0526 15:52:34.884702 10701 solver.cpp:239] Iteration 12544 (1.5559 iter/s, 31.493s/49 iters), loss = 0.00687671
I0526 15:52:34.884889 10701 solver.cpp:258]     Train net output #0: loss = 0.00420625 (* 1 = 0.00420625 loss)
I0526 15:52:34.884898 10701 sgd_solver.cpp:112] Iteration 12544, lr = 0.005
I0526 15:53:06.371093 10701 solver.cpp:239] Iteration 12593 (1.55625 iter/s, 31.486s/49 iters), loss = 0.00208089
I0526 15:53:06.371268 10701 solver.cpp:258]     Train net output #0: loss = 0.00286108 (* 1 = 0.00286108 loss)
I0526 15:53:06.371289 10701 sgd_solver.cpp:112] Iteration 12593, lr = 0.005
I0526 15:53:37.876068 10701 solver.cpp:239] Iteration 12642 (1.55536 iter/s, 31.504s/49 iters), loss = 0.0110742
I0526 15:53:37.876204 10701 solver.cpp:258]     Train net output #0: loss = 0.000388745 (* 1 = 0.000388745 loss)
I0526 15:53:37.876230 10701 sgd_solver.cpp:112] Iteration 12642, lr = 0.005
I0526 15:54:09.364852 10701 solver.cpp:239] Iteration 12691 (1.55615 iter/s, 31.488s/49 iters), loss = 0.00891745
I0526 15:54:09.365041 10701 solver.cpp:258]     Train net output #0: loss = 0.0156684 (* 1 = 0.0156684 loss)
I0526 15:54:09.365049 10701 sgd_solver.cpp:112] Iteration 12691, lr = 0.005
I0526 15:54:40.639801 10701 solver.cpp:239] Iteration 12740 (1.5668 iter/s, 31.274s/49 iters), loss = 0.0074217
I0526 15:54:40.640028 10701 solver.cpp:258]     Train net output #0: loss = 0.00102471 (* 1 = 0.00102471 loss)
I0526 15:54:40.640039 10701 sgd_solver.cpp:112] Iteration 12740, lr = 0.005
I0526 15:55:12.180826 10701 solver.cpp:239] Iteration 12789 (1.55358 iter/s, 31.54s/49 iters), loss = 0.00579922
I0526 15:55:12.181030 10701 solver.cpp:258]     Train net output #0: loss = 0.00375472 (* 1 = 0.00375472 loss)
I0526 15:55:12.181043 10701 sgd_solver.cpp:112] Iteration 12789, lr = 0.005
I0526 15:55:43.804621 10701 solver.cpp:239] Iteration 12838 (1.54951 iter/s, 31.623s/49 iters), loss = 0.00973028
I0526 15:55:43.804786 10701 solver.cpp:258]     Train net output #0: loss = 0.018216 (* 1 = 0.018216 loss)
I0526 15:55:43.804796 10701 sgd_solver.cpp:112] Iteration 12838, lr = 0.005
I0526 15:56:15.832360 10701 solver.cpp:239] Iteration 12887 (1.52996 iter/s, 32.027s/49 iters), loss = 0.00648686
I0526 15:56:15.832547 10701 solver.cpp:258]     Train net output #0: loss = 0.00277002 (* 1 = 0.00277002 loss)
I0526 15:56:15.832557 10701 sgd_solver.cpp:112] Iteration 12887, lr = 0.005
I0526 15:56:47.892848 10701 solver.cpp:239] Iteration 12936 (1.52838 iter/s, 32.06s/49 iters), loss = 0.00804056
I0526 15:56:47.893025 10701 solver.cpp:258]     Train net output #0: loss = 0.00281195 (* 1 = 0.00281195 loss)
I0526 15:56:47.893036 10701 sgd_solver.cpp:112] Iteration 12936, lr = 0.005
I0526 15:57:22.138340 10701 solver.cpp:239] Iteration 12985 (1.43087 iter/s, 34.245s/49 iters), loss = 0.0142495
I0526 15:57:22.138571 10701 solver.cpp:258]     Train net output #0: loss = 0.00115578 (* 1 = 0.00115578 loss)
I0526 15:57:22.138581 10701 sgd_solver.cpp:112] Iteration 12985, lr = 0.005
I0526 15:57:53.503259 10701 solver.cpp:239] Iteration 13034 (1.5623 iter/s, 31.364s/49 iters), loss = 0.0102521
I0526 15:57:53.503512 10701 solver.cpp:258]     Train net output #0: loss = 0.000491577 (* 1 = 0.000491577 loss)
I0526 15:57:53.503522 10701 sgd_solver.cpp:112] Iteration 13034, lr = 0.005
I0526 15:58:24.554143 10701 solver.cpp:239] Iteration 13083 (1.5781 iter/s, 31.05s/49 iters), loss = 0.00420027
I0526 15:58:24.554397 10701 solver.cpp:258]     Train net output #0: loss = 0.00141562 (* 1 = 0.00141562 loss)
I0526 15:58:24.554409 10701 sgd_solver.cpp:112] Iteration 13083, lr = 0.005
I0526 15:58:55.622946 10701 solver.cpp:239] Iteration 13132 (1.57719 iter/s, 31.068s/49 iters), loss = 0.00523144
I0526 15:58:55.623189 10701 solver.cpp:258]     Train net output #0: loss = 0.000378809 (* 1 = 0.000378809 loss)
I0526 15:58:55.623199 10701 sgd_solver.cpp:112] Iteration 13132, lr = 0.005
I0526 15:59:27.030938 10701 solver.cpp:239] Iteration 13181 (1.56016 iter/s, 31.407s/49 iters), loss = 0.00722596
I0526 15:59:27.031138 10701 solver.cpp:258]     Train net output #0: loss = 0.0208867 (* 1 = 0.0208867 loss)
I0526 15:59:27.031150 10701 sgd_solver.cpp:112] Iteration 13181, lr = 0.005
I0526 15:59:57.992532 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_13230.caffemodel
I0526 15:59:57.993495 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_13230.solverstate
I0526 15:59:57.993839 10701 solver.cpp:347] Iteration 13230, Testing net (#0)
I0526 16:00:09.840544 10701 solver.cpp:414]     Test net output #0: accuracy = 0.7932
I0526 16:00:09.840596 10701 solver.cpp:414]     Test net output #1: loss = 0.556133 (* 1 = 0.556133 loss)
I0526 16:00:09.840602 10701 solver.cpp:347] Iteration 13230, Testing net (#1)
I0526 16:00:32.055217 10701 solver.cpp:414]     Test net output #0: accuracy = 0.999149
I0526 16:00:32.055438 10701 solver.cpp:414]     Test net output #1: loss = 0.00374406 (* 1 = 0.00374406 loss)
I0526 16:00:32.055449 10701 solver.cpp:347] Iteration 13230, Testing net (#2)
I0526 16:01:23.196732 10701 solver.cpp:414]     Test net output #0: accuracy = 0.862793
I0526 16:01:23.196933 10701 solver.cpp:414]     Test net output #1: loss = 0.370261 (* 1 = 0.370261 loss)
I0526 16:01:23.848671 10701 solver.cpp:239] Iteration 13230 (0.419459 iter/s, 116.817s/49 iters), loss = 0.00805491
I0526 16:01:23.848727 10701 solver.cpp:258]     Train net output #0: loss = 0.00074411 (* 1 = 0.00074411 loss)
I0526 16:01:23.848735 10701 sgd_solver.cpp:112] Iteration 13230, lr = 0.005
I0526 16:01:55.500066 10701 solver.cpp:239] Iteration 13279 (1.54813 iter/s, 31.651s/49 iters), loss = 0.0118455
I0526 16:01:55.500211 10701 solver.cpp:258]     Train net output #0: loss = 0.00144615 (* 1 = 0.00144615 loss)
I0526 16:01:55.500221 10701 sgd_solver.cpp:112] Iteration 13279, lr = 0.005
I0526 16:02:27.035826 10701 solver.cpp:239] Iteration 13328 (1.55383 iter/s, 31.535s/49 iters), loss = 0.00635814
I0526 16:02:27.036010 10701 solver.cpp:258]     Train net output #0: loss = 0.00140563 (* 1 = 0.00140563 loss)
I0526 16:02:27.036018 10701 sgd_solver.cpp:112] Iteration 13328, lr = 0.005
I0526 16:02:58.635766 10701 solver.cpp:239] Iteration 13377 (1.55068 iter/s, 31.599s/49 iters), loss = 0.0110062
I0526 16:02:58.635954 10701 solver.cpp:258]     Train net output #0: loss = 0.0178244 (* 1 = 0.0178244 loss)
I0526 16:02:58.635974 10701 sgd_solver.cpp:112] Iteration 13377, lr = 0.005
I0526 16:03:30.157127 10701 solver.cpp:239] Iteration 13426 (1.55452 iter/s, 31.521s/49 iters), loss = 0.00760725
I0526 16:03:30.157346 10701 solver.cpp:258]     Train net output #0: loss = 0.0372699 (* 1 = 0.0372699 loss)
I0526 16:03:30.157356 10701 sgd_solver.cpp:112] Iteration 13426, lr = 0.005
I0526 16:04:01.615631 10701 solver.cpp:239] Iteration 13475 (1.55763 iter/s, 31.458s/49 iters), loss = 0.00541169
I0526 16:04:01.615828 10701 solver.cpp:258]     Train net output #0: loss = 0.0205028 (* 1 = 0.0205028 loss)
I0526 16:04:01.615837 10701 sgd_solver.cpp:112] Iteration 13475, lr = 0.005
I0526 16:04:33.125376 10701 solver.cpp:239] Iteration 13524 (1.55511 iter/s, 31.509s/49 iters), loss = 0.00750291
I0526 16:04:33.125583 10701 solver.cpp:258]     Train net output #0: loss = 0.00297516 (* 1 = 0.00297516 loss)
I0526 16:04:33.125593 10701 sgd_solver.cpp:112] Iteration 13524, lr = 0.005
I0526 16:05:05.800380 10701 solver.cpp:239] Iteration 13573 (1.49966 iter/s, 32.674s/49 iters), loss = 0.00312802
I0526 16:05:05.800545 10701 solver.cpp:258]     Train net output #0: loss = 0.00841127 (* 1 = 0.00841127 loss)
I0526 16:05:05.800555 10701 sgd_solver.cpp:112] Iteration 13573, lr = 0.005
I0526 16:05:38.066568 10701 solver.cpp:239] Iteration 13622 (1.51863 iter/s, 32.266s/49 iters), loss = 0.00301753
I0526 16:05:38.066701 10701 solver.cpp:258]     Train net output #0: loss = 0.000320273 (* 1 = 0.000320273 loss)
I0526 16:05:38.066712 10701 sgd_solver.cpp:112] Iteration 13622, lr = 0.005
I0526 16:06:10.809865 10701 solver.cpp:239] Iteration 13671 (1.4965 iter/s, 32.743s/49 iters), loss = 0.00990832
I0526 16:06:10.810015 10701 solver.cpp:258]     Train net output #0: loss = 0.00160294 (* 1 = 0.00160294 loss)
I0526 16:06:10.810025 10701 sgd_solver.cpp:112] Iteration 13671, lr = 0.005
I0526 16:06:42.492849 10701 solver.cpp:239] Iteration 13720 (1.54662 iter/s, 31.682s/49 iters), loss = 0.00564305
I0526 16:06:42.493055 10701 solver.cpp:258]     Train net output #0: loss = 0.00753545 (* 1 = 0.00753545 loss)
I0526 16:06:42.493065 10701 sgd_solver.cpp:112] Iteration 13720, lr = 0.005
I0526 16:07:13.961805 10701 solver.cpp:239] Iteration 13769 (1.55714 iter/s, 31.468s/49 iters), loss = 0.0100816
I0526 16:07:13.961944 10701 solver.cpp:258]     Train net output #0: loss = 0.00594156 (* 1 = 0.00594156 loss)
I0526 16:07:13.961967 10701 sgd_solver.cpp:112] Iteration 13769, lr = 0.005
I0526 16:07:45.513813 10701 solver.cpp:239] Iteration 13818 (1.55304 iter/s, 31.551s/49 iters), loss = 0.00739261
I0526 16:07:45.514047 10701 solver.cpp:258]     Train net output #0: loss = 0.000807538 (* 1 = 0.000807538 loss)
I0526 16:07:45.514057 10701 sgd_solver.cpp:112] Iteration 13818, lr = 0.005
I0526 16:08:16.727684 10701 solver.cpp:239] Iteration 13867 (1.56986 iter/s, 31.213s/49 iters), loss = 0.00788071
I0526 16:08:16.727926 10701 solver.cpp:258]     Train net output #0: loss = 0.000989806 (* 1 = 0.000989806 loss)
I0526 16:08:16.727936 10701 sgd_solver.cpp:112] Iteration 13867, lr = 0.005
I0526 16:08:48.053373 10701 solver.cpp:239] Iteration 13916 (1.56425 iter/s, 31.325s/49 iters), loss = 0.00832879
I0526 16:08:48.053532 10701 solver.cpp:258]     Train net output #0: loss = 0.00494341 (* 1 = 0.00494341 loss)
I0526 16:08:48.053541 10701 sgd_solver.cpp:112] Iteration 13916, lr = 0.005
I0526 16:09:18.775737 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_13965.caffemodel
I0526 16:09:18.776620 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_13965.solverstate
I0526 16:09:18.776949 10701 solver.cpp:347] Iteration 13965, Testing net (#0)
I0526 16:09:30.330651 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8736
I0526 16:09:30.330699 10701 solver.cpp:414]     Test net output #1: loss = 0.323471 (* 1 = 0.323471 loss)
I0526 16:09:30.330704 10701 solver.cpp:347] Iteration 13965, Testing net (#1)
I0526 16:09:52.296916 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998936
I0526 16:09:52.297114 10701 solver.cpp:414]     Test net output #1: loss = 0.005166 (* 1 = 0.005166 loss)
I0526 16:09:52.297134 10701 solver.cpp:347] Iteration 13965, Testing net (#2)
I0526 16:10:42.862047 10701 solver.cpp:414]     Test net output #0: accuracy = 0.925406
I0526 16:10:42.862236 10701 solver.cpp:414]     Test net output #1: loss = 0.186313 (* 1 = 0.186313 loss)
I0526 16:10:43.498064 10701 solver.cpp:239] Iteration 13965 (0.424448 iter/s, 115.444s/49 iters), loss = 0.00735756
I0526 16:10:43.498121 10701 solver.cpp:258]     Train net output #0: loss = 0.000560348 (* 1 = 0.000560348 loss)
I0526 16:10:43.498129 10701 sgd_solver.cpp:112] Iteration 13965, lr = 0.005
I0526 16:11:14.724515 10701 solver.cpp:239] Iteration 14014 (1.56921 iter/s, 31.226s/49 iters), loss = 0.00352003
I0526 16:11:14.724743 10701 solver.cpp:258]     Train net output #0: loss = 0.000933937 (* 1 = 0.000933937 loss)
I0526 16:11:14.724754 10701 sgd_solver.cpp:112] Iteration 14014, lr = 0.005
I0526 16:11:46.381788 10701 solver.cpp:239] Iteration 14063 (1.54784 iter/s, 31.657s/49 iters), loss = 0.00934653
I0526 16:11:46.382002 10701 solver.cpp:258]     Train net output #0: loss = 0.000295068 (* 1 = 0.000295068 loss)
I0526 16:11:46.382016 10701 sgd_solver.cpp:112] Iteration 14063, lr = 0.005
I0526 16:12:17.978305 10701 solver.cpp:239] Iteration 14112 (1.55083 iter/s, 31.596s/49 iters), loss = 0.00435226
I0526 16:12:17.978524 10701 solver.cpp:258]     Train net output #0: loss = 0.000533795 (* 1 = 0.000533795 loss)
I0526 16:12:17.978534 10701 sgd_solver.cpp:112] Iteration 14112, lr = 0.005
I0526 16:12:49.531494 10701 solver.cpp:239] Iteration 14161 (1.55299 iter/s, 31.552s/49 iters), loss = 0.0152299
I0526 16:12:49.531682 10701 solver.cpp:258]     Train net output #0: loss = 0.0259604 (* 1 = 0.0259604 loss)
I0526 16:12:49.531692 10701 sgd_solver.cpp:112] Iteration 14161, lr = 0.005
I0526 16:13:21.024214 10701 solver.cpp:239] Iteration 14210 (1.55595 iter/s, 31.492s/49 iters), loss = 0.00930055
I0526 16:13:21.024399 10701 solver.cpp:258]     Train net output #0: loss = 0.000763785 (* 1 = 0.000763785 loss)
I0526 16:13:21.024410 10701 sgd_solver.cpp:112] Iteration 14210, lr = 0.005
I0526 16:13:52.440825 10701 solver.cpp:239] Iteration 14259 (1.55971 iter/s, 31.416s/49 iters), loss = 0.00707344
I0526 16:13:52.441089 10701 solver.cpp:258]     Train net output #0: loss = 0.000545857 (* 1 = 0.000545857 loss)
I0526 16:13:52.441099 10701 sgd_solver.cpp:112] Iteration 14259, lr = 0.005
I0526 16:14:24.000669 10701 solver.cpp:239] Iteration 14308 (1.55265 iter/s, 31.559s/49 iters), loss = 0.00806084
I0526 16:14:24.000857 10701 solver.cpp:258]     Train net output #0: loss = 0.000678934 (* 1 = 0.000678934 loss)
I0526 16:14:24.000867 10701 sgd_solver.cpp:112] Iteration 14308, lr = 0.005
I0526 16:14:55.397814 10701 solver.cpp:239] Iteration 14357 (1.56071 iter/s, 31.396s/49 iters), loss = 0.00369534
I0526 16:14:55.397986 10701 solver.cpp:258]     Train net output #0: loss = 0.000874503 (* 1 = 0.000874503 loss)
I0526 16:14:55.397995 10701 sgd_solver.cpp:112] Iteration 14357, lr = 0.005
I0526 16:15:26.947899 10701 solver.cpp:239] Iteration 14406 (1.55314 iter/s, 31.549s/49 iters), loss = 0.0149156
I0526 16:15:26.948146 10701 solver.cpp:258]     Train net output #0: loss = 0.00196024 (* 1 = 0.00196024 loss)
I0526 16:15:26.948158 10701 sgd_solver.cpp:112] Iteration 14406, lr = 0.005
I0526 16:15:58.132787 10701 solver.cpp:239] Iteration 14455 (1.57132 iter/s, 31.184s/49 iters), loss = 0.00377903
I0526 16:15:58.133041 10701 solver.cpp:258]     Train net output #0: loss = 0.000318365 (* 1 = 0.000318365 loss)
I0526 16:15:58.133054 10701 sgd_solver.cpp:112] Iteration 14455, lr = 0.005
I0526 16:16:29.697826 10701 solver.cpp:239] Iteration 14504 (1.5524 iter/s, 31.564s/49 iters), loss = 0.00248936
I0526 16:16:29.698051 10701 solver.cpp:258]     Train net output #0: loss = 0.000695084 (* 1 = 0.000695084 loss)
I0526 16:16:29.698062 10701 sgd_solver.cpp:112] Iteration 14504, lr = 0.005
I0526 16:17:01.408466 10701 solver.cpp:239] Iteration 14553 (1.54525 iter/s, 31.71s/49 iters), loss = 0.00845233
I0526 16:17:01.408670 10701 solver.cpp:258]     Train net output #0: loss = 0.0799864 (* 1 = 0.0799864 loss)
I0526 16:17:01.408691 10701 sgd_solver.cpp:112] Iteration 14553, lr = 0.005
I0526 16:17:33.001978 10701 solver.cpp:239] Iteration 14602 (1.55098 iter/s, 31.593s/49 iters), loss = 0.0105665
I0526 16:17:33.002207 10701 solver.cpp:258]     Train net output #0: loss = 0.0878538 (* 1 = 0.0878538 loss)
I0526 16:17:33.002216 10701 sgd_solver.cpp:112] Iteration 14602, lr = 0.005
I0526 16:18:04.403195 10701 solver.cpp:239] Iteration 14651 (1.56051 iter/s, 31.4s/49 iters), loss = 0.00599302
I0526 16:18:04.403414 10701 solver.cpp:258]     Train net output #0: loss = 0.000516564 (* 1 = 0.000516564 loss)
I0526 16:18:04.403424 10701 sgd_solver.cpp:112] Iteration 14651, lr = 0.005
I0526 16:18:35.258529 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_14700.caffemodel
I0526 16:18:35.259436 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_14700.solverstate
I0526 16:18:35.259770 10701 solver.cpp:347] Iteration 14700, Testing net (#0)
I0526 16:18:46.860061 10701 solver.cpp:414]     Test net output #0: accuracy = 0.7756
I0526 16:18:46.860107 10701 solver.cpp:414]     Test net output #1: loss = 0.704485 (* 1 = 0.704485 loss)
I0526 16:18:46.860113 10701 solver.cpp:347] Iteration 14700, Testing net (#1)
I0526 16:19:08.835836 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998936
I0526 16:19:08.836086 10701 solver.cpp:414]     Test net output #1: loss = 0.00379704 (* 1 = 0.00379704 loss)
I0526 16:19:08.836095 10701 solver.cpp:347] Iteration 14700, Testing net (#2)
I0526 16:19:59.530938 10701 solver.cpp:414]     Test net output #0: accuracy = 0.811892
I0526 16:19:59.531154 10701 solver.cpp:414]     Test net output #1: loss = 0.542486 (* 1 = 0.542486 loss)
I0526 16:20:00.175590 10701 solver.cpp:239] Iteration 14700 (0.423246 iter/s, 115.772s/49 iters), loss = 0.00877865
I0526 16:20:00.175642 10701 solver.cpp:258]     Train net output #0: loss = 0.000494508 (* 1 = 0.000494508 loss)
I0526 16:20:00.175650 10701 sgd_solver.cpp:112] Iteration 14700, lr = 0.005
I0526 16:20:31.742090 10701 solver.cpp:239] Iteration 14749 (1.5523 iter/s, 31.566s/49 iters), loss = 0.00356941
I0526 16:20:31.742316 10701 solver.cpp:258]     Train net output #0: loss = 0.0163707 (* 1 = 0.0163707 loss)
I0526 16:20:31.742327 10701 sgd_solver.cpp:112] Iteration 14749, lr = 0.005
I0526 16:21:06.198640 10701 solver.cpp:239] Iteration 14798 (1.4221 iter/s, 34.456s/49 iters), loss = 0.00632304
I0526 16:21:06.198890 10701 solver.cpp:258]     Train net output #0: loss = 0.0445144 (* 1 = 0.0445144 loss)
I0526 16:21:06.198920 10701 sgd_solver.cpp:112] Iteration 14798, lr = 0.005
I0526 16:21:38.030061 10701 solver.cpp:239] Iteration 14847 (1.53938 iter/s, 31.831s/49 iters), loss = 0.00992198
I0526 16:21:38.030198 10701 solver.cpp:258]     Train net output #0: loss = 0.0122901 (* 1 = 0.0122901 loss)
I0526 16:21:38.030218 10701 sgd_solver.cpp:112] Iteration 14847, lr = 0.005
I0526 16:22:10.112136 10701 solver.cpp:239] Iteration 14896 (1.52738 iter/s, 32.081s/49 iters), loss = 0.00649781
I0526 16:22:10.112309 10701 solver.cpp:258]     Train net output #0: loss = 0.00287261 (* 1 = 0.00287261 loss)
I0526 16:22:10.112329 10701 sgd_solver.cpp:112] Iteration 14896, lr = 0.005
I0526 16:22:43.371251 10701 solver.cpp:239] Iteration 14945 (1.47333 iter/s, 33.258s/49 iters), loss = 0.00532799
I0526 16:22:43.371712 10701 solver.cpp:258]     Train net output #0: loss = 0.00675796 (* 1 = 0.00675796 loss)
I0526 16:22:43.371753 10701 sgd_solver.cpp:112] Iteration 14945, lr = 0.005
I0526 16:23:24.670192 10701 solver.cpp:239] Iteration 14994 (1.1865 iter/s, 41.298s/49 iters), loss = 0.011547
I0526 16:23:24.670413 10701 solver.cpp:258]     Train net output #0: loss = 0.0133913 (* 1 = 0.0133913 loss)
I0526 16:23:24.670424 10701 sgd_solver.cpp:112] Iteration 14994, lr = 0.005
I0526 16:24:06.755035 10701 solver.cpp:239] Iteration 15043 (1.16434 iter/s, 42.084s/49 iters), loss = 0.00844718
I0526 16:24:06.756453 10701 solver.cpp:258]     Train net output #0: loss = 0.000780159 (* 1 = 0.000780159 loss)
I0526 16:24:06.756466 10701 sgd_solver.cpp:112] Iteration 15043, lr = 0.005
I0526 16:24:46.797102 10701 solver.cpp:239] Iteration 15092 (1.22378 iter/s, 40.04s/49 iters), loss = 0.00864556
I0526 16:24:46.797248 10701 solver.cpp:258]     Train net output #0: loss = 0.00143193 (* 1 = 0.00143193 loss)
I0526 16:24:46.797257 10701 sgd_solver.cpp:112] Iteration 15092, lr = 0.005
I0526 16:25:33.465185 10701 solver.cpp:239] Iteration 15141 (1.04999 iter/s, 46.667s/49 iters), loss = 0.00361838
I0526 16:25:33.465268 10701 solver.cpp:258]     Train net output #0: loss = 0.000356706 (* 1 = 0.000356706 loss)
I0526 16:25:33.465278 10701 sgd_solver.cpp:112] Iteration 15141, lr = 0.005
I0526 16:26:18.926405 10701 solver.cpp:239] Iteration 15190 (1.07785 iter/s, 45.461s/49 iters), loss = 0.00694604
I0526 16:26:18.926710 10701 solver.cpp:258]     Train net output #0: loss = 0.000859765 (* 1 = 0.000859765 loss)
I0526 16:26:18.926769 10701 sgd_solver.cpp:112] Iteration 15190, lr = 0.005
I0526 16:27:18.177675 10701 solver.cpp:239] Iteration 15239 (0.827004 iter/s, 59.25s/49 iters), loss = 0.00598598
I0526 16:27:18.178053 10701 solver.cpp:258]     Train net output #0: loss = 0.000676469 (* 1 = 0.000676469 loss)
I0526 16:27:18.178084 10701 sgd_solver.cpp:112] Iteration 15239, lr = 0.005
I0526 16:28:39.260502 10701 solver.cpp:239] Iteration 15288 (0.604326 iter/s, 81.082s/49 iters), loss = 0.0167359
I0526 16:28:39.260802 10701 solver.cpp:258]     Train net output #0: loss = 0.0132422 (* 1 = 0.0132422 loss)
I0526 16:28:39.260823 10701 sgd_solver.cpp:112] Iteration 15288, lr = 0.005
I0526 16:29:50.037485 10701 solver.cpp:239] Iteration 15337 (0.692325 iter/s, 70.776s/49 iters), loss = 0.00794347
I0526 16:29:50.037637 10701 solver.cpp:258]     Train net output #0: loss = 0.00131823 (* 1 = 0.00131823 loss)
I0526 16:29:50.037649 10701 sgd_solver.cpp:112] Iteration 15337, lr = 0.005
I0526 16:30:38.027997 10701 solver.cpp:239] Iteration 15386 (1.02105 iter/s, 47.99s/49 iters), loss = 0.00767199
I0526 16:30:38.028182 10701 solver.cpp:258]     Train net output #0: loss = 0.00262232 (* 1 = 0.00262232 loss)
I0526 16:30:38.028190 10701 sgd_solver.cpp:112] Iteration 15386, lr = 0.005
I0526 16:31:18.146034 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_15435.caffemodel
I0526 16:31:18.146847 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_15435.solverstate
I0526 16:31:18.147214 10701 solver.cpp:347] Iteration 15435, Testing net (#0)
I0526 16:31:31.979290 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8508
I0526 16:31:31.979336 10701 solver.cpp:414]     Test net output #1: loss = 0.372494 (* 1 = 0.372494 loss)
I0526 16:31:31.979341 10701 solver.cpp:347] Iteration 15435, Testing net (#1)
I0526 16:31:58.583104 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998298
I0526 16:31:58.583231 10701 solver.cpp:414]     Test net output #1: loss = 0.00827977 (* 1 = 0.00827977 loss)
I0526 16:31:58.583240 10701 solver.cpp:347] Iteration 15435, Testing net (#2)
I0526 16:33:00.552594 10701 solver.cpp:414]     Test net output #0: accuracy = 0.867387
I0526 16:33:00.552742 10701 solver.cpp:414]     Test net output #1: loss = 0.317893 (* 1 = 0.317893 loss)
I0526 16:33:01.411653 10701 solver.cpp:239] Iteration 15435 (0.341742 iter/s, 143.383s/49 iters), loss = 0.00632143
I0526 16:33:01.411696 10701 solver.cpp:258]     Train net output #0: loss = 0.000511663 (* 1 = 0.000511663 loss)
I0526 16:33:01.411707 10701 sgd_solver.cpp:112] Iteration 15435, lr = 0.005
I0526 16:33:41.631213 10701 solver.cpp:239] Iteration 15484 (1.21833 iter/s, 40.219s/49 iters), loss = 0.00836979
I0526 16:33:41.631363 10701 solver.cpp:258]     Train net output #0: loss = 0.00248469 (* 1 = 0.00248469 loss)
I0526 16:33:41.631381 10701 sgd_solver.cpp:112] Iteration 15484, lr = 0.005
I0526 16:34:28.407295 10701 solver.cpp:239] Iteration 15533 (1.04757 iter/s, 46.775s/49 iters), loss = 0.00583208
I0526 16:34:28.407490 10701 solver.cpp:258]     Train net output #0: loss = 0.00132105 (* 1 = 0.00132105 loss)
I0526 16:34:28.407521 10701 sgd_solver.cpp:112] Iteration 15533, lr = 0.005
I0526 16:35:11.623955 10701 solver.cpp:239] Iteration 15582 (1.13384 iter/s, 43.216s/49 iters), loss = 0.00676342
I0526 16:35:11.624279 10701 solver.cpp:258]     Train net output #0: loss = 0.0015988 (* 1 = 0.0015988 loss)
I0526 16:35:11.624294 10701 sgd_solver.cpp:112] Iteration 15582, lr = 0.005
I0526 16:35:54.580991 10701 solver.cpp:239] Iteration 15631 (1.1407 iter/s, 42.956s/49 iters), loss = 0.00473821
I0526 16:35:54.581188 10701 solver.cpp:258]     Train net output #0: loss = 0.000360534 (* 1 = 0.000360534 loss)
I0526 16:35:54.581199 10701 sgd_solver.cpp:112] Iteration 15631, lr = 0.005
I0526 16:36:39.066054 10701 solver.cpp:239] Iteration 15680 (1.10152 iter/s, 44.484s/49 iters), loss = 0.00657961
I0526 16:36:39.066202 10701 solver.cpp:258]     Train net output #0: loss = 0.0019307 (* 1 = 0.0019307 loss)
I0526 16:36:39.066211 10701 sgd_solver.cpp:112] Iteration 15680, lr = 0.005
I0526 16:37:14.568513 10701 solver.cpp:239] Iteration 15729 (1.3802 iter/s, 35.502s/49 iters), loss = 0.00611581
I0526 16:37:14.568725 10701 solver.cpp:258]     Train net output #0: loss = 0.0204532 (* 1 = 0.0204532 loss)
I0526 16:37:14.568737 10701 sgd_solver.cpp:112] Iteration 15729, lr = 0.005
I0526 16:37:46.683533 10701 solver.cpp:239] Iteration 15778 (1.52581 iter/s, 32.114s/49 iters), loss = 0.0116888
I0526 16:37:46.683728 10701 solver.cpp:258]     Train net output #0: loss = 0.0128613 (* 1 = 0.0128613 loss)
I0526 16:37:46.683739 10701 sgd_solver.cpp:112] Iteration 15778, lr = 0.005
I0526 16:38:18.264168 10701 solver.cpp:239] Iteration 15827 (1.55161 iter/s, 31.58s/49 iters), loss = 0.0059828
I0526 16:38:18.264343 10701 solver.cpp:258]     Train net output #0: loss = 0.0103722 (* 1 = 0.0103722 loss)
I0526 16:38:18.264353 10701 sgd_solver.cpp:112] Iteration 15827, lr = 0.005
I0526 16:38:49.877447 10701 solver.cpp:239] Iteration 15876 (1.55 iter/s, 31.613s/49 iters), loss = 0.00355272
I0526 16:38:49.877672 10701 solver.cpp:258]     Train net output #0: loss = 0.00676466 (* 1 = 0.00676466 loss)
I0526 16:38:49.877682 10701 sgd_solver.cpp:112] Iteration 15876, lr = 0.005
I0526 16:39:21.517563 10701 solver.cpp:239] Iteration 15925 (1.54872 iter/s, 31.639s/49 iters), loss = 0.00487589
I0526 16:39:21.517773 10701 solver.cpp:258]     Train net output #0: loss = 0.000404741 (* 1 = 0.000404741 loss)
I0526 16:39:21.517784 10701 sgd_solver.cpp:112] Iteration 15925, lr = 0.005
I0526 16:39:53.126612 10701 solver.cpp:239] Iteration 15974 (1.55024 iter/s, 31.608s/49 iters), loss = 0.00646293
I0526 16:39:53.126803 10701 solver.cpp:258]     Train net output #0: loss = 0.000103964 (* 1 = 0.000103964 loss)
I0526 16:39:53.126812 10701 sgd_solver.cpp:112] Iteration 15974, lr = 0.005
I0526 16:40:24.764891 10701 solver.cpp:239] Iteration 16023 (1.54877 iter/s, 31.638s/49 iters), loss = 0.00815282
I0526 16:40:24.765069 10701 solver.cpp:258]     Train net output #0: loss = 0.000431246 (* 1 = 0.000431246 loss)
I0526 16:40:24.765077 10701 sgd_solver.cpp:112] Iteration 16023, lr = 0.005
I0526 16:40:56.732856 10701 solver.cpp:239] Iteration 16072 (1.53283 iter/s, 31.967s/49 iters), loss = 0.00744662
I0526 16:40:56.733093 10701 solver.cpp:258]     Train net output #0: loss = 0.000818175 (* 1 = 0.000818175 loss)
I0526 16:40:56.733104 10701 sgd_solver.cpp:112] Iteration 16072, lr = 0.005
I0526 16:41:27.955277 10701 solver.cpp:239] Iteration 16121 (1.56941 iter/s, 31.222s/49 iters), loss = 0.011448
I0526 16:41:27.955510 10701 solver.cpp:258]     Train net output #0: loss = 0.00281009 (* 1 = 0.00281009 loss)
I0526 16:41:27.955520 10701 sgd_solver.cpp:112] Iteration 16121, lr = 0.005
I0526 16:41:58.786307 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_16170.caffemodel
I0526 16:41:58.787137 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_16170.solverstate
I0526 16:41:58.787467 10701 solver.cpp:347] Iteration 16170, Testing net (#0)
I0526 16:42:10.390740 10701 solver.cpp:414]     Test net output #0: accuracy = 0.9392
I0526 16:42:10.390787 10701 solver.cpp:414]     Test net output #1: loss = 0.170908 (* 1 = 0.170908 loss)
I0526 16:42:10.390794 10701 solver.cpp:347] Iteration 16170, Testing net (#1)
I0526 16:42:32.312803 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998085
I0526 16:42:32.312981 10701 solver.cpp:414]     Test net output #1: loss = 0.00800699 (* 1 = 0.00800699 loss)
I0526 16:42:32.312990 10701 solver.cpp:347] Iteration 16170, Testing net (#2)
I0526 16:43:23.351609 10701 solver.cpp:414]     Test net output #0: accuracy = 0.923333
I0526 16:43:23.351817 10701 solver.cpp:414]     Test net output #1: loss = 0.187574 (* 1 = 0.187574 loss)
I0526 16:43:23.994943 10701 solver.cpp:239] Iteration 16170 (0.422272 iter/s, 116.039s/49 iters), loss = 0.00734491
I0526 16:43:23.994997 10701 solver.cpp:258]     Train net output #0: loss = 0.000539838 (* 1 = 0.000539838 loss)
I0526 16:43:23.995004 10701 sgd_solver.cpp:112] Iteration 16170, lr = 0.005
I0526 16:43:55.077466 10701 solver.cpp:239] Iteration 16219 (1.57648 iter/s, 31.082s/49 iters), loss = 0.00545647
I0526 16:43:55.077721 10701 solver.cpp:258]     Train net output #0: loss = 0.000277761 (* 1 = 0.000277761 loss)
I0526 16:43:55.077731 10701 sgd_solver.cpp:112] Iteration 16219, lr = 0.005
I0526 16:44:26.305327 10701 solver.cpp:239] Iteration 16268 (1.56915 iter/s, 31.227s/49 iters), loss = 0.00857629
I0526 16:44:26.305553 10701 solver.cpp:258]     Train net output #0: loss = 0.0283514 (* 1 = 0.0283514 loss)
I0526 16:44:26.305563 10701 sgd_solver.cpp:112] Iteration 16268, lr = 0.005
I0526 16:44:57.894976 10701 solver.cpp:239] Iteration 16317 (1.55117 iter/s, 31.589s/49 iters), loss = 0.00599687
I0526 16:44:57.895184 10701 solver.cpp:258]     Train net output #0: loss = 0.00738173 (* 1 = 0.00738173 loss)
I0526 16:44:57.895203 10701 sgd_solver.cpp:112] Iteration 16317, lr = 0.005
I0526 16:45:29.440340 10701 solver.cpp:239] Iteration 16366 (1.55334 iter/s, 31.545s/49 iters), loss = 0.0078224
I0526 16:45:29.440598 10701 solver.cpp:258]     Train net output #0: loss = 0.00201061 (* 1 = 0.00201061 loss)
I0526 16:45:29.440609 10701 sgd_solver.cpp:112] Iteration 16366, lr = 0.005
I0526 16:46:00.997372 10701 solver.cpp:239] Iteration 16415 (1.5528 iter/s, 31.556s/49 iters), loss = 0.0106139
I0526 16:46:00.997611 10701 solver.cpp:258]     Train net output #0: loss = 0.00287375 (* 1 = 0.00287375 loss)
I0526 16:46:00.997622 10701 sgd_solver.cpp:112] Iteration 16415, lr = 0.005
I0526 16:46:32.630403 10701 solver.cpp:239] Iteration 16464 (1.54906 iter/s, 31.632s/49 iters), loss = 0.00825643
I0526 16:46:32.630641 10701 solver.cpp:258]     Train net output #0: loss = 0.000363351 (* 1 = 0.000363351 loss)
I0526 16:46:32.630650 10701 sgd_solver.cpp:112] Iteration 16464, lr = 0.005
I0526 16:47:04.261040 10701 solver.cpp:239] Iteration 16513 (1.54916 iter/s, 31.63s/49 iters), loss = 0.00503315
I0526 16:47:04.261274 10701 solver.cpp:258]     Train net output #0: loss = 0.0189817 (* 1 = 0.0189817 loss)
I0526 16:47:04.261284 10701 sgd_solver.cpp:112] Iteration 16513, lr = 0.005
I0526 16:47:35.859441 10701 solver.cpp:239] Iteration 16562 (1.55073 iter/s, 31.598s/49 iters), loss = 0.00708549
I0526 16:47:35.859683 10701 solver.cpp:258]     Train net output #0: loss = 0.000393503 (* 1 = 0.000393503 loss)
I0526 16:47:35.859694 10701 sgd_solver.cpp:112] Iteration 16562, lr = 0.005
I0526 16:48:07.463117 10701 solver.cpp:239] Iteration 16611 (1.55049 iter/s, 31.603s/49 iters), loss = 0.012689
I0526 16:48:07.463294 10701 solver.cpp:258]     Train net output #0: loss = 0.000958255 (* 1 = 0.000958255 loss)
I0526 16:48:07.463312 10701 sgd_solver.cpp:112] Iteration 16611, lr = 0.005
I0526 16:48:39.057660 10701 solver.cpp:239] Iteration 16660 (1.55093 iter/s, 31.594s/49 iters), loss = 0.00932617
I0526 16:48:39.057801 10701 solver.cpp:258]     Train net output #0: loss = 0.00127205 (* 1 = 0.00127205 loss)
I0526 16:48:39.057819 10701 sgd_solver.cpp:112] Iteration 16660, lr = 0.005
I0526 16:49:21.845176 10701 solver.cpp:239] Iteration 16709 (1.14521 iter/s, 42.787s/49 iters), loss = 0.00554996
I0526 16:49:21.848832 10701 solver.cpp:258]     Train net output #0: loss = 0.00170995 (* 1 = 0.00170995 loss)
I0526 16:49:21.848847 10701 sgd_solver.cpp:112] Iteration 16709, lr = 0.005
I0526 16:50:05.942137 10701 solver.cpp:239] Iteration 16758 (1.11129 iter/s, 44.093s/49 iters), loss = 0.00475414
I0526 16:50:05.942239 10701 solver.cpp:258]     Train net output #0: loss = 0.0111616 (* 1 = 0.0111616 loss)
I0526 16:50:05.942248 10701 sgd_solver.cpp:112] Iteration 16758, lr = 0.005
I0526 16:50:47.065804 10701 solver.cpp:239] Iteration 16807 (1.19155 iter/s, 41.123s/49 iters), loss = 0.00637813
I0526 16:50:47.065948 10701 solver.cpp:258]     Train net output #0: loss = 0.000768949 (* 1 = 0.000768949 loss)
I0526 16:50:47.065959 10701 sgd_solver.cpp:112] Iteration 16807, lr = 0.005
I0526 16:51:26.186157 10701 solver.cpp:239] Iteration 16856 (1.25256 iter/s, 39.12s/49 iters), loss = 0.00646198
I0526 16:51:26.186349 10701 solver.cpp:258]     Train net output #0: loss = 0.0013168 (* 1 = 0.0013168 loss)
I0526 16:51:26.186360 10701 sgd_solver.cpp:112] Iteration 16856, lr = 0.005
I0526 16:51:58.658177 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_16905.caffemodel
I0526 16:51:58.659098 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_16905.solverstate
I0526 16:51:58.659446 10701 solver.cpp:347] Iteration 16905, Testing net (#0)
I0526 16:52:10.475687 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8592
I0526 16:52:10.475744 10701 solver.cpp:414]     Test net output #1: loss = 0.383781 (* 1 = 0.383781 loss)
I0526 16:52:10.475750 10701 solver.cpp:347] Iteration 16905, Testing net (#1)
I0526 16:52:33.150235 10701 solver.cpp:414]     Test net output #0: accuracy = 0.99766
I0526 16:52:33.150424 10701 solver.cpp:414]     Test net output #1: loss = 0.0113063 (* 1 = 0.0113063 loss)
I0526 16:52:33.150434 10701 solver.cpp:347] Iteration 16905, Testing net (#2)
I0526 16:53:27.222530 10701 solver.cpp:414]     Test net output #0: accuracy = 0.88
I0526 16:53:27.222656 10701 solver.cpp:414]     Test net output #1: loss = 0.297816 (* 1 = 0.297816 loss)
I0526 16:53:27.986654 10701 solver.cpp:239] Iteration 16905 (0.402299 iter/s, 121.8s/49 iters), loss = 0.00180157
I0526 16:53:27.986709 10701 solver.cpp:258]     Train net output #0: loss = 0.0251259 (* 1 = 0.0251259 loss)
I0526 16:53:27.986717 10701 sgd_solver.cpp:112] Iteration 16905, lr = 0.005
I0526 16:54:00.432955 10701 solver.cpp:239] Iteration 16954 (1.5102 iter/s, 32.446s/49 iters), loss = 0.00420095
I0526 16:54:00.433190 10701 solver.cpp:258]     Train net output #0: loss = 0.000366803 (* 1 = 0.000366803 loss)
I0526 16:54:00.433202 10701 sgd_solver.cpp:112] Iteration 16954, lr = 0.005
I0526 16:54:34.271769 10701 solver.cpp:239] Iteration 17003 (1.44808 iter/s, 33.838s/49 iters), loss = 0.00685356
I0526 16:54:34.271912 10701 solver.cpp:258]     Train net output #0: loss = 0.0178489 (* 1 = 0.0178489 loss)
I0526 16:54:34.271921 10701 sgd_solver.cpp:112] Iteration 17003, lr = 0.005
I0526 16:55:07.174649 10701 solver.cpp:239] Iteration 17052 (1.48927 iter/s, 32.902s/49 iters), loss = 0.00514514
I0526 16:55:07.174823 10701 solver.cpp:258]     Train net output #0: loss = 0.000657869 (* 1 = 0.000657869 loss)
I0526 16:55:07.174834 10701 sgd_solver.cpp:112] Iteration 17052, lr = 0.005
I0526 16:55:39.686836 10701 solver.cpp:239] Iteration 17101 (1.50714 iter/s, 32.512s/49 iters), loss = 0.00750746
I0526 16:55:39.687057 10701 solver.cpp:258]     Train net output #0: loss = 0.000396194 (* 1 = 0.000396194 loss)
I0526 16:55:39.687067 10701 sgd_solver.cpp:112] Iteration 17101, lr = 0.005
I0526 16:56:12.818473 10701 solver.cpp:239] Iteration 17150 (1.47898 iter/s, 33.131s/49 iters), loss = 0.0100902
I0526 16:56:12.818619 10701 solver.cpp:258]     Train net output #0: loss = 0.000932878 (* 1 = 0.000932878 loss)
I0526 16:56:12.818630 10701 sgd_solver.cpp:112] Iteration 17150, lr = 0.005
I0526 16:56:46.960506 10701 solver.cpp:239] Iteration 17199 (1.43522 iter/s, 34.141s/49 iters), loss = 0.00674993
I0526 16:56:46.960707 10701 solver.cpp:258]     Train net output #0: loss = 0.0568238 (* 1 = 0.0568238 loss)
I0526 16:56:46.960717 10701 sgd_solver.cpp:112] Iteration 17199, lr = 0.005
I0526 16:57:19.188683 10701 solver.cpp:239] Iteration 17248 (1.52046 iter/s, 32.227s/49 iters), loss = 0.00518868
I0526 16:57:19.188793 10701 solver.cpp:258]     Train net output #0: loss = 0.0133194 (* 1 = 0.0133194 loss)
I0526 16:57:19.188802 10701 sgd_solver.cpp:112] Iteration 17248, lr = 0.005
I0526 16:57:51.567692 10701 solver.cpp:239] Iteration 17297 (1.51337 iter/s, 32.378s/49 iters), loss = 0.00959852
I0526 16:57:51.567828 10701 solver.cpp:258]     Train net output #0: loss = 0.000624204 (* 1 = 0.000624204 loss)
I0526 16:57:51.567839 10701 sgd_solver.cpp:112] Iteration 17297, lr = 0.005
I0526 16:58:30.419201 10701 solver.cpp:239] Iteration 17346 (1.26123 iter/s, 38.851s/49 iters), loss = 0.0109495
I0526 16:58:30.419361 10701 solver.cpp:258]     Train net output #0: loss = 0.000991133 (* 1 = 0.000991133 loss)
I0526 16:58:30.419373 10701 sgd_solver.cpp:112] Iteration 17346, lr = 0.005
I0526 16:59:08.325269 10701 solver.cpp:239] Iteration 17395 (1.29271 iter/s, 37.905s/49 iters), loss = 0.00477758
I0526 16:59:08.325457 10701 solver.cpp:258]     Train net output #0: loss = 0.000522376 (* 1 = 0.000522376 loss)
I0526 16:59:08.325467 10701 sgd_solver.cpp:112] Iteration 17395, lr = 0.005
I0526 16:59:46.193539 10701 solver.cpp:239] Iteration 17444 (1.29397 iter/s, 37.868s/49 iters), loss = 0.00649857
I0526 16:59:46.193718 10701 solver.cpp:258]     Train net output #0: loss = 0.0019098 (* 1 = 0.0019098 loss)
I0526 16:59:46.193737 10701 sgd_solver.cpp:112] Iteration 17444, lr = 0.005
I0526 17:00:25.222684 10701 solver.cpp:239] Iteration 17493 (1.25551 iter/s, 39.028s/49 iters), loss = 0.00258584
I0526 17:00:25.222795 10701 solver.cpp:258]     Train net output #0: loss = 0.0129274 (* 1 = 0.0129274 loss)
I0526 17:00:25.222805 10701 sgd_solver.cpp:112] Iteration 17493, lr = 0.005
I0526 17:01:04.791409 10701 solver.cpp:239] Iteration 17542 (1.23837 iter/s, 39.568s/49 iters), loss = 0.00677846
I0526 17:01:04.791563 10701 solver.cpp:258]     Train net output #0: loss = 0.000845144 (* 1 = 0.000845144 loss)
I0526 17:01:04.791571 10701 sgd_solver.cpp:112] Iteration 17542, lr = 0.005
I0526 17:01:42.350267 10701 solver.cpp:239] Iteration 17591 (1.30465 iter/s, 37.558s/49 iters), loss = 0.00634127
I0526 17:01:42.350405 10701 solver.cpp:258]     Train net output #0: loss = 0.000492884 (* 1 = 0.000492884 loss)
I0526 17:01:42.350416 10701 sgd_solver.cpp:112] Iteration 17591, lr = 0.005
I0526 17:02:19.026525 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_17640.caffemodel
I0526 17:02:19.027820 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_17640.solverstate
I0526 17:02:19.028163 10701 solver.cpp:347] Iteration 17640, Testing net (#0)
I0526 17:02:33.358080 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8536
I0526 17:02:33.358127 10701 solver.cpp:414]     Test net output #1: loss = 0.376135 (* 1 = 0.376135 loss)
I0526 17:02:33.358134 10701 solver.cpp:347] Iteration 17640, Testing net (#1)
I0526 17:02:57.271232 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998085
I0526 17:02:57.271414 10701 solver.cpp:414]     Test net output #1: loss = 0.00725702 (* 1 = 0.00725702 loss)
I0526 17:02:57.271423 10701 solver.cpp:347] Iteration 17640, Testing net (#2)
I0526 17:03:49.931545 10701 solver.cpp:414]     Test net output #0: accuracy = 0.895856
I0526 17:03:49.931687 10701 solver.cpp:414]     Test net output #1: loss = 0.258147 (* 1 = 0.258147 loss)
I0526 17:03:50.614972 10701 solver.cpp:239] Iteration 17640 (0.382025 iter/s, 128.264s/49 iters), loss = 0.00269228
I0526 17:03:50.615012 10701 solver.cpp:258]     Train net output #0: loss = 0.000566128 (* 1 = 0.000566128 loss)
I0526 17:03:50.615020 10701 sgd_solver.cpp:112] Iteration 17640, lr = 0.0025
I0526 17:04:24.465123 10701 solver.cpp:239] Iteration 17689 (1.44756 iter/s, 33.85s/49 iters), loss = 0.00616273
I0526 17:04:24.465324 10701 solver.cpp:258]     Train net output #0: loss = 0.000464614 (* 1 = 0.000464614 loss)
I0526 17:04:24.465334 10701 sgd_solver.cpp:112] Iteration 17689, lr = 0.0025
I0526 17:04:57.182502 10701 solver.cpp:239] Iteration 17738 (1.49769 iter/s, 32.717s/49 iters), loss = 0.00879811
I0526 17:04:57.182663 10701 solver.cpp:258]     Train net output #0: loss = 0.0167641 (* 1 = 0.0167641 loss)
I0526 17:04:57.182672 10701 sgd_solver.cpp:112] Iteration 17738, lr = 0.0025
I0526 17:05:29.611429 10701 solver.cpp:239] Iteration 17787 (1.51104 iter/s, 32.428s/49 iters), loss = 0.00532815
I0526 17:05:29.611614 10701 solver.cpp:258]     Train net output #0: loss = 0.0165283 (* 1 = 0.0165283 loss)
I0526 17:05:29.611624 10701 sgd_solver.cpp:112] Iteration 17787, lr = 0.0025
I0526 17:06:02.307013 10701 solver.cpp:239] Iteration 17836 (1.4987 iter/s, 32.695s/49 iters), loss = 0.0102889
I0526 17:06:02.307134 10701 solver.cpp:258]     Train net output #0: loss = 0.000367793 (* 1 = 0.000367793 loss)
I0526 17:06:02.307158 10701 sgd_solver.cpp:112] Iteration 17836, lr = 0.0025
I0526 17:06:37.240075 10701 solver.cpp:239] Iteration 17885 (1.40273 iter/s, 34.932s/49 iters), loss = 0.0044904
I0526 17:06:37.240231 10701 solver.cpp:258]     Train net output #0: loss = 0.000603007 (* 1 = 0.000603007 loss)
I0526 17:06:37.240240 10701 sgd_solver.cpp:112] Iteration 17885, lr = 0.0025
I0526 17:07:11.998014 10701 solver.cpp:239] Iteration 17934 (1.40979 iter/s, 34.757s/49 iters), loss = 0.010184
I0526 17:07:11.998229 10701 solver.cpp:258]     Train net output #0: loss = 0.00101197 (* 1 = 0.00101197 loss)
I0526 17:07:11.998239 10701 sgd_solver.cpp:112] Iteration 17934, lr = 0.0025
I0526 17:07:44.012315 10701 solver.cpp:239] Iteration 17983 (1.53058 iter/s, 32.014s/49 iters), loss = 0.00567606
I0526 17:07:44.012567 10701 solver.cpp:258]     Train net output #0: loss = 0.0006306 (* 1 = 0.0006306 loss)
I0526 17:07:44.012578 10701 sgd_solver.cpp:112] Iteration 17983, lr = 0.0025
I0526 17:08:15.988826 10701 solver.cpp:239] Iteration 18032 (1.5324 iter/s, 31.976s/49 iters), loss = 0.00356427
I0526 17:08:15.989050 10701 solver.cpp:258]     Train net output #0: loss = 0.000706456 (* 1 = 0.000706456 loss)
I0526 17:08:15.989061 10701 sgd_solver.cpp:112] Iteration 18032, lr = 0.0025
I0526 17:08:47.904522 10701 solver.cpp:239] Iteration 18081 (1.53533 iter/s, 31.915s/49 iters), loss = 0.00562905
I0526 17:08:47.904780 10701 solver.cpp:258]     Train net output #0: loss = 0.00267616 (* 1 = 0.00267616 loss)
I0526 17:08:47.904793 10701 sgd_solver.cpp:112] Iteration 18081, lr = 0.0025
I0526 17:09:19.904397 10701 solver.cpp:239] Iteration 18130 (1.5313 iter/s, 31.999s/49 iters), loss = 0.00626107
I0526 17:09:19.904618 10701 solver.cpp:258]     Train net output #0: loss = 0.00609641 (* 1 = 0.00609641 loss)
I0526 17:09:19.904628 10701 sgd_solver.cpp:112] Iteration 18130, lr = 0.0025
I0526 17:09:52.781616 10701 solver.cpp:239] Iteration 18179 (1.4904 iter/s, 32.877s/49 iters), loss = 0.00777714
I0526 17:09:52.781805 10701 solver.cpp:258]     Train net output #0: loss = 0.0303595 (* 1 = 0.0303595 loss)
I0526 17:09:52.781816 10701 sgd_solver.cpp:112] Iteration 18179, lr = 0.0025
I0526 17:10:24.902632 10701 solver.cpp:239] Iteration 18228 (1.52553 iter/s, 32.12s/49 iters), loss = 0.00542534
I0526 17:10:24.902803 10701 solver.cpp:258]     Train net output #0: loss = 0.00058819 (* 1 = 0.00058819 loss)
I0526 17:10:24.902812 10701 sgd_solver.cpp:112] Iteration 18228, lr = 0.0025
I0526 17:10:56.628700 10701 solver.cpp:239] Iteration 18277 (1.54452 iter/s, 31.725s/49 iters), loss = 0.0071283
I0526 17:10:56.628921 10701 solver.cpp:258]     Train net output #0: loss = 0.00657372 (* 1 = 0.00657372 loss)
I0526 17:10:56.628931 10701 sgd_solver.cpp:112] Iteration 18277, lr = 0.0025
I0526 17:11:28.559613 10701 solver.cpp:239] Iteration 18326 (1.53461 iter/s, 31.93s/49 iters), loss = 0.00322602
I0526 17:11:28.559821 10701 solver.cpp:258]     Train net output #0: loss = 0.00260608 (* 1 = 0.00260608 loss)
I0526 17:11:28.559831 10701 sgd_solver.cpp:112] Iteration 18326, lr = 0.0025
I0526 17:12:00.072755 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_18375.caffemodel
I0526 17:12:00.073688 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_18375.solverstate
I0526 17:12:00.074028 10701 solver.cpp:347] Iteration 18375, Testing net (#0)
I0526 17:12:11.848704 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8636
I0526 17:12:11.848749 10701 solver.cpp:414]     Test net output #1: loss = 0.34317 (* 1 = 0.34317 loss)
I0526 17:12:11.848754 10701 solver.cpp:347] Iteration 18375, Testing net (#1)
I0526 17:12:34.107547 10701 solver.cpp:414]     Test net output #0: accuracy = 0.999149
I0526 17:12:34.107726 10701 solver.cpp:414]     Test net output #1: loss = 0.00301714 (* 1 = 0.00301714 loss)
I0526 17:12:34.107736 10701 solver.cpp:347] Iteration 18375, Testing net (#2)
I0526 17:13:25.923226 10701 solver.cpp:414]     Test net output #0: accuracy = 0.91045
I0526 17:13:25.923441 10701 solver.cpp:414]     Test net output #1: loss = 0.228477 (* 1 = 0.228477 loss)
I0526 17:13:26.578001 10701 solver.cpp:239] Iteration 18375 (0.415191 iter/s, 118.018s/49 iters), loss = 0.00565123
I0526 17:13:26.578056 10701 solver.cpp:258]     Train net output #0: loss = 0.000227473 (* 1 = 0.000227473 loss)
I0526 17:13:26.578065 10701 sgd_solver.cpp:112] Iteration 18375, lr = 0.0025
I0526 17:13:58.615483 10701 solver.cpp:239] Iteration 18424 (1.52948 iter/s, 32.037s/49 iters), loss = 0.00548767
I0526 17:13:58.615703 10701 solver.cpp:258]     Train net output #0: loss = 0.000249716 (* 1 = 0.000249716 loss)
I0526 17:13:58.615713 10701 sgd_solver.cpp:112] Iteration 18424, lr = 0.0025
I0526 17:14:30.280453 10701 solver.cpp:239] Iteration 18473 (1.5475 iter/s, 31.664s/49 iters), loss = 0.0043081
I0526 17:14:30.280665 10701 solver.cpp:258]     Train net output #0: loss = 0.00468132 (* 1 = 0.00468132 loss)
I0526 17:14:30.280678 10701 sgd_solver.cpp:112] Iteration 18473, lr = 0.0025
I0526 17:15:02.002615 10701 solver.cpp:239] Iteration 18522 (1.54472 iter/s, 31.721s/49 iters), loss = 0.0032493
I0526 17:15:02.002775 10701 solver.cpp:258]     Train net output #0: loss = 0.000263281 (* 1 = 0.000263281 loss)
I0526 17:15:02.002795 10701 sgd_solver.cpp:112] Iteration 18522, lr = 0.0025
I0526 17:15:33.870841 10701 solver.cpp:239] Iteration 18571 (1.53759 iter/s, 31.868s/49 iters), loss = 0.0104304
I0526 17:15:33.871101 10701 solver.cpp:258]     Train net output #0: loss = 0.00040585 (* 1 = 0.00040585 loss)
I0526 17:15:33.871112 10701 sgd_solver.cpp:112] Iteration 18571, lr = 0.0025
I0526 17:16:06.007481 10701 solver.cpp:239] Iteration 18620 (1.52477 iter/s, 32.136s/49 iters), loss = 0.0102424
I0526 17:16:06.007695 10701 solver.cpp:258]     Train net output #0: loss = 0.000373999 (* 1 = 0.000373999 loss)
I0526 17:16:06.007705 10701 sgd_solver.cpp:112] Iteration 18620, lr = 0.0025
I0526 17:16:38.125715 10701 solver.cpp:239] Iteration 18669 (1.52562 iter/s, 32.118s/49 iters), loss = 0.00685184
I0526 17:16:38.125927 10701 solver.cpp:258]     Train net output #0: loss = 0.00122659 (* 1 = 0.00122659 loss)
I0526 17:16:38.125938 10701 sgd_solver.cpp:112] Iteration 18669, lr = 0.0025
I0526 17:17:10.266186 10701 solver.cpp:239] Iteration 18718 (1.52458 iter/s, 32.14s/49 iters), loss = 0.00512977
I0526 17:17:10.266403 10701 solver.cpp:258]     Train net output #0: loss = 0.00454926 (* 1 = 0.00454926 loss)
I0526 17:17:10.266413 10701 sgd_solver.cpp:112] Iteration 18718, lr = 0.0025
I0526 17:17:42.324741 10701 solver.cpp:239] Iteration 18767 (1.52848 iter/s, 32.058s/49 iters), loss = 0.00665589
I0526 17:17:42.324923 10701 solver.cpp:258]     Train net output #0: loss = 0.000948574 (* 1 = 0.000948574 loss)
I0526 17:17:42.324934 10701 sgd_solver.cpp:112] Iteration 18767, lr = 0.0025
I0526 17:18:14.394879 10701 solver.cpp:239] Iteration 18816 (1.52796 iter/s, 32.069s/49 iters), loss = 0.00920069
I0526 17:18:14.395076 10701 solver.cpp:258]     Train net output #0: loss = 0.0019915 (* 1 = 0.0019915 loss)
I0526 17:18:14.395084 10701 sgd_solver.cpp:112] Iteration 18816, lr = 0.0025
I0526 17:18:48.602773 10701 solver.cpp:239] Iteration 18865 (1.43246 iter/s, 34.207s/49 iters), loss = 0.00568473
I0526 17:18:48.602919 10701 solver.cpp:258]     Train net output #0: loss = 0.000283722 (* 1 = 0.000283722 loss)
I0526 17:18:48.602931 10701 sgd_solver.cpp:112] Iteration 18865, lr = 0.0025
I0526 17:19:21.274065 10701 solver.cpp:239] Iteration 18914 (1.4998 iter/s, 32.671s/49 iters), loss = 0.0027139
I0526 17:19:21.274194 10701 solver.cpp:258]     Train net output #0: loss = 0.000754447 (* 1 = 0.000754447 loss)
I0526 17:19:21.274204 10701 sgd_solver.cpp:112] Iteration 18914, lr = 0.0025
I0526 17:19:54.462204 10701 solver.cpp:239] Iteration 18963 (1.47644 iter/s, 33.188s/49 iters), loss = 0.0069491
I0526 17:19:54.462424 10701 solver.cpp:258]     Train net output #0: loss = 0.000505413 (* 1 = 0.000505413 loss)
I0526 17:19:54.462435 10701 sgd_solver.cpp:112] Iteration 18963, lr = 0.0025
I0526 17:20:27.055981 10701 solver.cpp:239] Iteration 19012 (1.50339 iter/s, 32.593s/49 iters), loss = 0.00383059
I0526 17:20:27.056120 10701 solver.cpp:258]     Train net output #0: loss = 0.00022095 (* 1 = 0.00022095 loss)
I0526 17:20:27.056131 10701 sgd_solver.cpp:112] Iteration 19012, lr = 0.0025
I0526 17:20:59.520767 10701 solver.cpp:239] Iteration 19061 (1.50936 iter/s, 32.464s/49 iters), loss = 0.006272
I0526 17:20:59.520925 10701 solver.cpp:258]     Train net output #0: loss = 0.000602025 (* 1 = 0.000602025 loss)
I0526 17:20:59.520933 10701 sgd_solver.cpp:112] Iteration 19061, lr = 0.0025
I0526 17:21:31.925132 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_19110.caffemodel
I0526 17:21:31.925993 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_19110.solverstate
I0526 17:21:31.926328 10701 solver.cpp:347] Iteration 19110, Testing net (#0)
I0526 17:21:43.826244 10701 solver.cpp:414]     Test net output #0: accuracy = 0.892
I0526 17:21:43.826292 10701 solver.cpp:414]     Test net output #1: loss = 0.273366 (* 1 = 0.273366 loss)
I0526 17:21:43.826297 10701 solver.cpp:347] Iteration 19110, Testing net (#1)
I0526 17:22:06.087404 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998085
I0526 17:22:06.087549 10701 solver.cpp:414]     Test net output #1: loss = 0.00752723 (* 1 = 0.00752723 loss)
I0526 17:22:06.087568 10701 solver.cpp:347] Iteration 19110, Testing net (#2)
I0526 17:22:58.001273 10701 solver.cpp:414]     Test net output #0: accuracy = 0.91973
I0526 17:22:58.001489 10701 solver.cpp:414]     Test net output #1: loss = 0.200981 (* 1 = 0.200981 loss)
I0526 17:22:58.663331 10701 solver.cpp:239] Iteration 19110 (0.411274 iter/s, 119.142s/49 iters), loss = 0.0052488
I0526 17:22:58.663383 10701 solver.cpp:258]     Train net output #0: loss = 0.000613922 (* 1 = 0.000613922 loss)
I0526 17:22:58.663390 10701 sgd_solver.cpp:112] Iteration 19110, lr = 0.0025
I0526 17:23:30.826639 10701 solver.cpp:239] Iteration 19159 (1.52349 iter/s, 32.163s/49 iters), loss = 0.0100399
I0526 17:23:30.826795 10701 solver.cpp:258]     Train net output #0: loss = 0.000294736 (* 1 = 0.000294736 loss)
I0526 17:23:30.826805 10701 sgd_solver.cpp:112] Iteration 19159, lr = 0.0025
I0526 17:24:03.407402 10701 solver.cpp:239] Iteration 19208 (1.50399 iter/s, 32.58s/49 iters), loss = 0.00345407
I0526 17:24:03.407573 10701 solver.cpp:258]     Train net output #0: loss = 0.000607639 (* 1 = 0.000607639 loss)
I0526 17:24:03.407583 10701 sgd_solver.cpp:112] Iteration 19208, lr = 0.0025
I0526 17:24:35.579095 10701 solver.cpp:239] Iteration 19257 (1.52311 iter/s, 32.171s/49 iters), loss = 0.00199059
I0526 17:24:35.579232 10701 solver.cpp:258]     Train net output #0: loss = 0.000632965 (* 1 = 0.000632965 loss)
I0526 17:24:35.579253 10701 sgd_solver.cpp:112] Iteration 19257, lr = 0.0025
I0526 17:25:07.606101 10701 solver.cpp:239] Iteration 19306 (1.53001 iter/s, 32.026s/49 iters), loss = 0.00321298
I0526 17:25:07.606284 10701 solver.cpp:258]     Train net output #0: loss = 0.000298495 (* 1 = 0.000298495 loss)
I0526 17:25:07.606294 10701 sgd_solver.cpp:112] Iteration 19306, lr = 0.0025
I0526 17:25:40.447736 10701 solver.cpp:239] Iteration 19355 (1.49204 iter/s, 32.841s/49 iters), loss = 0.00511507
I0526 17:25:40.447952 10701 solver.cpp:258]     Train net output #0: loss = 0.00468754 (* 1 = 0.00468754 loss)
I0526 17:25:40.447962 10701 sgd_solver.cpp:112] Iteration 19355, lr = 0.0025
I0526 17:26:12.511354 10701 solver.cpp:239] Iteration 19404 (1.52824 iter/s, 32.063s/49 iters), loss = 0.00988439
I0526 17:26:12.511507 10701 solver.cpp:258]     Train net output #0: loss = 0.147595 (* 1 = 0.147595 loss)
I0526 17:26:12.511516 10701 sgd_solver.cpp:112] Iteration 19404, lr = 0.0025
I0526 17:26:44.713779 10701 solver.cpp:239] Iteration 19453 (1.52164 iter/s, 32.202s/49 iters), loss = 0.00285365
I0526 17:26:44.713907 10701 solver.cpp:258]     Train net output #0: loss = 0.00293259 (* 1 = 0.00293259 loss)
I0526 17:26:44.713927 10701 sgd_solver.cpp:112] Iteration 19453, lr = 0.0025
I0526 17:27:16.606321 10701 solver.cpp:239] Iteration 19502 (1.53644 iter/s, 31.892s/49 iters), loss = 0.00665819
I0526 17:27:16.606460 10701 solver.cpp:258]     Train net output #0: loss = 0.0014555 (* 1 = 0.0014555 loss)
I0526 17:27:16.606470 10701 sgd_solver.cpp:112] Iteration 19502, lr = 0.0025
I0526 17:27:48.071590 10701 solver.cpp:239] Iteration 19551 (1.55729 iter/s, 31.465s/49 iters), loss = 0.00700796
I0526 17:27:48.071724 10701 solver.cpp:258]     Train net output #0: loss = 0.00318549 (* 1 = 0.00318549 loss)
I0526 17:27:48.071744 10701 sgd_solver.cpp:112] Iteration 19551, lr = 0.0025
I0526 17:28:19.731232 10701 solver.cpp:239] Iteration 19600 (1.54774 iter/s, 31.659s/49 iters), loss = 0.00403845
I0526 17:28:19.731398 10701 solver.cpp:258]     Train net output #0: loss = 0.00102298 (* 1 = 0.00102298 loss)
I0526 17:28:19.731408 10701 sgd_solver.cpp:112] Iteration 19600, lr = 0.0025
I0526 17:28:53.094569 10701 solver.cpp:239] Iteration 19649 (1.46869 iter/s, 33.363s/49 iters), loss = 0.00698604
I0526 17:28:53.094724 10701 solver.cpp:258]     Train net output #0: loss = 0.00278717 (* 1 = 0.00278717 loss)
I0526 17:28:53.094734 10701 sgd_solver.cpp:112] Iteration 19649, lr = 0.0025
I0526 17:29:25.176651 10701 solver.cpp:239] Iteration 19698 (1.52738 iter/s, 32.081s/49 iters), loss = 0.00338118
I0526 17:29:25.176807 10701 solver.cpp:258]     Train net output #0: loss = 0.00045308 (* 1 = 0.00045308 loss)
I0526 17:29:25.176826 10701 sgd_solver.cpp:112] Iteration 19698, lr = 0.0025
I0526 17:29:58.322993 10701 solver.cpp:239] Iteration 19747 (1.47831 iter/s, 33.146s/49 iters), loss = 0.00911067
I0526 17:29:58.323194 10701 solver.cpp:258]     Train net output #0: loss = 0.00942337 (* 1 = 0.00942337 loss)
I0526 17:29:58.323204 10701 sgd_solver.cpp:112] Iteration 19747, lr = 0.0025
I0526 17:30:30.560400 10701 solver.cpp:239] Iteration 19796 (1.51999 iter/s, 32.237s/49 iters), loss = 0.0122102
I0526 17:30:30.560693 10701 solver.cpp:258]     Train net output #0: loss = 0.021805 (* 1 = 0.021805 loss)
I0526 17:30:30.560703 10701 sgd_solver.cpp:112] Iteration 19796, lr = 0.0025
I0526 17:31:05.581562 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_19845.caffemodel
I0526 17:31:05.582543 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_19845.solverstate
I0526 17:31:05.582881 10701 solver.cpp:347] Iteration 19845, Testing net (#0)
I0526 17:31:17.903368 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8352
I0526 17:31:17.903415 10701 solver.cpp:414]     Test net output #1: loss = 0.428177 (* 1 = 0.428177 loss)
I0526 17:31:17.903421 10701 solver.cpp:347] Iteration 19845, Testing net (#1)
I0526 17:31:41.735118 10701 solver.cpp:414]     Test net output #0: accuracy = 0.999149
I0526 17:31:41.735278 10701 solver.cpp:414]     Test net output #1: loss = 0.0049184 (* 1 = 0.0049184 loss)
I0526 17:31:41.735297 10701 solver.cpp:347] Iteration 19845, Testing net (#2)
I0526 17:32:34.262382 10701 solver.cpp:414]     Test net output #0: accuracy = 0.878378
I0526 17:32:34.262579 10701 solver.cpp:414]     Test net output #1: loss = 0.310978 (* 1 = 0.310978 loss)
I0526 17:32:34.902469 10701 solver.cpp:239] Iteration 19845 (0.394078 iter/s, 124.341s/49 iters), loss = 0.00808704
I0526 17:32:34.902523 10701 solver.cpp:258]     Train net output #0: loss = 0.000390819 (* 1 = 0.000390819 loss)
I0526 17:32:34.902531 10701 sgd_solver.cpp:112] Iteration 19845, lr = 0.0025
I0526 17:33:06.304805 10701 solver.cpp:239] Iteration 19894 (1.56041 iter/s, 31.402s/49 iters), loss = 0.00280187
I0526 17:33:06.305011 10701 solver.cpp:258]     Train net output #0: loss = 0.00388883 (* 1 = 0.00388883 loss)
I0526 17:33:06.305022 10701 sgd_solver.cpp:112] Iteration 19894, lr = 0.0025
I0526 17:33:40.870980 10701 solver.cpp:239] Iteration 19943 (1.41762 iter/s, 34.565s/49 iters), loss = 0.00513174
I0526 17:33:40.871199 10701 solver.cpp:258]     Train net output #0: loss = 0.000865713 (* 1 = 0.000865713 loss)
I0526 17:33:40.871209 10701 sgd_solver.cpp:112] Iteration 19943, lr = 0.0025
I0526 17:34:15.309651 10701 solver.cpp:239] Iteration 19992 (1.42285 iter/s, 34.438s/49 iters), loss = 0.00801161
I0526 17:34:15.309767 10701 solver.cpp:258]     Train net output #0: loss = 0.00190903 (* 1 = 0.00190903 loss)
I0526 17:34:15.309777 10701 sgd_solver.cpp:112] Iteration 19992, lr = 0.0025
I0526 17:34:47.922585 10701 solver.cpp:239] Iteration 20041 (1.50251 iter/s, 32.612s/49 iters), loss = 0.0031604
I0526 17:34:47.922744 10701 solver.cpp:258]     Train net output #0: loss = 0.00444971 (* 1 = 0.00444971 loss)
I0526 17:34:47.922753 10701 sgd_solver.cpp:112] Iteration 20041, lr = 0.0025
I0526 17:35:22.976089 10701 solver.cpp:239] Iteration 20090 (1.39788 iter/s, 35.053s/49 iters), loss = 0.00500773
I0526 17:35:22.976246 10701 solver.cpp:258]     Train net output #0: loss = 0.00635253 (* 1 = 0.00635253 loss)
I0526 17:35:22.976264 10701 sgd_solver.cpp:112] Iteration 20090, lr = 0.0025
I0526 17:35:57.870002 10701 solver.cpp:239] Iteration 20139 (1.40429 iter/s, 34.893s/49 iters), loss = 0.00687835
I0526 17:35:57.870131 10701 solver.cpp:258]     Train net output #0: loss = 0.00030732 (* 1 = 0.00030732 loss)
I0526 17:35:57.870151 10701 sgd_solver.cpp:112] Iteration 20139, lr = 0.0025
I0526 17:36:33.049933 10701 solver.cpp:239] Iteration 20188 (1.39288 iter/s, 35.179s/49 iters), loss = 0.00763475
I0526 17:36:33.050146 10701 solver.cpp:258]     Train net output #0: loss = 0.000389274 (* 1 = 0.000389274 loss)
I0526 17:36:33.050158 10701 sgd_solver.cpp:112] Iteration 20188, lr = 0.0025
I0526 17:37:06.183125 10701 solver.cpp:239] Iteration 20237 (1.47893 iter/s, 33.132s/49 iters), loss = 0.00409248
I0526 17:37:06.183302 10701 solver.cpp:258]     Train net output #0: loss = 0.0025791 (* 1 = 0.0025791 loss)
I0526 17:37:06.183312 10701 sgd_solver.cpp:112] Iteration 20237, lr = 0.0025
I0526 17:37:39.944739 10701 solver.cpp:239] Iteration 20286 (1.45138 iter/s, 33.761s/49 iters), loss = 0.00920378
I0526 17:37:39.944928 10701 solver.cpp:258]     Train net output #0: loss = 0.0114096 (* 1 = 0.0114096 loss)
I0526 17:37:39.944939 10701 sgd_solver.cpp:112] Iteration 20286, lr = 0.0025
I0526 17:38:13.918988 10701 solver.cpp:239] Iteration 20335 (1.44228 iter/s, 33.974s/49 iters), loss = 0.00544595
I0526 17:38:13.919171 10701 solver.cpp:258]     Train net output #0: loss = 0.00039988 (* 1 = 0.00039988 loss)
I0526 17:38:13.919180 10701 sgd_solver.cpp:112] Iteration 20335, lr = 0.0025
I0526 17:38:46.959398 10701 solver.cpp:239] Iteration 20384 (1.48305 iter/s, 33.04s/49 iters), loss = 0.00845885
I0526 17:38:46.959563 10701 solver.cpp:258]     Train net output #0: loss = 0.00697633 (* 1 = 0.00697633 loss)
I0526 17:38:46.959574 10701 sgd_solver.cpp:112] Iteration 20384, lr = 0.0025
I0526 17:39:22.017524 10701 solver.cpp:239] Iteration 20433 (1.39772 iter/s, 35.057s/49 iters), loss = 0.00293724
I0526 17:39:22.017632 10701 solver.cpp:258]     Train net output #0: loss = 0.0011137 (* 1 = 0.0011137 loss)
I0526 17:39:22.017642 10701 sgd_solver.cpp:112] Iteration 20433, lr = 0.0025
I0526 17:40:00.159620 10701 solver.cpp:239] Iteration 20482 (1.28471 iter/s, 38.141s/49 iters), loss = 0.010559
I0526 17:40:00.159790 10701 solver.cpp:258]     Train net output #0: loss = 0.0028341 (* 1 = 0.0028341 loss)
I0526 17:40:00.159798 10701 sgd_solver.cpp:112] Iteration 20482, lr = 0.0025
I0526 17:40:37.575489 10701 solver.cpp:239] Iteration 20531 (1.30964 iter/s, 37.415s/49 iters), loss = 0.00747282
I0526 17:40:37.575644 10701 solver.cpp:258]     Train net output #0: loss = 0.00325805 (* 1 = 0.00325805 loss)
I0526 17:40:37.575654 10701 sgd_solver.cpp:112] Iteration 20531, lr = 0.0025
I0526 17:41:09.256791 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_20580.caffemodel
I0526 17:41:09.257660 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_20580.solverstate
I0526 17:41:09.257993 10701 solver.cpp:347] Iteration 20580, Testing net (#0)
I0526 17:41:22.226871 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8704
I0526 17:41:22.226920 10701 solver.cpp:414]     Test net output #1: loss = 0.323386 (* 1 = 0.323386 loss)
I0526 17:41:22.226925 10701 solver.cpp:347] Iteration 20580, Testing net (#1)
I0526 17:41:46.866032 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998511
I0526 17:41:46.866163 10701 solver.cpp:414]     Test net output #1: loss = 0.00627532 (* 1 = 0.00627532 loss)
I0526 17:41:46.866173 10701 solver.cpp:347] Iteration 20580, Testing net (#2)
I0526 17:42:41.200269 10701 solver.cpp:414]     Test net output #0: accuracy = 0.904234
I0526 17:42:41.200445 10701 solver.cpp:414]     Test net output #1: loss = 0.215415 (* 1 = 0.215415 loss)
I0526 17:42:41.884289 10701 solver.cpp:239] Iteration 20580 (0.394182 iter/s, 124.308s/49 iters), loss = 0.00467328
I0526 17:42:41.884362 10701 solver.cpp:258]     Train net output #0: loss = 0.00119064 (* 1 = 0.00119064 loss)
I0526 17:42:41.884382 10701 sgd_solver.cpp:112] Iteration 20580, lr = 0.0025
I0526 17:43:16.637481 10701 solver.cpp:239] Iteration 20629 (1.40995 iter/s, 34.753s/49 iters), loss = 0.00692458
I0526 17:43:16.637631 10701 solver.cpp:258]     Train net output #0: loss = 0.000367295 (* 1 = 0.000367295 loss)
I0526 17:43:16.637650 10701 sgd_solver.cpp:112] Iteration 20629, lr = 0.0025
I0526 17:43:51.297075 10701 solver.cpp:239] Iteration 20678 (1.41377 iter/s, 34.659s/49 iters), loss = 0.00431985
I0526 17:43:51.297216 10701 solver.cpp:258]     Train net output #0: loss = 0.00151419 (* 1 = 0.00151419 loss)
I0526 17:43:51.297226 10701 sgd_solver.cpp:112] Iteration 20678, lr = 0.0025
I0526 17:44:26.342712 10701 solver.cpp:239] Iteration 20727 (1.3982 iter/s, 35.045s/49 iters), loss = 0.0111296
I0526 17:44:26.342919 10701 solver.cpp:258]     Train net output #0: loss = 0.0266044 (* 1 = 0.0266044 loss)
I0526 17:44:26.342941 10701 sgd_solver.cpp:112] Iteration 20727, lr = 0.0025
I0526 17:44:58.519301 10701 solver.cpp:239] Iteration 20776 (1.52287 iter/s, 32.176s/49 iters), loss = 0.00386616
I0526 17:44:58.519480 10701 solver.cpp:258]     Train net output #0: loss = 0.00114853 (* 1 = 0.00114853 loss)
I0526 17:44:58.519491 10701 sgd_solver.cpp:112] Iteration 20776, lr = 0.0025
I0526 17:45:29.927390 10701 solver.cpp:239] Iteration 20825 (1.56016 iter/s, 31.407s/49 iters), loss = 0.00369977
I0526 17:45:29.927515 10701 solver.cpp:258]     Train net output #0: loss = 0.000415325 (* 1 = 0.000415325 loss)
I0526 17:45:29.927533 10701 sgd_solver.cpp:112] Iteration 20825, lr = 0.0025
I0526 17:46:01.345119 10701 solver.cpp:239] Iteration 20874 (1.55967 iter/s, 31.417s/49 iters), loss = 0.00861117
I0526 17:46:01.345299 10701 solver.cpp:258]     Train net output #0: loss = 0.000894652 (* 1 = 0.000894652 loss)
I0526 17:46:01.345309 10701 sgd_solver.cpp:112] Iteration 20874, lr = 0.0025
I0526 17:46:32.760385 10701 solver.cpp:239] Iteration 20923 (1.55976 iter/s, 31.415s/49 iters), loss = 0.00463734
I0526 17:46:32.760593 10701 solver.cpp:258]     Train net output #0: loss = 0.00104989 (* 1 = 0.00104989 loss)
I0526 17:46:32.760603 10701 sgd_solver.cpp:112] Iteration 20923, lr = 0.0025
I0526 17:47:04.338368 10701 solver.cpp:239] Iteration 20972 (1.55176 iter/s, 31.577s/49 iters), loss = 0.00614514
I0526 17:47:04.338575 10701 solver.cpp:258]     Train net output #0: loss = 0.000883415 (* 1 = 0.000883415 loss)
I0526 17:47:04.338585 10701 sgd_solver.cpp:112] Iteration 20972, lr = 0.0025
I0526 17:47:35.759871 10701 solver.cpp:239] Iteration 21021 (1.55947 iter/s, 31.421s/49 iters), loss = 0.00515906
I0526 17:47:35.760035 10701 solver.cpp:258]     Train net output #0: loss = 0.000567952 (* 1 = 0.000567952 loss)
I0526 17:47:35.760046 10701 sgd_solver.cpp:112] Iteration 21021, lr = 0.0025
I0526 17:48:07.555598 10701 solver.cpp:239] Iteration 21070 (1.54112 iter/s, 31.795s/49 iters), loss = 0.00655038
I0526 17:48:07.555838 10701 solver.cpp:258]     Train net output #0: loss = 0.000523519 (* 1 = 0.000523519 loss)
I0526 17:48:07.555848 10701 sgd_solver.cpp:112] Iteration 21070, lr = 0.0025
I0526 17:48:39.071797 10701 solver.cpp:239] Iteration 21119 (1.55482 iter/s, 31.515s/49 iters), loss = 0.0123253
I0526 17:48:39.071977 10701 solver.cpp:258]     Train net output #0: loss = 0.00425965 (* 1 = 0.00425965 loss)
I0526 17:48:39.071987 10701 sgd_solver.cpp:112] Iteration 21119, lr = 0.0025
I0526 17:49:10.560871 10701 solver.cpp:239] Iteration 21168 (1.55615 iter/s, 31.488s/49 iters), loss = 0.00442507
I0526 17:49:10.561035 10701 solver.cpp:258]     Train net output #0: loss = 0.038372 (* 1 = 0.038372 loss)
I0526 17:49:10.561045 10701 sgd_solver.cpp:112] Iteration 21168, lr = 0.0025
I0526 17:49:42.371901 10701 solver.cpp:239] Iteration 21217 (1.5404 iter/s, 31.81s/49 iters), loss = 0.00612677
I0526 17:49:42.372103 10701 solver.cpp:258]     Train net output #0: loss = 0.0022455 (* 1 = 0.0022455 loss)
I0526 17:49:42.372114 10701 sgd_solver.cpp:112] Iteration 21217, lr = 0.0025
I0526 17:50:14.398700 10701 solver.cpp:239] Iteration 21266 (1.53001 iter/s, 32.026s/49 iters), loss = 0.00558273
I0526 17:50:14.398872 10701 solver.cpp:258]     Train net output #0: loss = 0.00759462 (* 1 = 0.00759462 loss)
I0526 17:50:14.398882 10701 sgd_solver.cpp:112] Iteration 21266, lr = 0.0025
I0526 17:50:45.580842 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_21315.caffemodel
I0526 17:50:45.581768 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_21315.solverstate
I0526 17:50:45.582098 10701 solver.cpp:347] Iteration 21315, Testing net (#0)
I0526 17:50:57.232168 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8424
I0526 17:50:57.232214 10701 solver.cpp:414]     Test net output #1: loss = 0.411399 (* 1 = 0.411399 loss)
I0526 17:50:57.232221 10701 solver.cpp:347] Iteration 21315, Testing net (#1)
I0526 17:51:19.356644 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998085
I0526 17:51:19.356868 10701 solver.cpp:414]     Test net output #1: loss = 0.00559224 (* 1 = 0.00559224 loss)
I0526 17:51:19.356878 10701 solver.cpp:347] Iteration 21315, Testing net (#2)
I0526 17:52:10.568833 10701 solver.cpp:414]     Test net output #0: accuracy = 0.877748
I0526 17:52:10.569033 10701 solver.cpp:414]     Test net output #1: loss = 0.299224 (* 1 = 0.299224 loss)
I0526 17:52:11.208912 10701 solver.cpp:239] Iteration 21315 (0.419485 iter/s, 116.81s/49 iters), loss = 0.00437235
I0526 17:52:11.208966 10701 solver.cpp:258]     Train net output #0: loss = 0.0391584 (* 1 = 0.0391584 loss)
I0526 17:52:11.208976 10701 sgd_solver.cpp:112] Iteration 21315, lr = 0.0025
I0526 17:52:42.636245 10701 solver.cpp:239] Iteration 21364 (1.55917 iter/s, 31.427s/49 iters), loss = 0.00507008
I0526 17:52:42.636401 10701 solver.cpp:258]     Train net output #0: loss = 0.00103864 (* 1 = 0.00103864 loss)
I0526 17:52:42.636410 10701 sgd_solver.cpp:112] Iteration 21364, lr = 0.0025
I0526 17:53:14.191581 10701 solver.cpp:239] Iteration 21413 (1.55284 iter/s, 31.555s/49 iters), loss = 0.00413667
I0526 17:53:14.191812 10701 solver.cpp:258]     Train net output #0: loss = 0.000881528 (* 1 = 0.000881528 loss)
I0526 17:53:14.191823 10701 sgd_solver.cpp:112] Iteration 21413, lr = 0.0025
I0526 17:53:46.073158 10701 solver.cpp:239] Iteration 21462 (1.53697 iter/s, 31.881s/49 iters), loss = 0.01122
I0526 17:53:46.073329 10701 solver.cpp:258]     Train net output #0: loss = 0.000486272 (* 1 = 0.000486272 loss)
I0526 17:53:46.073339 10701 sgd_solver.cpp:112] Iteration 21462, lr = 0.0025
I0526 17:54:17.963764 10701 solver.cpp:239] Iteration 21511 (1.53653 iter/s, 31.89s/49 iters), loss = 0.0033867
I0526 17:54:17.963922 10701 solver.cpp:258]     Train net output #0: loss = 0.000316466 (* 1 = 0.000316466 loss)
I0526 17:54:17.963932 10701 sgd_solver.cpp:112] Iteration 21511, lr = 0.0025
I0526 17:54:49.779892 10701 solver.cpp:239] Iteration 21560 (1.54015 iter/s, 31.815s/49 iters), loss = 0.00347835
I0526 17:54:49.780074 10701 solver.cpp:258]     Train net output #0: loss = 0.000533532 (* 1 = 0.000533532 loss)
I0526 17:54:49.780084 10701 sgd_solver.cpp:112] Iteration 21560, lr = 0.0025
I0526 17:55:21.664353 10701 solver.cpp:239] Iteration 21609 (1.53682 iter/s, 31.884s/49 iters), loss = 0.0076512
I0526 17:55:21.664537 10701 solver.cpp:258]     Train net output #0: loss = 0.00853934 (* 1 = 0.00853934 loss)
I0526 17:55:21.664547 10701 sgd_solver.cpp:112] Iteration 21609, lr = 0.0025
I0526 17:55:53.525578 10701 solver.cpp:239] Iteration 21658 (1.53793 iter/s, 31.861s/49 iters), loss = 0.00150918
I0526 17:55:53.525763 10701 solver.cpp:258]     Train net output #0: loss = 0.000469318 (* 1 = 0.000469318 loss)
I0526 17:55:53.525772 10701 sgd_solver.cpp:112] Iteration 21658, lr = 0.0025
I0526 17:56:25.343516 10701 solver.cpp:239] Iteration 21707 (1.54006 iter/s, 31.817s/49 iters), loss = 0.00632959
I0526 17:56:25.343652 10701 solver.cpp:258]     Train net output #0: loss = 0.000296415 (* 1 = 0.000296415 loss)
I0526 17:56:25.343672 10701 sgd_solver.cpp:112] Iteration 21707, lr = 0.0025
I0526 17:56:57.263541 10701 solver.cpp:239] Iteration 21756 (1.53514 iter/s, 31.919s/49 iters), loss = 0.00484813
I0526 17:56:57.263698 10701 solver.cpp:258]     Train net output #0: loss = 0.00345546 (* 1 = 0.00345546 loss)
I0526 17:56:57.263707 10701 sgd_solver.cpp:112] Iteration 21756, lr = 0.0025
I0526 17:57:29.052384 10701 solver.cpp:239] Iteration 21805 (1.54146 iter/s, 31.788s/49 iters), loss = 0.00801236
I0526 17:57:29.052537 10701 solver.cpp:258]     Train net output #0: loss = 0.000337532 (* 1 = 0.000337532 loss)
I0526 17:57:29.052546 10701 sgd_solver.cpp:112] Iteration 21805, lr = 0.0025
I0526 17:58:00.864320 10701 solver.cpp:239] Iteration 21854 (1.54035 iter/s, 31.811s/49 iters), loss = 0.00924587
I0526 17:58:00.864478 10701 solver.cpp:258]     Train net output #0: loss = 0.00161055 (* 1 = 0.00161055 loss)
I0526 17:58:00.864487 10701 sgd_solver.cpp:112] Iteration 21854, lr = 0.0025
I0526 17:58:32.634512 10701 solver.cpp:239] Iteration 21903 (1.54234 iter/s, 31.77s/49 iters), loss = 0.00257088
I0526 17:58:32.634657 10701 solver.cpp:258]     Train net output #0: loss = 0.00585318 (* 1 = 0.00585318 loss)
I0526 17:58:32.634667 10701 sgd_solver.cpp:112] Iteration 21903, lr = 0.0025
I0526 17:59:04.435739 10701 solver.cpp:239] Iteration 21952 (1.54083 iter/s, 31.801s/49 iters), loss = 0.00462141
I0526 17:59:04.435869 10701 solver.cpp:258]     Train net output #0: loss = 0.000960002 (* 1 = 0.000960002 loss)
I0526 17:59:04.435889 10701 sgd_solver.cpp:112] Iteration 21952, lr = 0.0025
I0526 17:59:36.239468 10701 solver.cpp:239] Iteration 22001 (1.54074 iter/s, 31.803s/49 iters), loss = 0.00550748
I0526 17:59:36.239652 10701 solver.cpp:258]     Train net output #0: loss = 0.000314347 (* 1 = 0.000314347 loss)
I0526 17:59:36.239662 10701 sgd_solver.cpp:112] Iteration 22001, lr = 0.0025
I0526 18:00:07.446646 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_22050.caffemodel
I0526 18:00:07.447482 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_22050.solverstate
I0526 18:00:07.447824 10701 solver.cpp:347] Iteration 22050, Testing net (#0)
I0526 18:00:19.110834 10701 solver.cpp:414]     Test net output #0: accuracy = 0.9144
I0526 18:00:19.110882 10701 solver.cpp:414]     Test net output #1: loss = 0.214285 (* 1 = 0.214285 loss)
I0526 18:00:19.110888 10701 solver.cpp:347] Iteration 22050, Testing net (#1)
I0526 18:00:41.197311 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998085
I0526 18:00:41.197492 10701 solver.cpp:414]     Test net output #1: loss = 0.00617605 (* 1 = 0.00617605 loss)
I0526 18:00:41.197500 10701 solver.cpp:347] Iteration 22050, Testing net (#2)
I0526 18:01:32.657188 10701 solver.cpp:414]     Test net output #0: accuracy = 0.908919
I0526 18:01:32.657331 10701 solver.cpp:414]     Test net output #1: loss = 0.215932 (* 1 = 0.215932 loss)
I0526 18:01:33.305577 10701 solver.cpp:239] Iteration 22050 (0.418571 iter/s, 117.065s/49 iters), loss = 0.0062183
I0526 18:01:33.305631 10701 solver.cpp:258]     Train net output #0: loss = 0.00879986 (* 1 = 0.00879986 loss)
I0526 18:01:33.305639 10701 sgd_solver.cpp:112] Iteration 22050, lr = 0.0025
I0526 18:02:05.312386 10701 solver.cpp:239] Iteration 22099 (1.53096 iter/s, 32.006s/49 iters), loss = 0.00206308
I0526 18:02:05.312613 10701 solver.cpp:258]     Train net output #0: loss = 0.000432175 (* 1 = 0.000432175 loss)
I0526 18:02:05.312623 10701 sgd_solver.cpp:112] Iteration 22099, lr = 0.0025
I0526 18:02:37.216977 10701 solver.cpp:239] Iteration 22148 (1.53586 iter/s, 31.904s/49 iters), loss = 0.00372728
I0526 18:02:37.217106 10701 solver.cpp:258]     Train net output #0: loss = 0.0123385 (* 1 = 0.0123385 loss)
I0526 18:02:37.217116 10701 sgd_solver.cpp:112] Iteration 22148, lr = 0.0025
I0526 18:03:09.228770 10701 solver.cpp:239] Iteration 22197 (1.53072 iter/s, 32.011s/49 iters), loss = 0.00594583
I0526 18:03:09.228982 10701 solver.cpp:258]     Train net output #0: loss = 0.000414002 (* 1 = 0.000414002 loss)
I0526 18:03:09.228992 10701 sgd_solver.cpp:112] Iteration 22197, lr = 0.0025
I0526 18:03:41.450810 10701 solver.cpp:239] Iteration 22246 (1.52075 iter/s, 32.221s/49 iters), loss = 0.004982
I0526 18:03:41.451050 10701 solver.cpp:258]     Train net output #0: loss = 0.00118907 (* 1 = 0.00118907 loss)
I0526 18:03:41.451061 10701 sgd_solver.cpp:112] Iteration 22246, lr = 0.0025
I0526 18:04:13.681262 10701 solver.cpp:239] Iteration 22295 (1.52032 iter/s, 32.23s/49 iters), loss = 0.0113546
I0526 18:04:13.681421 10701 solver.cpp:258]     Train net output #0: loss = 0.000888574 (* 1 = 0.000888574 loss)
I0526 18:04:13.681430 10701 sgd_solver.cpp:112] Iteration 22295, lr = 0.0025
I0526 18:04:45.897426 10701 solver.cpp:239] Iteration 22344 (1.52098 iter/s, 32.216s/49 iters), loss = 0.00721688
I0526 18:04:45.897606 10701 solver.cpp:258]     Train net output #0: loss = 0.00395447 (* 1 = 0.00395447 loss)
I0526 18:04:45.897617 10701 sgd_solver.cpp:112] Iteration 22344, lr = 0.0025
I0526 18:05:17.885150 10701 solver.cpp:239] Iteration 22393 (1.53187 iter/s, 31.987s/49 iters), loss = 0.00444195
I0526 18:05:17.885376 10701 solver.cpp:258]     Train net output #0: loss = 0.00130926 (* 1 = 0.00130926 loss)
I0526 18:05:17.885387 10701 sgd_solver.cpp:112] Iteration 22393, lr = 0.0025
I0526 18:05:49.751046 10701 solver.cpp:239] Iteration 22442 (1.53774 iter/s, 31.865s/49 iters), loss = 0.0022371
I0526 18:05:49.751196 10701 solver.cpp:258]     Train net output #0: loss = 0.00018265 (* 1 = 0.00018265 loss)
I0526 18:05:49.751206 10701 sgd_solver.cpp:112] Iteration 22442, lr = 0.0025
I0526 18:06:21.703431 10701 solver.cpp:239] Iteration 22491 (1.53355 iter/s, 31.952s/49 iters), loss = 0.00878154
I0526 18:06:21.703680 10701 solver.cpp:258]     Train net output #0: loss = 0.00529234 (* 1 = 0.00529234 loss)
I0526 18:06:21.703691 10701 sgd_solver.cpp:112] Iteration 22491, lr = 0.0025
I0526 18:06:53.934607 10701 solver.cpp:239] Iteration 22540 (1.52032 iter/s, 32.23s/49 iters), loss = 0.00645503
I0526 18:06:53.934743 10701 solver.cpp:258]     Train net output #0: loss = 0.000365336 (* 1 = 0.000365336 loss)
I0526 18:06:53.934756 10701 sgd_solver.cpp:112] Iteration 22540, lr = 0.0025
I0526 18:07:26.222793 10701 solver.cpp:239] Iteration 22589 (1.51759 iter/s, 32.288s/49 iters), loss = 0.00418203
I0526 18:07:26.223052 10701 solver.cpp:258]     Train net output #0: loss = 0.000811332 (* 1 = 0.000811332 loss)
I0526 18:07:26.223062 10701 sgd_solver.cpp:112] Iteration 22589, lr = 0.0025
I0526 18:07:58.464422 10701 solver.cpp:239] Iteration 22638 (1.5198 iter/s, 32.241s/49 iters), loss = 0.00936834
I0526 18:07:58.464606 10701 solver.cpp:258]     Train net output #0: loss = 0.00185819 (* 1 = 0.00185819 loss)
I0526 18:07:58.464614 10701 sgd_solver.cpp:112] Iteration 22638, lr = 0.0025
I0526 18:08:30.685003 10701 solver.cpp:239] Iteration 22687 (1.52079 iter/s, 32.22s/49 iters), loss = 0.00782414
I0526 18:08:30.685178 10701 solver.cpp:258]     Train net output #0: loss = 0.000747937 (* 1 = 0.000747937 loss)
I0526 18:08:30.685189 10701 sgd_solver.cpp:112] Iteration 22687, lr = 0.0025
I0526 18:09:02.939604 10701 solver.cpp:239] Iteration 22736 (1.51919 iter/s, 32.254s/49 iters), loss = 0.00574349
I0526 18:09:02.939764 10701 solver.cpp:258]     Train net output #0: loss = 0.0792928 (* 1 = 0.0792928 loss)
I0526 18:09:02.939774 10701 sgd_solver.cpp:112] Iteration 22736, lr = 0.0025
I0526 18:09:34.359722 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_22785.caffemodel
I0526 18:09:34.360700 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_22785.solverstate
I0526 18:09:34.361047 10701 solver.cpp:347] Iteration 22785, Testing net (#0)
I0526 18:09:46.271407 10701 solver.cpp:414]     Test net output #0: accuracy = 0.9228
I0526 18:09:46.271452 10701 solver.cpp:414]     Test net output #1: loss = 0.204563 (* 1 = 0.204563 loss)
I0526 18:09:46.271458 10701 solver.cpp:347] Iteration 22785, Testing net (#1)
I0526 18:10:08.614388 10701 solver.cpp:414]     Test net output #0: accuracy = 0.999574
I0526 18:10:08.614614 10701 solver.cpp:414]     Test net output #1: loss = 0.00227056 (* 1 = 0.00227056 loss)
I0526 18:10:08.614622 10701 solver.cpp:347] Iteration 22785, Testing net (#2)
I0526 18:11:00.581266 10701 solver.cpp:414]     Test net output #0: accuracy = 0.936577
I0526 18:11:00.581471 10701 solver.cpp:414]     Test net output #1: loss = 0.153471 (* 1 = 0.153471 loss)
I0526 18:11:01.241730 10701 solver.cpp:239] Iteration 22785 (0.414198 iter/s, 118.301s/49 iters), loss = 0.00376282
I0526 18:11:01.241787 10701 solver.cpp:258]     Train net output #0: loss = 0.000306121 (* 1 = 0.000306121 loss)
I0526 18:11:01.241796 10701 sgd_solver.cpp:112] Iteration 22785, lr = 0.0025
I0526 18:11:33.106472 10701 solver.cpp:239] Iteration 22834 (1.53779 iter/s, 31.864s/49 iters), loss = 0.00735555
I0526 18:11:33.106623 10701 solver.cpp:258]     Train net output #0: loss = 0.00104952 (* 1 = 0.00104952 loss)
I0526 18:11:33.106632 10701 sgd_solver.cpp:112] Iteration 22834, lr = 0.0025
I0526 18:12:05.049645 10701 solver.cpp:239] Iteration 22883 (1.53398 iter/s, 31.943s/49 iters), loss = 0.00264869
I0526 18:12:05.049875 10701 solver.cpp:258]     Train net output #0: loss = 0.000555916 (* 1 = 0.000555916 loss)
I0526 18:12:05.049885 10701 sgd_solver.cpp:112] Iteration 22883, lr = 0.0025
I0526 18:12:36.922793 10701 solver.cpp:239] Iteration 22932 (1.5374 iter/s, 31.872s/49 iters), loss = 0.00221414
I0526 18:12:36.923049 10701 solver.cpp:258]     Train net output #0: loss = 0.000126559 (* 1 = 0.000126559 loss)
I0526 18:12:36.923060 10701 sgd_solver.cpp:112] Iteration 22932, lr = 0.0025
I0526 18:13:08.801646 10701 solver.cpp:239] Iteration 22981 (1.53711 iter/s, 31.878s/49 iters), loss = 0.00678446
I0526 18:13:08.801887 10701 solver.cpp:258]     Train net output #0: loss = 0.000505212 (* 1 = 0.000505212 loss)
I0526 18:13:08.801898 10701 sgd_solver.cpp:112] Iteration 22981, lr = 0.0025
I0526 18:13:40.626487 10701 solver.cpp:239] Iteration 23030 (1.53972 iter/s, 31.824s/49 iters), loss = 0.00351826
I0526 18:13:40.626698 10701 solver.cpp:258]     Train net output #0: loss = 0.00716458 (* 1 = 0.00716458 loss)
I0526 18:13:40.626708 10701 sgd_solver.cpp:112] Iteration 23030, lr = 0.0025
I0526 18:14:12.541388 10701 solver.cpp:239] Iteration 23079 (1.53538 iter/s, 31.914s/49 iters), loss = 0.00821702
I0526 18:14:12.541576 10701 solver.cpp:258]     Train net output #0: loss = 0.00739508 (* 1 = 0.00739508 loss)
I0526 18:14:12.541585 10701 sgd_solver.cpp:112] Iteration 23079, lr = 0.0025
I0526 18:14:44.376027 10701 solver.cpp:239] Iteration 23128 (1.53923 iter/s, 31.834s/49 iters), loss = 0.00666184
I0526 18:14:44.376194 10701 solver.cpp:258]     Train net output #0: loss = 0.000712746 (* 1 = 0.000712746 loss)
I0526 18:14:44.376204 10701 sgd_solver.cpp:112] Iteration 23128, lr = 0.0025
I0526 18:15:16.245733 10701 solver.cpp:239] Iteration 23177 (1.53754 iter/s, 31.869s/49 iters), loss = 0.00994217
I0526 18:15:16.245890 10701 solver.cpp:258]     Train net output #0: loss = 0.00116314 (* 1 = 0.00116314 loss)
I0526 18:15:16.245900 10701 sgd_solver.cpp:112] Iteration 23177, lr = 0.0025
I0526 18:15:48.390731 10701 solver.cpp:239] Iteration 23226 (1.52439 iter/s, 32.144s/49 iters), loss = 0.00897168
I0526 18:15:48.390959 10701 solver.cpp:258]     Train net output #0: loss = 0.000450968 (* 1 = 0.000450968 loss)
I0526 18:15:48.390969 10701 sgd_solver.cpp:112] Iteration 23226, lr = 0.0025
I0526 18:16:20.263206 10701 solver.cpp:239] Iteration 23275 (1.5374 iter/s, 31.872s/49 iters), loss = 0.00614301
I0526 18:16:20.263447 10701 solver.cpp:258]     Train net output #0: loss = 0.00147678 (* 1 = 0.00147678 loss)
I0526 18:16:20.263458 10701 sgd_solver.cpp:112] Iteration 23275, lr = 0.0025
I0526 18:16:52.206230 10701 solver.cpp:239] Iteration 23324 (1.53403 iter/s, 31.942s/49 iters), loss = 0.00411122
I0526 18:16:52.206463 10701 solver.cpp:258]     Train net output #0: loss = 0.000280544 (* 1 = 0.000280544 loss)
I0526 18:16:52.206473 10701 sgd_solver.cpp:112] Iteration 23324, lr = 0.0025
I0526 18:17:24.065542 10701 solver.cpp:239] Iteration 23373 (1.53803 iter/s, 31.859s/49 iters), loss = 0.00453943
I0526 18:17:24.065671 10701 solver.cpp:258]     Train net output #0: loss = 0.000329651 (* 1 = 0.000329651 loss)
I0526 18:17:24.065682 10701 sgd_solver.cpp:112] Iteration 23373, lr = 0.0025
I0526 18:17:55.919826 10701 solver.cpp:239] Iteration 23422 (1.53827 iter/s, 31.854s/49 iters), loss = 0.0038976
I0526 18:17:55.920006 10701 solver.cpp:258]     Train net output #0: loss = 0.00439691 (* 1 = 0.00439691 loss)
I0526 18:17:55.920015 10701 sgd_solver.cpp:112] Iteration 23422, lr = 0.0025
I0526 18:18:27.793248 10701 solver.cpp:239] Iteration 23471 (1.53735 iter/s, 31.873s/49 iters), loss = 0.00679449
I0526 18:18:27.793432 10701 solver.cpp:258]     Train net output #0: loss = 0.000474418 (* 1 = 0.000474418 loss)
I0526 18:18:27.793442 10701 sgd_solver.cpp:112] Iteration 23471, lr = 0.0025
I0526 18:18:59.128600 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_23520.caffemodel
I0526 18:18:59.129556 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_23520.solverstate
I0526 18:18:59.129894 10701 solver.cpp:347] Iteration 23520, Testing net (#0)
I0526 18:19:10.966277 10701 solver.cpp:414]     Test net output #0: accuracy = 0.9188
I0526 18:19:10.966327 10701 solver.cpp:414]     Test net output #1: loss = 0.225863 (* 1 = 0.225863 loss)
I0526 18:19:10.966333 10701 solver.cpp:347] Iteration 23520, Testing net (#1)
I0526 18:19:33.605734 10701 solver.cpp:414]     Test net output #0: accuracy = 0.999574
I0526 18:19:33.605913 10701 solver.cpp:414]     Test net output #1: loss = 0.00239785 (* 1 = 0.00239785 loss)
I0526 18:19:33.605923 10701 solver.cpp:347] Iteration 23520, Testing net (#2)
I0526 18:20:25.021095 10701 solver.cpp:414]     Test net output #0: accuracy = 0.911171
I0526 18:20:25.021282 10701 solver.cpp:414]     Test net output #1: loss = 0.225144 (* 1 = 0.225144 loss)
I0526 18:20:25.666517 10701 solver.cpp:239] Iteration 23520 (0.415702 iter/s, 117.873s/49 iters), loss = 0.00632559
I0526 18:20:25.666570 10701 solver.cpp:258]     Train net output #0: loss = 0.0009627 (* 1 = 0.0009627 loss)
I0526 18:20:25.666579 10701 sgd_solver.cpp:112] Iteration 23520, lr = 0.0025
I0526 18:20:57.103204 10701 solver.cpp:239] Iteration 23569 (1.55872 iter/s, 31.436s/49 iters), loss = 0.0123874
I0526 18:20:57.103420 10701 solver.cpp:258]     Train net output #0: loss = 0.0776145 (* 1 = 0.0776145 loss)
I0526 18:20:57.103430 10701 sgd_solver.cpp:112] Iteration 23569, lr = 0.0025
I0526 18:21:28.811887 10701 solver.cpp:239] Iteration 23618 (1.54535 iter/s, 31.708s/49 iters), loss = 0.00556528
I0526 18:21:28.812139 10701 solver.cpp:258]     Train net output #0: loss = 0.000393344 (* 1 = 0.000393344 loss)
I0526 18:21:28.812150 10701 sgd_solver.cpp:112] Iteration 23618, lr = 0.0025
I0526 18:22:00.793789 10701 solver.cpp:239] Iteration 23667 (1.53216 iter/s, 31.981s/49 iters), loss = 0.00938098
I0526 18:22:00.794023 10701 solver.cpp:258]     Train net output #0: loss = 0.00131194 (* 1 = 0.00131194 loss)
I0526 18:22:00.794034 10701 sgd_solver.cpp:112] Iteration 23667, lr = 0.0025
I0526 18:22:32.376459 10701 solver.cpp:239] Iteration 23716 (1.55152 iter/s, 31.582s/49 iters), loss = 0.00368342
I0526 18:22:32.376672 10701 solver.cpp:258]     Train net output #0: loss = 0.000649207 (* 1 = 0.000649207 loss)
I0526 18:22:32.376683 10701 sgd_solver.cpp:112] Iteration 23716, lr = 0.0025
I0526 18:23:03.820587 10701 solver.cpp:239] Iteration 23765 (1.55838 iter/s, 31.443s/49 iters), loss = 0.00291711
I0526 18:23:03.820804 10701 solver.cpp:258]     Train net output #0: loss = 0.000761069 (* 1 = 0.000761069 loss)
I0526 18:23:03.820813 10701 sgd_solver.cpp:112] Iteration 23765, lr = 0.0025
I0526 18:23:35.466071 10701 solver.cpp:239] Iteration 23814 (1.54843 iter/s, 31.645s/49 iters), loss = 0.00329803
I0526 18:23:35.466308 10701 solver.cpp:258]     Train net output #0: loss = 0.00256605 (* 1 = 0.00256605 loss)
I0526 18:23:35.466320 10701 sgd_solver.cpp:112] Iteration 23814, lr = 0.0025
I0526 18:24:07.316655 10701 solver.cpp:239] Iteration 23863 (1.53846 iter/s, 31.85s/49 iters), loss = 0.00336642
I0526 18:24:07.316948 10701 solver.cpp:258]     Train net output #0: loss = 0.00114712 (* 1 = 0.00114712 loss)
I0526 18:24:07.316958 10701 sgd_solver.cpp:112] Iteration 23863, lr = 0.0025
I0526 18:24:39.157006 10701 solver.cpp:239] Iteration 23912 (1.53894 iter/s, 31.84s/49 iters), loss = 0.00709314
I0526 18:24:39.157136 10701 solver.cpp:258]     Train net output #0: loss = 0.00124018 (* 1 = 0.00124018 loss)
I0526 18:24:39.157145 10701 sgd_solver.cpp:112] Iteration 23912, lr = 0.0025
I0526 18:25:10.999271 10701 solver.cpp:239] Iteration 23961 (1.53885 iter/s, 31.842s/49 iters), loss = 0.0104966
I0526 18:25:10.999420 10701 solver.cpp:258]     Train net output #0: loss = 0.000861151 (* 1 = 0.000861151 loss)
I0526 18:25:10.999429 10701 sgd_solver.cpp:112] Iteration 23961, lr = 0.0025
I0526 18:25:42.852499 10701 solver.cpp:239] Iteration 24010 (1.53832 iter/s, 31.853s/49 iters), loss = 0.00722941
I0526 18:25:42.852689 10701 solver.cpp:258]     Train net output #0: loss = 0.000901693 (* 1 = 0.000901693 loss)
I0526 18:25:42.852699 10701 sgd_solver.cpp:112] Iteration 24010, lr = 0.0025
I0526 18:26:14.730863 10701 solver.cpp:239] Iteration 24059 (1.53711 iter/s, 31.878s/49 iters), loss = 0.00368056
I0526 18:26:14.731061 10701 solver.cpp:258]     Train net output #0: loss = 0.0021119 (* 1 = 0.0021119 loss)
I0526 18:26:14.731071 10701 sgd_solver.cpp:112] Iteration 24059, lr = 0.0025
I0526 18:26:46.624797 10701 solver.cpp:239] Iteration 24108 (1.53639 iter/s, 31.893s/49 iters), loss = 0.00478352
I0526 18:26:46.624976 10701 solver.cpp:258]     Train net output #0: loss = 0.00423011 (* 1 = 0.00423011 loss)
I0526 18:26:46.624994 10701 sgd_solver.cpp:112] Iteration 24108, lr = 0.0025
I0526 18:27:18.487506 10701 solver.cpp:239] Iteration 24157 (1.53788 iter/s, 31.862s/49 iters), loss = 0.00727301
I0526 18:27:18.487641 10701 solver.cpp:258]     Train net output #0: loss = 0.00139457 (* 1 = 0.00139457 loss)
I0526 18:27:18.487650 10701 sgd_solver.cpp:112] Iteration 24157, lr = 0.0025
I0526 18:27:50.347968 10701 solver.cpp:239] Iteration 24206 (1.53798 iter/s, 31.86s/49 iters), loss = 0.00279184
I0526 18:27:50.348146 10701 solver.cpp:258]     Train net output #0: loss = 0.00056073 (* 1 = 0.00056073 loss)
I0526 18:27:50.348165 10701 sgd_solver.cpp:112] Iteration 24206, lr = 0.0025
I0526 18:28:21.540889 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_24255.caffemodel
I0526 18:28:21.541707 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_24255.solverstate
I0526 18:28:21.542054 10701 solver.cpp:347] Iteration 24255, Testing net (#0)
I0526 18:28:33.377930 10701 solver.cpp:414]     Test net output #0: accuracy = 0.87
I0526 18:28:33.377975 10701 solver.cpp:414]     Test net output #1: loss = 0.301212 (* 1 = 0.301212 loss)
I0526 18:28:33.377981 10701 solver.cpp:347] Iteration 24255, Testing net (#1)
I0526 18:28:55.884788 10701 solver.cpp:414]     Test net output #0: accuracy = 0.999362
I0526 18:28:55.884949 10701 solver.cpp:414]     Test net output #1: loss = 0.00196149 (* 1 = 0.00196149 loss)
I0526 18:28:55.884968 10701 solver.cpp:347] Iteration 24255, Testing net (#2)
I0526 18:29:48.224925 10701 solver.cpp:414]     Test net output #0: accuracy = 0.902973
I0526 18:29:48.225081 10701 solver.cpp:414]     Test net output #1: loss = 0.21782 (* 1 = 0.21782 loss)
I0526 18:29:48.878131 10701 solver.cpp:239] Iteration 24255 (0.413401 iter/s, 118.529s/49 iters), loss = 0.00517841
I0526 18:29:48.878187 10701 solver.cpp:258]     Train net output #0: loss = 0.000658632 (* 1 = 0.000658632 loss)
I0526 18:29:48.878196 10701 sgd_solver.cpp:112] Iteration 24255, lr = 0.0025
I0526 18:30:21.016353 10701 solver.cpp:239] Iteration 24304 (1.52467 iter/s, 32.138s/49 iters), loss = 0.00591256
I0526 18:30:21.016551 10701 solver.cpp:258]     Train net output #0: loss = 0.000464153 (* 1 = 0.000464153 loss)
I0526 18:30:21.016562 10701 sgd_solver.cpp:112] Iteration 24304, lr = 0.0025
I0526 18:30:52.940954 10701 solver.cpp:239] Iteration 24353 (1.5349 iter/s, 31.924s/49 iters), loss = 0.00702129
I0526 18:30:52.941170 10701 solver.cpp:258]     Train net output #0: loss = 0.00199168 (* 1 = 0.00199168 loss)
I0526 18:30:52.941180 10701 sgd_solver.cpp:112] Iteration 24353, lr = 0.0025
I0526 18:31:24.913167 10701 solver.cpp:239] Iteration 24402 (1.53259 iter/s, 31.972s/49 iters), loss = 0.00506809
I0526 18:31:24.913352 10701 solver.cpp:258]     Train net output #0: loss = 0.00090895 (* 1 = 0.00090895 loss)
I0526 18:31:24.913362 10701 sgd_solver.cpp:112] Iteration 24402, lr = 0.0025
I0526 18:31:56.896741 10701 solver.cpp:239] Iteration 24451 (1.53206 iter/s, 31.983s/49 iters), loss = 0.00567284
I0526 18:31:56.896879 10701 solver.cpp:258]     Train net output #0: loss = 0.00397835 (* 1 = 0.00397835 loss)
I0526 18:31:56.896909 10701 sgd_solver.cpp:112] Iteration 24451, lr = 0.0025
I0526 18:32:28.876523 10701 solver.cpp:239] Iteration 24500 (1.53226 iter/s, 31.979s/49 iters), loss = 0.00570531
I0526 18:32:28.876725 10701 solver.cpp:258]     Train net output #0: loss = 0.000545449 (* 1 = 0.000545449 loss)
I0526 18:32:28.876736 10701 sgd_solver.cpp:112] Iteration 24500, lr = 0.0025
I0526 18:33:00.906508 10701 solver.cpp:239] Iteration 24549 (1.52986 iter/s, 32.029s/49 iters), loss = 0.00355764
I0526 18:33:00.906713 10701 solver.cpp:258]     Train net output #0: loss = 0.00110922 (* 1 = 0.00110922 loss)
I0526 18:33:00.906724 10701 sgd_solver.cpp:112] Iteration 24549, lr = 0.0025
I0526 18:33:32.451508 10701 solver.cpp:239] Iteration 24598 (1.55339 iter/s, 31.544s/49 iters), loss = 0.00187433
I0526 18:33:32.451727 10701 solver.cpp:258]     Train net output #0: loss = 0.00248111 (* 1 = 0.00248111 loss)
I0526 18:33:32.451737 10701 sgd_solver.cpp:112] Iteration 24598, lr = 0.0025
I0526 18:34:03.869096 10701 solver.cpp:239] Iteration 24647 (1.55967 iter/s, 31.417s/49 iters), loss = 0.00698567
I0526 18:34:03.869235 10701 solver.cpp:258]     Train net output #0: loss = 0.00677957 (* 1 = 0.00677957 loss)
I0526 18:34:03.869254 10701 sgd_solver.cpp:112] Iteration 24647, lr = 0.0025
I0526 18:34:35.274314 10701 solver.cpp:239] Iteration 24696 (1.56026 iter/s, 31.405s/49 iters), loss = 0.00281198
I0526 18:34:35.274534 10701 solver.cpp:258]     Train net output #0: loss = 0.000392045 (* 1 = 0.000392045 loss)
I0526 18:34:35.274544 10701 sgd_solver.cpp:112] Iteration 24696, lr = 0.0025
I0526 18:35:06.710597 10701 solver.cpp:239] Iteration 24745 (1.55872 iter/s, 31.436s/49 iters), loss = 0.00160421
I0526 18:35:06.710813 10701 solver.cpp:258]     Train net output #0: loss = 0.000358576 (* 1 = 0.000358576 loss)
I0526 18:35:06.710821 10701 sgd_solver.cpp:112] Iteration 24745, lr = 0.0025
I0526 18:35:38.138914 10701 solver.cpp:239] Iteration 24794 (1.55912 iter/s, 31.428s/49 iters), loss = 0.0111183
I0526 18:35:38.139093 10701 solver.cpp:258]     Train net output #0: loss = 0.00182906 (* 1 = 0.00182906 loss)
I0526 18:35:38.139102 10701 sgd_solver.cpp:112] Iteration 24794, lr = 0.0025
I0526 18:36:09.979092 10701 solver.cpp:239] Iteration 24843 (1.53899 iter/s, 31.839s/49 iters), loss = 0.00636741
I0526 18:36:09.979285 10701 solver.cpp:258]     Train net output #0: loss = 0.00966534 (* 1 = 0.00966534 loss)
I0526 18:36:09.979295 10701 sgd_solver.cpp:112] Iteration 24843, lr = 0.0025
I0526 18:36:41.907934 10701 solver.cpp:239] Iteration 24892 (1.5347 iter/s, 31.928s/49 iters), loss = 0.012786
I0526 18:36:41.908165 10701 solver.cpp:258]     Train net output #0: loss = 0.000980583 (* 1 = 0.000980583 loss)
I0526 18:36:41.908176 10701 sgd_solver.cpp:112] Iteration 24892, lr = 0.0025
I0526 18:37:13.722973 10701 solver.cpp:239] Iteration 24941 (1.5402 iter/s, 31.814s/49 iters), loss = 0.00286386
I0526 18:37:13.723074 10701 solver.cpp:258]     Train net output #0: loss = 0.0192346 (* 1 = 0.0192346 loss)
I0526 18:37:13.723083 10701 sgd_solver.cpp:112] Iteration 24941, lr = 0.0025
I0526 18:37:44.950886 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_24990.caffemodel
I0526 18:37:44.951792 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_24990.solverstate
I0526 18:37:44.952134 10701 solver.cpp:347] Iteration 24990, Testing net (#0)
I0526 18:37:56.803146 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8272
I0526 18:37:56.803184 10701 solver.cpp:414]     Test net output #1: loss = 0.429559 (* 1 = 0.429559 loss)
I0526 18:37:56.803191 10701 solver.cpp:347] Iteration 24990, Testing net (#1)
I0526 18:38:19.254256 10701 solver.cpp:414]     Test net output #0: accuracy = 0.999149
I0526 18:38:19.254467 10701 solver.cpp:414]     Test net output #1: loss = 0.00457895 (* 1 = 0.00457895 loss)
I0526 18:38:19.254477 10701 solver.cpp:347] Iteration 24990, Testing net (#2)
I0526 18:39:12.132302 10701 solver.cpp:414]     Test net output #0: accuracy = 0.86027
I0526 18:39:12.132495 10701 solver.cpp:414]     Test net output #1: loss = 0.321759 (* 1 = 0.321759 loss)
I0526 18:39:12.782313 10701 solver.cpp:239] Iteration 24990 (0.411561 iter/s, 119.059s/49 iters), loss = 0.00318013
I0526 18:39:12.782361 10701 solver.cpp:258]     Train net output #0: loss = 0.000781188 (* 1 = 0.000781188 loss)
I0526 18:39:12.782372 10701 sgd_solver.cpp:112] Iteration 24990, lr = 0.0025
I0526 18:39:45.307595 10701 solver.cpp:239] Iteration 25039 (1.50653 iter/s, 32.525s/49 iters), loss = 0.00595108
I0526 18:39:45.307749 10701 solver.cpp:258]     Train net output #0: loss = 0.00833538 (* 1 = 0.00833538 loss)
I0526 18:39:45.307765 10701 sgd_solver.cpp:112] Iteration 25039, lr = 0.0025
I0526 18:40:17.869439 10701 solver.cpp:239] Iteration 25088 (1.50487 iter/s, 32.561s/49 iters), loss = 0.00561859
I0526 18:40:17.869676 10701 solver.cpp:258]     Train net output #0: loss = 0.000570795 (* 1 = 0.000570795 loss)
I0526 18:40:17.869704 10701 sgd_solver.cpp:112] Iteration 25088, lr = 0.0025
I0526 18:40:50.235646 10701 solver.cpp:239] Iteration 25137 (1.51398 iter/s, 32.365s/49 iters), loss = 0.0066342
I0526 18:40:50.235858 10701 solver.cpp:258]     Train net output #0: loss = 0.000770601 (* 1 = 0.000770601 loss)
I0526 18:40:50.235880 10701 sgd_solver.cpp:112] Iteration 25137, lr = 0.0025
I0526 18:41:22.569456 10701 solver.cpp:239] Iteration 25186 (1.51548 iter/s, 32.333s/49 iters), loss = 0.00242649
I0526 18:41:22.569634 10701 solver.cpp:258]     Train net output #0: loss = 0.00380069 (* 1 = 0.00380069 loss)
I0526 18:41:22.569650 10701 sgd_solver.cpp:112] Iteration 25186, lr = 0.0025
I0526 18:41:54.558413 10701 solver.cpp:239] Iteration 25235 (1.53182 iter/s, 31.988s/49 iters), loss = 0.00665908
I0526 18:41:54.558610 10701 solver.cpp:258]     Train net output #0: loss = 0.000382957 (* 1 = 0.000382957 loss)
I0526 18:41:54.558619 10701 sgd_solver.cpp:112] Iteration 25235, lr = 0.0025
I0526 18:42:26.093164 10701 solver.cpp:239] Iteration 25284 (1.55388 iter/s, 31.534s/49 iters), loss = 0.00488885
I0526 18:42:26.093325 10701 solver.cpp:258]     Train net output #0: loss = 0.000975496 (* 1 = 0.000975496 loss)
I0526 18:42:26.093335 10701 sgd_solver.cpp:112] Iteration 25284, lr = 0.0025
I0526 18:42:57.476805 10701 solver.cpp:239] Iteration 25333 (1.56135 iter/s, 31.383s/49 iters), loss = 0.00717296
I0526 18:42:57.476954 10701 solver.cpp:258]     Train net output #0: loss = 0.000948071 (* 1 = 0.000948071 loss)
I0526 18:42:57.476964 10701 sgd_solver.cpp:112] Iteration 25333, lr = 0.0025
I0526 18:43:28.835330 10701 solver.cpp:239] Iteration 25382 (1.5626 iter/s, 31.358s/49 iters), loss = 0.00929695
I0526 18:43:28.835527 10701 solver.cpp:258]     Train net output #0: loss = 0.00186644 (* 1 = 0.00186644 loss)
I0526 18:43:28.835538 10701 sgd_solver.cpp:112] Iteration 25382, lr = 0.0025
I0526 18:44:00.241406 10701 solver.cpp:239] Iteration 25431 (1.56026 iter/s, 31.405s/49 iters), loss = 0.00947711
I0526 18:44:00.241616 10701 solver.cpp:258]     Train net output #0: loss = 0.000442094 (* 1 = 0.000442094 loss)
I0526 18:44:00.241626 10701 sgd_solver.cpp:112] Iteration 25431, lr = 0.0025
I0526 18:44:31.658118 10701 solver.cpp:239] Iteration 25480 (1.55971 iter/s, 31.416s/49 iters), loss = 0.00459268
I0526 18:44:31.658249 10701 solver.cpp:258]     Train net output #0: loss = 0.00228771 (* 1 = 0.00228771 loss)
I0526 18:44:31.658275 10701 sgd_solver.cpp:112] Iteration 25480, lr = 0.0025
I0526 18:45:03.041124 10701 solver.cpp:239] Iteration 25529 (1.5614 iter/s, 31.382s/49 iters), loss = 0.0040111
I0526 18:45:03.041288 10701 solver.cpp:258]     Train net output #0: loss = 0.0025712 (* 1 = 0.0025712 loss)
I0526 18:45:03.041307 10701 sgd_solver.cpp:112] Iteration 25529, lr = 0.0025
I0526 18:45:34.411485 10701 solver.cpp:239] Iteration 25578 (1.562 iter/s, 31.37s/49 iters), loss = 0.00523704
I0526 18:45:34.411659 10701 solver.cpp:258]     Train net output #0: loss = 0.00125676 (* 1 = 0.00125676 loss)
I0526 18:45:34.411669 10701 sgd_solver.cpp:112] Iteration 25578, lr = 0.0025
I0526 18:46:06.233821 10701 solver.cpp:239] Iteration 25627 (1.53982 iter/s, 31.822s/49 iters), loss = 0.0048516
I0526 18:46:06.234026 10701 solver.cpp:258]     Train net output #0: loss = 0.000156978 (* 1 = 0.000156978 loss)
I0526 18:46:06.234037 10701 sgd_solver.cpp:112] Iteration 25627, lr = 0.0025
I0526 18:46:38.114645 10701 solver.cpp:239] Iteration 25676 (1.53701 iter/s, 31.88s/49 iters), loss = 0.00513031
I0526 18:46:38.114817 10701 solver.cpp:258]     Train net output #0: loss = 0.0256102 (* 1 = 0.0256102 loss)
I0526 18:46:38.114828 10701 sgd_solver.cpp:112] Iteration 25676, lr = 0.0025
I0526 18:47:09.348067 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_25725.caffemodel
I0526 18:47:09.349021 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_25725.solverstate
I0526 18:47:09.349368 10701 solver.cpp:347] Iteration 25725, Testing net (#0)
I0526 18:47:21.039746 10701 solver.cpp:414]     Test net output #0: accuracy = 0.8456
I0526 18:47:21.039793 10701 solver.cpp:414]     Test net output #1: loss = 0.392177 (* 1 = 0.392177 loss)
I0526 18:47:21.039799 10701 solver.cpp:347] Iteration 25725, Testing net (#1)
I0526 18:47:43.162835 10701 solver.cpp:414]     Test net output #0: accuracy = 0.998723
I0526 18:47:43.163022 10701 solver.cpp:414]     Test net output #1: loss = 0.00498612 (* 1 = 0.00498612 loss)
I0526 18:47:43.163030 10701 solver.cpp:347] Iteration 25725, Testing net (#2)
I0526 18:48:34.816592 10701 solver.cpp:414]     Test net output #0: accuracy = 0.884234
I0526 18:48:34.816836 10701 solver.cpp:414]     Test net output #1: loss = 0.283239 (* 1 = 0.283239 loss)
I0526 18:48:35.468999 10701 solver.cpp:239] Iteration 25725 (0.41754 iter/s, 117.354s/49 iters), loss = 0.00578284
I0526 18:48:35.469051 10701 solver.cpp:258]     Train net output #0: loss = 0.0101766 (* 1 = 0.0101766 loss)
I0526 18:48:35.469061 10701 sgd_solver.cpp:112] Iteration 25725, lr = 0.0025
I0526 18:49:07.549974 10701 solver.cpp:239] Iteration 25774 (1.52743 iter/s, 32.08s/49 iters), loss = 0.00552696
I0526 18:49:07.550166 10701 solver.cpp:258]     Train net output #0: loss = 0.00221346 (* 1 = 0.00221346 loss)
I0526 18:49:07.550179 10701 sgd_solver.cpp:112] Iteration 25774, lr = 0.0025
I0526 18:49:39.677608 10701 solver.cpp:239] Iteration 25823 (1.5252 iter/s, 32.127s/49 iters), loss = 0.00469118
I0526 18:49:39.677851 10701 solver.cpp:258]     Train net output #0: loss = 0.000960301 (* 1 = 0.000960301 loss)
I0526 18:49:39.677861 10701 sgd_solver.cpp:112] Iteration 25823, lr = 0.0025
I0526 18:50:12.048830 10701 solver.cpp:239] Iteration 25872 (1.51375 iter/s, 32.37s/49 iters), loss = 0.00447896
I0526 18:50:12.049073 10701 solver.cpp:258]     Train net output #0: loss = 0.00109351 (* 1 = 0.00109351 loss)
I0526 18:50:12.049084 10701 sgd_solver.cpp:112] Iteration 25872, lr = 0.0025
I0526 18:50:44.325197 10701 solver.cpp:239] Iteration 25921 (1.51816 iter/s, 32.276s/49 iters), loss = 0.00543967
I0526 18:50:44.325415 10701 solver.cpp:258]     Train net output #0: loss = 0.000279702 (* 1 = 0.000279702 loss)
I0526 18:50:44.325426 10701 sgd_solver.cpp:112] Iteration 25921, lr = 0.0025
I0526 18:51:16.551296 10701 solver.cpp:239] Iteration 25970 (1.52056 iter/s, 32.225s/49 iters), loss = 0.00365153
I0526 18:51:16.551451 10701 solver.cpp:258]     Train net output #0: loss = 0.000638401 (* 1 = 0.000638401 loss)
I0526 18:51:16.551460 10701 sgd_solver.cpp:112] Iteration 25970, lr = 0.0025
I0526 18:51:48.822530 10701 solver.cpp:239] Iteration 26019 (1.51839 iter/s, 32.271s/49 iters), loss = 0.0101106
I0526 18:51:48.822701 10701 solver.cpp:258]     Train net output #0: loss = 0.000223688 (* 1 = 0.000223688 loss)
I0526 18:51:48.822721 10701 sgd_solver.cpp:112] Iteration 26019, lr = 0.0025
I0526 18:52:21.015087 10701 solver.cpp:239] Iteration 26068 (1.52212 iter/s, 32.192s/49 iters), loss = 0.00503068
I0526 18:52:21.015230 10701 solver.cpp:258]     Train net output #0: loss = 0.0171439 (* 1 = 0.0171439 loss)
I0526 18:52:21.015240 10701 sgd_solver.cpp:112] Iteration 26068, lr = 0.0025
I0526 18:52:53.193637 10701 solver.cpp:239] Iteration 26117 (1.52278 iter/s, 32.178s/49 iters), loss = 0.00379058
I0526 18:52:53.193781 10701 solver.cpp:258]     Train net output #0: loss = 0.000514827 (* 1 = 0.000514827 loss)
I0526 18:52:53.193791 10701 sgd_solver.cpp:112] Iteration 26117, lr = 0.0025
I0526 18:53:37.255708 10701 solver.cpp:239] Iteration 26166 (1.11209 iter/s, 44.061s/49 iters), loss = 0.00630439
I0526 18:53:37.255861 10701 solver.cpp:258]     Train net output #0: loss = 0.000306341 (* 1 = 0.000306341 loss)
I0526 18:53:37.255872 10701 sgd_solver.cpp:112] Iteration 26166, lr = 0.0025
I0526 18:54:51.044425 10701 solver.cpp:239] Iteration 26215 (0.664065 iter/s, 73.788s/49 iters), loss = 0.00707085
I0526 18:54:51.044979 10701 solver.cpp:258]     Train net output #0: loss = 0.00173975 (* 1 = 0.00173975 loss)
I0526 18:54:51.045050 10701 sgd_solver.cpp:112] Iteration 26215, lr = 0.0025
I0526 18:56:19.357609 10701 solver.cpp:239] Iteration 26264 (0.554851 iter/s, 88.312s/49 iters), loss = 0.00808991
I0526 18:56:19.357848 10701 solver.cpp:258]     Train net output #0: loss = 0.000425289 (* 1 = 0.000425289 loss)
I0526 18:56:19.357867 10701 sgd_solver.cpp:112] Iteration 26264, lr = 0.0025
I0526 18:57:53.457177 10701 solver.cpp:239] Iteration 26313 (0.520728 iter/s, 94.099s/49 iters), loss = 0.00666064
I0526 18:57:53.457334 10701 solver.cpp:258]     Train net output #0: loss = 0.00237676 (* 1 = 0.00237676 loss)
I0526 18:57:53.457348 10701 sgd_solver.cpp:112] Iteration 26313, lr = 0.0025
I0526 18:59:16.579075 10701 solver.cpp:239] Iteration 26362 (0.589502 iter/s, 83.121s/49 iters), loss = 0.008896
I0526 18:59:16.579216 10701 solver.cpp:258]     Train net output #0: loss = 0.00142862 (* 1 = 0.00142862 loss)
I0526 18:59:16.579226 10701 sgd_solver.cpp:112] Iteration 26362, lr = 0.0025
I0526 18:59:59.824406 10701 solver.cpp:239] Iteration 26411 (1.13308 iter/s, 43.245s/49 iters), loss = 0.003344
I0526 18:59:59.824568 10701 solver.cpp:258]     Train net output #0: loss = 0.000362561 (* 1 = 0.000362561 loss)
I0526 18:59:59.824579 10701 sgd_solver.cpp:112] Iteration 26411, lr = 0.0025
I0526 19:00:11.144820 10701 solver.cpp:464] Snapshotting to binary proto file snapshots/snapshot_iter_26425.caffemodel
I0526 19:00:11.148172 10701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file snapshots/snapshot_iter_26425.solverstate
I0526 19:00:11.148535 10701 solver.cpp:332] Optimization Done.
I0526 19:00:11.148854 10701 caffe.cpp:250] Optimization Done.
