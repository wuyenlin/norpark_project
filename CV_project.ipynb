{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LCcsWbgC931"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aoWaGuvDAFu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XdNJNeSXDFJj"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7otGhksDEPw"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  batch = list(filter(lambda x: x is not None, batch))\n",
    "  return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "class selfData:\n",
    "  def __init__(self, img_path, target_path, transforms = None):\n",
    "    with open(target_path, 'r') as f:\n",
    "      lines = f.readlines()\n",
    "      self.img_list = [os.path.join(img_path, i.split()[0]) for i in lines]\n",
    "      self.label_list = [i.split()[1] for i in lines]\n",
    "      self.transforms = transforms\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    try:\n",
    "      img_path = self.img_list[index]\n",
    "      img = Image.open(img_path)\n",
    "      img = self.transforms(img)\n",
    "      label = self.label_list[index]\n",
    "    except:\n",
    "      return None\n",
    "    return img, label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2ID1LIozTbJ"
   },
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tfrj2H_tzLZZ"
   },
   "outputs": [],
   "source": [
    "class mAlexNet(nn.Module):\n",
    "  def __init__(self, num_classes = 2):\n",
    "    super(mAlexNet, self).__init__()\n",
    "    self.input_channel = 3\n",
    "    self.num_output = num_classes\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=self.input_channel, out_channels= 16, kernel_size= 11, stride= 4),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels= 16, out_channels= 20, kernel_size= 5, stride= 1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    )\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels= 20, out_channels= 30, kernel_size= 3, stride= 1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    )\n",
    "    self.layer4 = nn.Sequential(\n",
    "        nn.Linear(30*3*3, out_features=48),\n",
    "        #nn.Linear(30, out_features=48),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "    self.layer5 = nn.Sequential(\n",
    "        nn.Linear(in_features=48, out_features=2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer3(self.layer2(self.layer1(x)))\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.layer5(self.layer4(x))\n",
    "    m = nn.Softmax(dim = 1)\n",
    "    x = m(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bT6o4XdHzc05"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3uUeAM6yzfQV"
   },
   "outputs": [],
   "source": [
    "def train(epoch, img_path, target_path, transforms, net, criterion):\n",
    "  train_dataset = selfData(img_path, target_path, transforms)\n",
    "  train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True, num_workers = 0,drop_last= False, collate_fn=collate_fn)\n",
    "  print('Training begins...')\n",
    "  for ep in range(epoch):  \n",
    "    learning_rate = 0.01\n",
    "    if ep >= 12:\n",
    "      learning_rate = 0.0025\n",
    "    elif ep >= 6:\n",
    "      learning_rate = 0.005\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader,1):\n",
    "      inputs, labels = data\n",
    "      labels = list(map(int, labels))\n",
    "      labels = torch.Tensor(labels)\n",
    "      if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "      optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, labels.long())\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "  print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IB2YY3CSFn9H"
   },
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9l8aOatFm84"
   },
   "outputs": [],
   "source": [
    "def test(img_path, target_path, transforms, net):\n",
    "  print(\"\\nTesting starts now...\")\n",
    "  test_dataset = selfData(img_path, target_path, transforms)\n",
    "  test_loader = DataLoader(test_dataset, batch_size = 100, shuffle = True, num_workers = 0, collate_fn=collate_fn)\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  item = 1\n",
    "  with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "      images, labels = data\n",
    "      # print(\"Testing on batch {}\".format(item))\n",
    "      labels = list(map(int, labels))\n",
    "      labels = torch.Tensor(labels)\n",
    "      if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "      outputs = net(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "      item += 1\n",
    "      accuracy = (correct/total)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i09O6sFSziRD"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AC2aj2n8sAD8"
   },
   "outputs": [],
   "source": [
    "epochs = 18\n",
    "net = mAlexNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),  # normalize to [0, 1]\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNibnWz2sAD_"
   },
   "source": [
    "## Table 2 reproduction ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "VrqLt6XRIIL7",
    "outputId": "91ebbfb5-e0d1-4511-d46d-6478bd089f41",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n",
      "Finished Training.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/UFPR04_train' and testing on 'splits/PKLot/UFPR04_test': 0.958.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/UFPR04_train' and testing on 'splits/PKLot/UFPR05_test': 0.798.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/UFPR04_train' and testing on 'splits/PKLot/PUC_test': 0.929.\n",
      "\n",
      "Training begins...\n",
      "Finished Training.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/UFPR05_train' and testing on 'splits/PKLot/UFPR04_test': 0.830.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/UFPR05_train' and testing on 'splits/PKLot/UFPR05_test': 0.974.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/UFPR05_train' and testing on 'splits/PKLot/PUC_test': 0.891.\n",
      "\n",
      "Training begins...\n",
      "Finished Training.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/PUC_train' and testing on 'splits/PKLot/UFPR04_test': 0.958.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/PUC_train' and testing on 'splits/PKLot/UFPR05_test': 0.947.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/PKLot/PUC_train' and testing on 'splits/PKLot/PUC_test': 0.990.\n",
      "\n",
      "Experiments ended.\n"
     ]
    }
   ],
   "source": [
    "train_img = 'PKLot/PKLotSegmented'\n",
    "train_lab = ['splits/PKLot/UFPR04_train.txt','splits/PKLot/UFPR05_train.txt', 'splits/PKLot/PUC_train.txt']\n",
    "test_img = 'PKLot/PKLotSegmented'\n",
    "test_lab = ['splits/PKLot/UFPR04_test.txt','splits/PKLot/UFPR05_test.txt', 'splits/PKLot/PUC_test.txt']\n",
    "\n",
    "for train_set in train_lab:\n",
    "    train(epochs, train_img, train_set, tf, net, criterion)\n",
    "    PATH = './trained.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    net = mAlexNet().to(device)\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    for test_set in test_lab:      \n",
    "        accuracy = test(test_img, test_set, tf, net)\n",
    "        print(\"Training on '{}' and testing on '{}': {:.3f}.\\n\".format(train_set.split('.')[0], test_set.split('.')[0], accuracy))\n",
    "print(\"Experiments ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmDGX8fEsAED"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n",
      "Finished Training.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRParkAB/odd' and testing on 'splits/CNRParkAB/even': 0.927.\n",
      "\n",
      "Training begins...\n",
      "Finished Training.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRParkAB/even' and testing on 'splits/CNRParkAB/odd': 0.925.\n",
      "\n",
      "Experiments ended.\n"
     ]
    }
   ],
   "source": [
    "train_img = 'CNRPark-Patches-150x150'\n",
    "train_lab = ['splits/CNRParkAB/odd.txt','splits/CNRParkAB/even.txt']\n",
    "test_img = 'CNRPark-Patches-150x150'\n",
    "test_lab = ['splits/CNRParkAB/even.txt','splits/CNRParkAB/odd.txt']\n",
    "\n",
    "for train_set, test_set in zip(train_lab, test_lab):\n",
    "    train(epochs, train_img, train_set, tf, net, criterion)\n",
    "    PATH = './trained.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    net = mAlexNet().to(device)\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    accuracy = test(test_img, test_set, tf, net)\n",
    "    print(\"Training on '{}' and testing on '{}': {:.3f}.\\n\".format(train_set.split('.')[0], test_set.split('.')[0], accuracy))\n",
    "print(\"Experiments ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9p5gNFSksAEG"
   },
   "source": [
    "## Figure 5 Reproduction ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOIyJ0tcsAEG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins...\n",
      "Finished Training.\n",
      "Skip to next test.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/sunny' and testing on 'splits/CNRPark-EXT/overcast': 0.952.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/sunny' and testing on 'splits/CNRPark-EXT/rainy': 0.915.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/sunny' and testing on 'splits/PKLot/val': 0.726.\n",
      "\n",
      "Training begins...\n",
      "Finished Training.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/overcast' and testing on 'splits/CNRPark-EXT/sunny': 0.924.\n",
      "\n",
      "Skip to next test.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/overcast' and testing on 'splits/CNRPark-EXT/rainy': 0.928.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/overcast' and testing on 'splits/PKLot/val': 0.653.\n",
      "\n",
      "Training begins...\n",
      "Finished Training.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/rainy' and testing on 'splits/CNRPark-EXT/sunny': 0.917.\n",
      "\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/rainy' and testing on 'splits/CNRPark-EXT/overcast': 0.959.\n",
      "\n",
      "Skip to next test.\n",
      "\n",
      "Testing starts now...\n",
      "Training on 'splits/CNRPark-EXT/rainy' and testing on 'splits/PKLot/val': 0.642.\n",
      "\n",
      "Experiments ended.\n"
     ]
    }
   ],
   "source": [
    "train_img = 'PATCHES/'\n",
    "train_lab = ['splits/CNRPark-EXT/sunny.txt','splits/CNRPark-EXT/overcast.txt','splits/CNRPark-EXT/rainy.txt']\n",
    "test_lab = ['splits/CNRPark-EXT/sunny.txt','splits/CNRPark-EXT/overcast.txt','splits/CNRPark-EXT/rainy.txt','splits/PKLot/val.txt']\n",
    "\n",
    "for train_set in train_lab:\n",
    "    train(epochs, train_img, train_set, tf, net, criterion)\n",
    "    PATH = './trained.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    net = mAlexNet().to(device)\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    for test_set in test_lab:\n",
    "        if test_set == train_set:\n",
    "            accuracy = 'none'\n",
    "            print(\"Skip to next test.\")\n",
    "        elif test_set == 'splits/PKLot/val.txt':\n",
    "            test_img = 'PKLot/PKLotSegmented'\n",
    "            accuracy = test(test_img, test_set, tf, net)\n",
    "            print(\"Training on '{}' and testing on '{}': {:.3f}.\\n\".format(train_set.split('.')[0], test_set.split('.')[0], accuracy))\n",
    "        else:\n",
    "            test_img = 'PATCHES/'\n",
    "            accuracy = test(test_img, test_set, tf, net)\n",
    "            print(\"Training on '{}' and testing on '{}': {:.3f}.\\n\".format(train_set.split('.')[0], test_set.split('.')[0], accuracy))\n",
    "print(\"Experiments ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrWe7kk7sAEJ"
   },
   "source": [
    "## Testing on NORPark dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ow1_ZXkcsAEK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing starts now...\n",
      "\n",
      "Trained on trained_model/sunny, accuracy : 0.818\n",
      "\n",
      "Testing starts now...\n",
      "\n",
      "Trained on trained_model/overcast, accuracy : 0.789\n",
      "\n",
      "Testing starts now...\n",
      "\n",
      "Trained on trained_model/rainy, accuracy : 0.831\n",
      "\n",
      "Testing starts now...\n",
      "\n",
      "Trained on trained_model/04, accuracy : 0.854\n",
      "\n",
      "Testing starts now...\n",
      "\n",
      "Trained on trained_model/05, accuracy : 0.834\n",
      "\n",
      "Testing starts now...\n",
      "\n",
      "Trained on trained_model/puc, accuracy : 0.893\n",
      "Experiments ended.\n"
     ]
    }
   ],
   "source": [
    "test_img = 'NORPark/'\n",
    "test_lab = 'splits/NORPark/nor_lab.txt'\n",
    "PATHS = ['trained_model/sunny.pth','trained_model/overcast.pth',\n",
    "         'trained_model/rainy.pth','trained_model/04.pth',\n",
    "         'trained_model/05.pth','trained_model/puc.pth']\n",
    "\n",
    "for PATH in PATHS:\n",
    "    net = mAlexNet().to(device)\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    accuracy = test(test_img, test_lab, tf, net)\n",
    "    trained_name = PATH.split('.pth')[0]\n",
    "    print('\\nTrained on {}, accuracy : {:.3f}'.format(trained_name, accuracy))\n",
    "print(\"Experiments ended.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of cv_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
